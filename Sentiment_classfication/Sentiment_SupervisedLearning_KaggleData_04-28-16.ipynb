{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose:  Use supervised learning to train a classifier to predict Kaggle-assigned tweet sentiment.\n",
    "#           Compare a variety of sample sizes, types of features, and classifiers.\n",
    "#           Save the chosen classifier and featurizer to disk.\n",
    "# Author:  Carol Sniegoski\n",
    "# Date:  04/27/16\n",
    "# Course:  MAS DSE capstone, Spring 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "import math\n",
    "\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # for featurizing using term frequencies\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # for featurizing using word n-grams\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#from textblob import TextBlob\n",
    "#from textblob import Blobber\n",
    "#from textblob.taggers import NLTKTagger\n",
    "#from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function defs.\n",
    "\n",
    "# return string with non-ascii chars removed\n",
    "def to_ascii(s):\n",
    "    returnstr = s.strip()\n",
    "    returnstr = \"\".join([ch for ch in returnstr if ord(ch)< 128])\n",
    "    return returnstr\n",
    "\n",
    "# Return df containing 'fraction' fraction of the original df,\n",
    "# with each value in column 'col' equally represented.\n",
    "def sample_equally( df, col, fraction ):\n",
    "    n = int(df.shape[0] * fraction)  # Get the total number of records to sample.\n",
    "    vals = pd.unique(df[col].values.ravel())  # Get the class labels.\n",
    "    n_to_sample = int(n/len(vals))   # Get the number of records to sample from each class.\n",
    "    \n",
    "    samples = []\n",
    "    for val in vals:\n",
    "        #samples.append( df[df[col]==val].sample(n=n_to_sample) )  # This should work in python 0.16.1\n",
    "        rows = np.random.choice(df[df[col]==val].index.values, n_to_sample)\n",
    "        sampled_df = df.ix[rows]\n",
    "        samples.append(sampled_df)\n",
    "    \n",
    "    result = pd.concat(samples)\n",
    "\n",
    "    return result\n",
    "\n",
    "# From newer version of python.\n",
    "def cohen_kappa_score(y1, y2, labels=None, weights=None):\n",
    "    confusion = confusion_matrix(y1, y2, labels=labels)\n",
    "    n_classes = confusion.shape[0]\n",
    "    sum0 = np.sum(confusion, axis=0)\n",
    "    sum1 = np.sum(confusion, axis=1)\n",
    "    expected = np.outer(sum0, sum1) / np.sum(sum0)\n",
    "\n",
    "    if weights is None:\n",
    "        w_mat = np.ones([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat.flat[:: n_classes + 1] = 0\n",
    "    elif weights == \"linear\" or weights == \"quadratic\":\n",
    "        w_mat = np.zeros([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat += np.arange(n_classes)\n",
    "        if weights == \"linear\":\n",
    "            w_mat = np.abs(w_mat - w_mat.T)\n",
    "        else:\n",
    "            w_mat = (w_mat - w_mat.T) ** 2\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kappa weighting type.\")\n",
    "\n",
    "    k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
    "    return 1 - k\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle_topHashtagsByTopic_04-07-16.csv  database.sqlite\r\n",
      "Sentiment.csv                           hashes.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Locate the data.\n",
    "%ls ../data/Kaggle/Kaggle_1stGOPDebateTweets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Set the names of the cleaned text field and the class label field,\n",
    "# to be used in the sampling, featurizing, and classification steps.\n",
    "clean_text = 'ascii_clean'  # This is where the cleaned text will be put.\n",
    "label_field = 'K_sentiment' # This is where the labels will be put.\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ascii_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate</td>\n",
       "      <td>rt @nancyleegrahn how did everyone feel about the climate change question last night? exactly. #gopdebate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…</td>\n",
       "      <td>rt @scottwalker didnt catch the full #gopdebate last night. here are some of scotts best lines in 90 seconds. #walker16 url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.</td>\n",
       "      <td>rt @tjmshow no mention of tamir rice and the #gopdebate was held in cleveland? wow.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  \\\n",
       "0                                    RT @NancyLeeGrahn: How did everyone feel about the Climate Change question last night? Exactly. #GOPDebate   \n",
       "1  RT @ScottWalker: Didn't catch the full #GOPdebate last night. Here are some of Scott's best lines in 90 seconds. #Walker16 http://t.co/ZSfF…   \n",
       "2                                                          RT @TJMShow: No mention of Tamir Rice and the #GOPDebate was held in Cleveland? Wow.   \n",
       "\n",
       "                                                                                                                   ascii_clean  \n",
       "0                    rt @nancyleegrahn how did everyone feel about the climate change question last night? exactly. #gopdebate  \n",
       "1  rt @scottwalker didnt catch the full #gopdebate last night. here are some of scotts best lines in 90 seconds. #walker16 url  \n",
       "2                                          rt @tjmshow no mention of tamir rice and the #gopdebate was held in cleveland? wow.  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the clean_text field.\n",
    "# Load data file & clean the 'text' column.\n",
    "\n",
    "prefix = \"../data/Kaggle/Kaggle_1stGOPDebateTweets/\"\n",
    "df = pd.read_csv(prefix + \"Sentiment.csv\")\n",
    "\n",
    "# Convert to ascii\n",
    "df['ascii'] = df['text'].apply(to_ascii)\n",
    "df[clean_text] = df['ascii']\n",
    "\n",
    "# Remove hashtags\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"#([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove handles\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"@([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove URLs\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \" \")\n",
    "# Replace URLs with \"URL\"\n",
    "df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \"URL\")\n",
    "\n",
    "# Remove punctuation symbols - but not @ or #\n",
    "df[clean_text] = df[clean_text].str.replace(r\"(['';:%()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"(['';:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"([;:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "\n",
    "# Remove eol symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"\\n\", \" \")\n",
    "\n",
    "# Remove &x symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"&[a-z]+\", \" \")\n",
    "\n",
    "# Convert to lowercase\n",
    "df[clean_text] = df[clean_text].str.lower()\n",
    "\n",
    "#print df[df['ascii']!=df[clean_text]][['ascii', 'K_sentiment']].head(10)\n",
    "df[['text', clean_text]].head(3)\n",
    "#df[df['ascii'].str.contains(\"\\n\")][['text', 'ascii']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative    (Count: 8493, Frequency: 0.61)\n",
      "Neutral     (Count: 3142, Frequency: 0.23)\n",
      "Positive    (Count: 2236, Frequency: 0.16)\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Populate the label_field.\n",
    "df[label_field] = df['sentiment']\n",
    "\n",
    "# Show the class frequencies.\n",
    "counts = df[label_field].value_counts()\n",
    "total = counts.sum()\n",
    "\n",
    "counts = counts.apply(lambda x: (\"Count: %d\" % x, \"Frequency: %.2f\" % (float(x)/total)) )\n",
    "\n",
    "#print(\"%.2f\" % a)\n",
    "#string = 'string%d' % (i,)\n",
    "\n",
    "print counts\n",
    "print type(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data\n",
      "(13871, 24)\n",
      "Negative    8493\n",
      "Neutral     3142\n",
      "Positive    2236\n",
      "dtype: int64\n",
      "\n",
      "0.75 random sample\n",
      "(10401, 24)\n",
      "Positive    3467\n",
      "Neutral     3467\n",
      "Negative    3467\n",
      "dtype: int64\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Sample the data so as to get equal numbers of each class.\n",
    "# The sizes of the sampled dataset will be the following fractions of the size of the original dataset.\n",
    "data_fractions = [.75] \n",
    "\n",
    "# Include the original unsampled data.\n",
    "df_samples = [ df ]\n",
    "sample_names = [ 'original data' ]\n",
    "\n",
    "# Now add additional samples using random over- or undersampling so as to obtain equal numbers of each class. \n",
    "for data_fraction in data_fractions:\n",
    "    df_samples.append(sample_equally( df, label_field, data_fraction ))\n",
    "    sample_names.append( str(data_fraction)+' random sample' )\n",
    "\n",
    "#for df_sample in df_samples:\n",
    "for sample_name, df_sample in zip(sample_names, df_samples):\n",
    "    print sample_name\n",
    "    print df_sample.shape\n",
    "    print df_sample[label_field].value_counts()\n",
    "    print\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Convert sampled data & their class labels into ndarrays.\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "\n",
    "for df_sample in df_samples:\n",
    "    X_samples.append(df_sample[clean_text].values)\n",
    "    y_samples.append(df_sample[label_field].values)\n",
    "\n",
    "print type(X_samples[0])\n",
    "print len(X_samples)\n",
    "print len(y_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of types of feature vectors to use.\n",
    "# Add feature vectors to this list by running one or more of the feature-generation cells below.\n",
    "\n",
    "feature_vector_lists = []\n",
    "feature_names = []\n",
    "featurizers = []\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data (13871, 7374)\n",
      "0.75 random sample (10401, 6769)\n",
      "['char 3grams']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using character n-grams.\n",
    "\n",
    "this_feature_name = \"char 3grams\"\n",
    "this_feature_vector_list = []\n",
    "\n",
    "ngram_min_size = 3\n",
    "ngram_max_size = 3\n",
    "\n",
    "#test_string = [\"I really like python, it's pretty awesome.\"]\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char'  # create character ngrams\n",
    "                             )\n",
    "\n",
    "for X_sample, sample_name in zip(X_samples, sample_names):\n",
    "    #X_featurized = vectorizer.fit_transform(X)\n",
    "    #print X_featurized.shape\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    #feature_names.append( this_feature_name + ', ' + sample_name )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names\n",
    "    \n",
    "#print('{1}-grams: {0}'.format(vect.get_feature_names(), ngram_size))\n",
    "#print 'Number of char n-grams:', len(vectorizer.get_feature_names())\n",
    "#print vectorizer.get_feature_names()[1000:1025]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data (13871, 8859)\n",
      "0.75 random sample (10401, 8066)\n",
      "['char 3grams', 'tfidf', 'word 1- & 2grams']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using word n-grams.\n",
    "\n",
    "this_feature_name = 'word 1- & 2grams'\n",
    "this_feature_vector_list = []\n",
    "\n",
    "ngram_min_size = 1\n",
    "ngram_max_size = 2\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,      # min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,    # max percent of docs a token can appear in (if a float value)\n",
    "                             analyzer='word'  # create word ngrams; this is the default\n",
    "                             )\n",
    "\n",
    "for X_sample, sample_name in zip(X_samples, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data (13871, 3242)\n",
      "0.5 random sample (6933, 2042)\n",
      "0.75 random sample (10401, 2841)\n",
      "1.8 random sample (24966, 5494)\n",
      "['char 3grams', 'word 1- & 2grams', 'term freq']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using term frequency (same as word 1-grams, presumably).\n",
    "\n",
    "this_feature_name = 'term freq'\n",
    "this_feature_vector_list = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5,     # Min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,   # Max percent of docs a token can appear in (if a float value)\n",
    "                             sublinear_tf = True,   # Need to look up what this is\n",
    "                             use_idf = False)  # Don't use inverse document frequency weighting\n",
    "\n",
    "for X_sample, sample_name in zip(X_samples, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data (13871, 3242)\n",
      "0.75 random sample (10401, 2858)\n",
      "['char 3grams', 'tfidf']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using tfidf.\n",
    "\n",
    "this_feature_name = 'tfidf'\n",
    "this_feature_vector_list = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5,     # Min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,   # Max percent of docs a token can appear in (if a float value)\n",
    "                             sublinear_tf = True,   # Need to look up what this is\n",
    "                             use_idf = True)  # Use idf\n",
    "\n",
    "for X_sample, sample_name in zip(X_samples, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of classifiers to use.\n",
    "# Add classifiers to this list by running one or more of the classifier-creation cells below.\n",
    "\n",
    "classifiers = []\n",
    "classifier_names = []\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['Multinomial NB', 'Bernoulli NB']\n"
     ]
    }
   ],
   "source": [
    "# Create Naive Bayes classifiers.\n",
    "\n",
    "# Multinomial NaiveBayes. Commonly used for text classification.\n",
    "classifier_names.append(\"Multinomial NB\")\n",
    "classifiers.append(MultinomialNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "                                 fit_prior=True))  # Fit priors based on training data\n",
    "                  \n",
    "# Bernoulli NaiveBayes. Commonly used for text classification for short documents.\n",
    "# Expects boolean features (e.g., word occurence/nonoccurence instead of term frequency or tfidf).\n",
    "classifier_names.append('Bernoulli NB')\n",
    "classifiers.append(BernoulliNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "                               binarize=0,       # Threshold for binarizing the input features\n",
    "                               fit_prior=True))  # Fit priors based on training data\n",
    "print 'done'\n",
    "print classifier_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['LinearSVC']\n"
     ]
    }
   ],
   "source": [
    "# Create SVM / logistic regression classifiers.\n",
    "\n",
    "# SVM with linear kernel.\n",
    "classifier_names.append('LinearSVC')\n",
    "classifiers.append(LinearSVC(random_state=0)) \n",
    "\n",
    "# Logistic regression (sometimes called maxent).\n",
    "#classifier_names.append('Logistic')\n",
    "#classifiers.append(SGDClassifier(loss='hinge', \n",
    "#                                 penalty='l2', \n",
    "#                                 alpha=1e-3, \n",
    "#                                 n_iter=5, \n",
    "#                                 random_state=0))\n",
    "print 'done'\n",
    "print classifier_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['LinearSVC', 'RandomForest']\n"
     ]
    }
   ],
   "source": [
    "# Create ensemble classifiers.\n",
    "\n",
    "# RandomForest.\n",
    "classifier_names.append('RandomForest')\n",
    "classifiers.append(RandomForestClassifier(n_estimators = 100))  # Number of decision stumps to use in the ensemble\n",
    "\n",
    "# AdaBoost with decision stumps.\n",
    "### WARNING: Training this is very, very slow. ###\n",
    "#classifier_names.append('Adaboost on DecTree')\n",
    "#classifiers.append( AdaBoostClassifier(\n",
    "#        #BernoulliNB(alpha=1.0, binarize=0, fit_prior=True),  # Use BernoulliNB as the weak estimators\n",
    "#        DecisionTreeClassifier(max_depth=2),   # Use decision tree stumps as the weak estimators\n",
    "#        n_estimators=600,    # The max number of estimators at which boosting is terminated\n",
    "#        learning_rate=1) )   # By how much to shrink the contribution of each (successive?) estimator\n",
    "#                             # By default, AdaBoost uses estimated class probabilities, not boolean class values\n",
    "print 'done'\n",
    "print classifier_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize scores.\n",
    "scores = {}\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning classifier LinearSVC\n",
      "   done with char 3grams\n",
      "done training and testing classifiers\n"
     ]
    }
   ],
   "source": [
    "# Train and test classifiers using crossvalidation.\n",
    "# This will use all the types of sampling, features, and classifiers that were created.\n",
    "\n",
    "cv = 3  # Number of crossvalidation folds to use.\n",
    "#scores = {}\n",
    "#score_descriptions = []\n",
    "\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    print 'beginning classifier ' + classifier_name\n",
    "    scores[classifier_name] = {}\n",
    "    for feature_vector_list, feature_name in zip(feature_vector_lists, feature_names):\n",
    "        scores[classifier_name][feature_name] = {}\n",
    "        for X, y_sample, sample_name in zip(feature_vector_list, y_samples, sample_names):\n",
    "            y_pred = cross_validation.cross_val_predict(classifier, X, y_sample, cv=cv)\n",
    "            scores[classifier_name][feature_name][sample_name] = ( y_sample, y_pred )\n",
    "            #scores[classifier_name][feature_name][sample_name] = cross_validation.cross_val_score(classifier, X, y_sample, cv=cv)\n",
    "            #scores.append( cross_validation.cross_val_score(classifier, X, y_sample, cv=cv) )\n",
    "            #score_descriptions.append( classifier_name + ', ' + feature_name + ', ' + sample_name )\n",
    "        print '   done with ' + feature_name\n",
    "    \n",
    "print 'done training and testing classifiers' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "\n",
      "char 3grams\n",
      "\n",
      "  original data\n",
      "0.570903323481\n",
      "1\n",
      "  0.75 random sample\n",
      "0.755408133833\n",
      "1\n",
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Print results.\n",
    "\n",
    "for classifier_name, classifier_results in scores.items():\n",
    "    print classifier_name\n",
    "    print\n",
    "    for feature_name, feature_results in classifier_results.items():\n",
    "        print feature_name\n",
    "        print\n",
    "        #for sample_name, sample_scores in feature_results.items():\n",
    "        for sample_name, results in feature_results.items():\n",
    "            #print \"  \" + sample_name + \": mean=\" + str(sample_scores.mean()) + \", std=\" + str(sample_scores.std())\n",
    "            print \"  \" + sample_name\n",
    "            y, y_pred = results\n",
    "            #print type(results)\n",
    "            #print confusion_matrix( y, y_pred )\n",
    "            #print classification_report( y, y_pred )\n",
    "            print metrics.accuracy_score( y, y_pred )\n",
    "            print cohen_kappa_score( y, y_pred )\n",
    "            #print \n",
    "        print\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.698202095952\n",
      "   Neg  Neu  Pos\n",
      "[[2434  679  354]\n",
      " [ 661 2343  463]\n",
      " [ 381  601 2485]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.70      0.70      0.70      3467\n",
      "    Neutral       0.65      0.68      0.66      3467\n",
      "   Positive       0.75      0.72      0.73      3467\n",
      "\n",
      "avg / total       0.70      0.70      0.70     10401\n",
      "\n",
      "\n",
      "0.697817517546\n",
      "   Neg  Neu  Pos\n",
      "[[2261  885  321]\n",
      " [ 530 2560  377]\n",
      " [ 319  711 2437]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.73      0.65      0.69      3467\n",
      "    Neutral       0.62      0.74      0.67      3467\n",
      "   Positive       0.78      0.70      0.74      3467\n",
      "\n",
      "avg / total       0.71      0.70      0.70     10401\n",
      "\n",
      "\n",
      "0.793192962215\n",
      "   Neg  Neu  Pos\n",
      "[[2709  470  288]\n",
      " [ 499 2573  395]\n",
      " [ 204  295 2968]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.79      0.78      0.79      3467\n",
      "    Neutral       0.77      0.74      0.76      3467\n",
      "   Positive       0.81      0.86      0.83      3467\n",
      "\n",
      "avg / total       0.79      0.79      0.79     10401\n",
      "\n",
      "\n",
      "0.668397269493\n",
      "   Neg  Neu  Pos\n",
      "[[2319  690  458]\n",
      " [ 767 2172  528]\n",
      " [ 412  594 2461]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.66      0.67      0.67      3467\n",
      "    Neutral       0.63      0.63      0.63      3467\n",
      "   Positive       0.71      0.71      0.71      3467\n",
      "\n",
      "avg / total       0.67      0.67      0.67     10401\n",
      "\n",
      "\n",
      "0.945582155562\n",
      "   Neg  Neu  Pos\n",
      "[[3285   93   89]\n",
      " [ 157 3174  136]\n",
      " [  40   51 3376]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.94      0.95      0.95      3467\n",
      "    Neutral       0.96      0.92      0.94      3467\n",
      "   Positive       0.94      0.97      0.96      3467\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10401\n",
      "\n",
      "\n",
      "0.852321892126\n",
      "   Neg  Neu  Pos\n",
      "[[2924  433  110]\n",
      " [ 473 2809  185]\n",
      " [ 134  201 3132]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.83      0.84      0.84      3467\n",
      "    Neutral       0.82      0.81      0.81      3467\n",
      "   Positive       0.91      0.90      0.91      3467\n",
      "\n",
      "avg / total       0.85      0.85      0.85     10401\n",
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Fit classifiers to the whole (sampled) dataset and look at the confusion matrix and classification report for each.\n",
    "\n",
    "#OneVsOneClassifier(LinearSVC(random_state=0)).fit(X, y).predict(X)\n",
    "predicteds = []\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(X_featurized, y)\n",
    "    predicteds.append( classifier.predict(X_featurized))\n",
    "    \n",
    "for y_pred in predicteds:\n",
    "    print accuracy_score(y, y_pred)\n",
    "    print '   Neg ', 'Neu ', 'Pos'\n",
    "    print confusion_matrix(y, y_pred)\n",
    "    print classification_report(y, y_pred)\n",
    "    print\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "0.643068271934\n",
      "   Neg  Neu  Pos\n",
      "[[5475 2011 1007]\n",
      " [ 710 1949  483]\n",
      " [ 298  442 1496]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.84      0.64      0.73      8493\n",
      "    Neutral       0.44      0.62      0.52      3142\n",
      "   Positive       0.50      0.67      0.57      2236\n",
      "\n",
      "avg / total       0.70      0.64      0.66     13871\n",
      "\n",
      "\n",
      "0.626559008002\n",
      "   Neg  Neu  Pos\n",
      "[[5070 2494  929]\n",
      " [ 557 2179  406]\n",
      " [ 252  542 1442]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.86      0.60      0.71      8493\n",
      "    Neutral       0.42      0.69      0.52      3142\n",
      "   Positive       0.52      0.64      0.58      2236\n",
      "\n",
      "avg / total       0.71      0.63      0.64     13871\n",
      "\n",
      "\n",
      "0.685098406748\n",
      "   Neg  Neu  Pos\n",
      "[[5693 1765 1035]\n",
      " [ 617 2067  458]\n",
      " [ 210  283 1743]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.87      0.67      0.76      8493\n",
      "    Neutral       0.50      0.66      0.57      3142\n",
      "   Positive       0.54      0.78      0.64      2236\n",
      "\n",
      "avg / total       0.74      0.69      0.70     13871\n",
      "\n",
      "\n",
      "0.626126450869\n",
      "   Neg  Neu  Pos\n",
      "[[5305 1958 1230]\n",
      " [ 760 1867  515]\n",
      " [ 307  416 1513]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.83      0.62      0.71      8493\n",
      "    Neutral       0.44      0.59      0.51      3142\n",
      "   Positive       0.46      0.68      0.55      2236\n",
      "\n",
      "avg / total       0.68      0.63      0.64     13871\n",
      "\n",
      "\n",
      "0.796698147214\n",
      "   Neg  Neu  Pos\n",
      "[[6605 1361  527]\n",
      " [ 445 2488  209]\n",
      " [ 134  144 1958]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.92      0.78      0.84      8493\n",
      "    Neutral       0.62      0.79      0.70      3142\n",
      "   Positive       0.73      0.88      0.79      2236\n",
      "\n",
      "avg / total       0.82      0.80      0.80     13871\n",
      "\n",
      "\n",
      "0.711196020474\n",
      "   Neg  Neu  Pos\n",
      "[[5826 1940  727]\n",
      " [ 648 2223  271]\n",
      " [ 178  242 1816]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.88      0.69      0.77      8493\n",
      "    Neutral       0.50      0.71      0.59      3142\n",
      "   Positive       0.65      0.81      0.72      2236\n",
      "\n",
      "avg / total       0.75      0.71      0.72     13871\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply classifiers to the whole (not sampled) dataset and look at the confusion matrix and classification report for each.\n",
    "\n",
    "# Format the whole dataset.\n",
    "X_all = df[clean_text].values\n",
    "y_all = df[label_field].values\n",
    "print type(X)\n",
    "\n",
    "# Create feature vectors from the tweets. Use the same feature vector as above.\n",
    "X_featurized_all = vectorizer.transform(X_all)\n",
    "\n",
    "# Generate predictions using the classifier trained on the equally sampled data.\n",
    "predicteds = []\n",
    "for classifier in classifiers:\n",
    "    predicteds.append( classifier.predict(X_featurized_all) )\n",
    "    \n",
    "for y_pred_all in predicteds:\n",
    "    print accuracy_score(y_all, y_pred_all)\n",
    "    print '   Neg ', 'Neu ', 'Pos'\n",
    "    print confusion_matrix(y_all, y_pred_all)\n",
    "    print classification_report(y_all, y_pred_all)\n",
    "    print\n",
    "\n",
    "#y_pred_all = classifier_2.predict(X_featurized_all)\n",
    "\n",
    "# Get scores.\n",
    "#print accuracy_score(y_all, y_pred_all)\n",
    "#print '   Neg ', 'Neu ', 'Pos'\n",
    "#print confusion_matrix(y_all, y_pred_all)\n",
    "#print classification_report(y_all, y_pred_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SAVE CLASSIFIERS TO DISK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now create/recreate the classifiers and featurizers to save to disk.\n",
    "# This is not written very well; it's repetitive cut & paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (24966, 9393)\n",
      "<type 'numpy.ndarray'> (24966,)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create final classifier for LinearSVC, char 3grams, 1.8 sample.\n",
    "\n",
    "# Get the desired feature vector. Sigh, if only I had used dicts from the beginning ...\n",
    "classifier_name = \"LinearSVC\"\n",
    "feature_name = \"char 3grams\"\n",
    "sample_name = \"1.8 random sample\"\n",
    "\n",
    "classifier_ix = classifier_names.index(classifier_name)\n",
    "feature_ix = feature_names.index(feature_name)\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "\n",
    "classifier = classifiers[classifier_ix]\n",
    "X_featurized = feature_vector_lists[feature_ix][sample_ix]\n",
    "y = y_samples[sample_ix]\n",
    "print type(X_featurized), X_featurized.shape\n",
    "print type(y), y.shape\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 34.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Trein classifier on the entire feature vector.\n",
    "classifier.fit(X_featurized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mclassification\u001b[m\u001b[m/                \u001b[34mdocuments\u001b[m\u001b[m/                     \u001b[34mspark-1.6.0-bin-hadoop2.4\u001b[m\u001b[m/     tweet_neo4j_2-2016-01-23.zip\r\n",
      "\u001b[34mcurl\u001b[m\u001b[m/                          \u001b[34mscala-2.11.7\u001b[m\u001b[m/                  spark-1.6.0-bin-hadoop2.4.tgz  \u001b[34mworkspace\u001b[m\u001b[m/\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/                          scala-2.11.7.tgz               \u001b[34mtarget\u001b[m\u001b[m/\r\n",
      "\u001b[34mdataCharacterization\u001b[m\u001b[m/          \u001b[34mscripts\u001b[m\u001b[m/                       \u001b[34mtweet_neo4j_2\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# Save trained classifiers to pickle files.\n",
    "\n",
    "# Find output directory.\n",
    "%ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/LinearSVC_char3grams_1.8randomsample_2016-04-29.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = classifier_name + '_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 14.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save trained classifier object to file.\n",
    "joblib.dump(classifier, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (13871, 7374)\n",
      "<type 'numpy.ndarray'> (13871,)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create final classifier for LinearSVC, char 3grams, original sample.\n",
    "\n",
    "# Get the desired feature vector. Sigh, if only I had used dicts from the beginning ...\n",
    "classifier_name = \"LinearSVC\"\n",
    "feature_name = \"char 3grams\"\n",
    "sample_name = \"original data\"\n",
    "\n",
    "classifier_ix = classifier_names.index(classifier_name)\n",
    "feature_ix = feature_names.index(feature_name)\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "\n",
    "classifier = classifiers[classifier_ix]\n",
    "X_featurized = feature_vector_lists[feature_ix][sample_ix]\n",
    "y = y_samples[sample_ix]\n",
    "print type(X_featurized), X_featurized.shape\n",
    "print type(y), y.shape\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 12.9 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Trein classifier on the entire feature vector.\n",
    "classifier.fit(X_featurized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mclassification\u001b[m\u001b[m/                \u001b[34mdocuments\u001b[m\u001b[m/                     \u001b[34mspark-1.6.0-bin-hadoop2.4\u001b[m\u001b[m/     tweet_neo4j_2-2016-01-23.zip\r\n",
      "\u001b[34mcurl\u001b[m\u001b[m/                          \u001b[34mscala-2.11.7\u001b[m\u001b[m/                  spark-1.6.0-bin-hadoop2.4.tgz  \u001b[34mworkspace\u001b[m\u001b[m/\r\n",
      "\u001b[34mdata\u001b[m\u001b[m/                          scala-2.11.7.tgz               \u001b[34mtarget\u001b[m\u001b[m/\r\n",
      "\u001b[34mdataCharacterization\u001b[m\u001b[m/          \u001b[34mscripts\u001b[m\u001b[m/                       \u001b[34mtweet_neo4j_2\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# Find output directory.\n",
    "%ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/LinearSVC_char3grams_originaldata_2016-04-28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = classifier_name + '_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 15.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save trained classifier object to file.\n",
    "joblib.dump(classifier, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (13871, 7374)\n",
      "<type 'numpy.ndarray'> (13871,)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create final classifier for Random Forest-depth 5, char 3grams, original sample.\n",
    "\n",
    "# Get the desired feature vector. Sigh, if only I had used dicts from the beginning ...\n",
    "classifier_name = \"RandomForest-d5\"\n",
    "feature_name = \"char 3grams\"\n",
    "sample_name = \"original data\"\n",
    "\n",
    "classifier_ix = classifier_names.index(classifier_name)\n",
    "feature_ix = feature_names.index(feature_name)\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "\n",
    "classifier = classifiers[classifier_ix]\n",
    "X_featurized = feature_vector_lists[feature_ix][sample_ix]\n",
    "y = y_samples[sample_ix]\n",
    "print type(X_featurized), X_featurized.shape\n",
    "print type(y), y.shape\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 929 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Trein classifier on the entire feature vector.\n",
    "classifier.fit(X_featurized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/RandomForest-d5_char3grams_originaldata_2016-04-28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = classifier_name + '_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 279 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save trained classifier object to file.\n",
    "joblib.dump(classifier, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (10401, 6746)\n",
      "<type 'numpy.ndarray'> (10401,)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Create final classifier for Random Forest, char 3grams, 0.75 random sample.\n",
    "\n",
    "# Get the desired feature vector. Sigh, if only I had used dicts from the beginning ...\n",
    "classifier_name = \"RandomForest\"\n",
    "feature_name = \"char 3grams\"\n",
    "sample_name = \"0.75 random sample\"\n",
    "\n",
    "classifier_ix = classifier_names.index(classifier_name)\n",
    "feature_ix = feature_names.index(feature_name)\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "\n",
    "classifier = classifiers[classifier_ix]\n",
    "X_featurized = feature_vector_lists[feature_ix][sample_ix]\n",
    "y = y_samples[sample_ix]\n",
    "print type(X_featurized), X_featurized.shape\n",
    "print type(y), y.shape\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 45.3 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Trein classifier on the entire feature vector.\n",
    "classifier.fit(X_featurized, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/RandomForest_char3grams_0.75randomsample_2016-04-28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = classifier_name + '_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 401 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save trained classifier object to file.\n",
    "joblib.dump(classifier, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### SAVE FEATURIZERS TO DISK ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24966,)\n"
     ]
    }
   ],
   "source": [
    "# Recreate the featurizer to save:  char 3grams, 1.8 sample.\n",
    "\n",
    "sample_name = '1.8 random sample'\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "X_sample = X_samples[sample_ix]\n",
    "\n",
    "ngram_min_size = 3\n",
    "ngram_max_size = 3\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char'  # create character ngrams\n",
    "                             )\n",
    "vectorizer.fit(X_sample)\n",
    "print X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/featurizer_char3grams_1.8randomsample_2016-04-29.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = 'featurizer_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 494 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save featurizer object to file.\n",
    "joblib.dump(vectorizer, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871,)\n"
     ]
    }
   ],
   "source": [
    "# Recreate the featurizer to save:  char 3grams, original data.\n",
    "\n",
    "sample_name = 'original data'\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "X_sample = X_samples[sample_ix]\n",
    "\n",
    "ngram_min_size = 3\n",
    "ngram_max_size = 3\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char' # create character ngrams\n",
    "                             )\n",
    "vectorizer.fit(X_sample)\n",
    "print X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/featurizer_char3grams_originaldata_2016-04-28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = 'featurizer_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 370 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save featurizer object to file.\n",
    "joblib.dump(vectorizer, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10401,)\n"
     ]
    }
   ],
   "source": [
    "# Recreate the featurizer to save:  char 3grams, 0.75 random sample.\n",
    "\n",
    "sample_name = '0.75 random sample'\n",
    "sample_ix = sample_names.index(sample_name)\n",
    "X_sample = X_samples[sample_ix]\n",
    "\n",
    "ngram_min_size = 3\n",
    "ngram_max_size = 3\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char' # create character ngrams\n",
    "                             )\n",
    "vectorizer.fit(X_sample)\n",
    "print X_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../classification/featurizer_char3grams_0.75randomsample_2016-04-28.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create file names.\n",
    "\n",
    "out_dir = '../classification/'\n",
    "outfile_name = 'featurizer_' + feature_name + '_' + sample_name + '_' + str(datetime.date.today()) + '.pkl'\n",
    "outfile_name = outfile_name.replace(' ', '')\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 1: 322 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1\n",
    "\n",
    "# Save featurizer object to file.\n",
    "joblib.dump(vectorizer, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DO NOT USE BELOW THIS POINT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize results.\n",
    "\n",
    "#df = pd.read_table(\"data.csv\",sep=\"|\")\n",
    "#grouped = df.groupby('app')['hours']\n",
    "\n",
    "title = 'TITLE'\n",
    "colors = \"rgbcmyk\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "initial_gap = 0.1\n",
    "start = initial_gap\n",
    "width = 1.0\n",
    "gap = 0.05\n",
    "\n",
    "#for app,group in grouped:\n",
    "for \n",
    "    size = group.shape[0]\n",
    "    ind = np.linspace(start,start + width, size+1)[:-1]   \n",
    "    w = (ind[1]-ind[0])\n",
    "    start = start + width + gap\n",
    "    plt.bar(ind,group,w,color=list(colors[:size]))\n",
    "\n",
    "tick_loc = (np.arange(len(grouped)) * (width+gap)) + initial_gap + width/2\n",
    "ax.set_xticklabels([app for app,_ in grouped])\n",
    "ax.xaxis.set_major_locator(mtick.FixedLocator(tick_loc))\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read classifier back in.\n",
    "# classifier = joblib.load(outfile_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning classifier LinearSVC\n",
      "   done with char 3grams\n",
      "   done with word 1- & 2grams\n",
      "   done with term freq\n",
      "   done with tfidf\n",
      "beginning classifier Logistic\n",
      "   done with char 3grams\n",
      "   done with word 1- & 2grams\n",
      "   done with term freq\n",
      "   done with tfidf\n",
      "done training and testing classifiers\n",
      "\n",
      "LinearSVC, char 3grams, original data\n",
      "0.58872294631 0.041397971201\n",
      "\n",
      "LinearSVC, char 3grams, 0.75 random sample\n",
      "0.765214793745 0.00575572887056\n",
      "\n",
      "LinearSVC, char 3grams, 1.8 random sample\n",
      "0.879196576384 0.00447410561315\n",
      "\n",
      "LinearSVC, word 1- & 2grams, original data\n",
      "0.603999992602 0.0239679891631\n",
      "\n",
      "LinearSVC, word 1- & 2grams, 0.75 random sample\n",
      "0.757136342151 0.00430706192601\n",
      "\n",
      "LinearSVC, word 1- & 2grams, 1.8 random sample\n",
      "0.869623854624 0.00539175961027\n",
      "\n",
      "LinearSVC, term freq, original data\n",
      "0.654172112618 0.0192540811024\n",
      "\n",
      "LinearSVC, term freq, 0.75 random sample\n",
      "0.702433003009 0.00358254670367\n",
      "\n",
      "LinearSVC, term freq, 1.8 random sample\n",
      "0.768886819512 0.00517943280617\n",
      "\n",
      "LinearSVC, tfidf, original data\n",
      "0.645882992068 0.0210368237765\n",
      "\n",
      "LinearSVC, tfidf, 0.75 random sample\n",
      "0.708296080054 0.0069373659961\n",
      "\n",
      "LinearSVC, tfidf, 1.8 random sample\n",
      "0.783586543274 0.00373557369036\n",
      "\n",
      "Logistic, char 3grams, original data\n",
      "0.633489424991 0.0253200466104\n",
      "\n",
      "Logistic, char 3grams, 0.75 random sample\n",
      "0.688102792714 0.0115257959508\n",
      "\n",
      "Logistic, char 3grams, 1.8 random sample\n",
      "0.765362718488 0.00878335664811\n",
      "\n",
      "Logistic, word 1- & 2grams, original data\n",
      "0.661600706355 0.0169215393058\n",
      "\n",
      "Logistic, word 1- & 2grams, 0.75 random sample\n",
      "0.69464509234 0.00610319290026\n",
      "\n",
      "Logistic, word 1- & 2grams, 1.8 random sample\n",
      "0.768967236467 0.0076475924865\n",
      "\n",
      "Logistic, term freq, original data\n",
      "0.630812208049 0.00952572357996\n",
      "\n",
      "Logistic, term freq, 0.75 random sample\n",
      "0.630802050975 0.00980252160591\n",
      "\n",
      "Logistic, term freq, 1.8 random sample\n",
      "0.643796560984 0.00471304071189\n",
      "\n",
      "Logistic, tfidf, original data\n",
      "0.630956248343 0.00694376044396\n",
      "\n",
      "Logistic, tfidf, 0.75 random sample\n",
      "0.662342513928 0.00356766756426\n",
      "\n",
      "Logistic, tfidf, 1.8 random sample\n",
      "0.685212808963 0.00707482343385\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "### OLD VERSION ###\n",
    "# Train, test, and score classifiers using crossvalidation.\n",
    "\n",
    "cv = 5  # Number of crossvalidation folds to use.\n",
    "scores = []\n",
    "score_descriptions = []\n",
    "\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    print 'beginning classifier ' + classifier_name\n",
    "    for feature_vector_list, feature_name in zip(feature_vector_lists, feature_names):\n",
    "        for X, y_sample, sample_name in zip(feature_vector_list, y_samples, sample_names):\n",
    "            scores.append( cross_validation.cross_val_score(classifier, X, y_sample, cv=cv) )\n",
    "            score_descriptions.append( classifier_name + ', ' + feature_name + ', ' + sample_name )\n",
    "        print '   done with ' + feature_name\n",
    "    #print 'done with classifier ' + classifier_name\n",
    "print 'done training and testing classifiers' \n",
    "print\n",
    "\n",
    "for score, score_description in zip(scores, score_descriptions):\n",
    "    print score_description\n",
    "    #print score\n",
    "    print score.mean(), score.std()\n",
    "    print\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65802113  0.64889529  0.65560366  0.65897066  0.63492063]\n",
      "0.651282275202\n",
      "\n",
      "[ 0.65513929  0.64457253  0.67003367  0.65897066  0.63203463]\n",
      "0.65215015532\n",
      "\n",
      "[ 0.70653218  0.69644573  0.70851371  0.69215969  0.68927369]\n",
      "0.698584999161\n",
      "\n",
      "[ 0.6364073   0.63400576  0.64165464  0.63251563  0.61519962]\n",
      "0.631956590746\n",
      "\n",
      "[ 0.7857829   0.79538905  0.8027898   0.79268879  0.77537278]\n",
      "0.79040466418\n",
      "\n",
      "[ 0.74447646  0.72910663  0.73256373  0.74266474  0.71284271]\n",
      "0.73233085625\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create classifier(s). Classify & score using crossvalidation.\n",
    "# Note that all sklearn classifiers do multiclass classification.\n",
    "# So we do not need to use sklearn.multiclass unless we want to experiment with different multiclass strategies.\n",
    "# e.g.:\n",
    "#classifiers.append( OneVsOneClassifier(LinearSVC(random_state=0)) )\n",
    "#classifiers.append( OneVsRestClassifier(LinearSVC(random_state=0)) )\n",
    "\n",
    "\n",
    "#classifiers.append( svm.SVC() )\n",
    "\n",
    "# Multinomial NaiveBayes. Commonly used for text classification.\n",
    "classifiers.append(MultinomialNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "                                 fit_prior=True))  # Fit priors based on training data\n",
    "                  \n",
    "# Bernoulli NaiveBayes. Commonly used for text classification for short documents.\n",
    "# Expects boolean features (e.g., word occurence/nonoccurence instead of term frequency or tfidf).\n",
    "classifiers.append(BernoulliNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "                               binarize=0,       # Threshold for binarizing the input features\n",
    "                               fit_prior=True))  # Fit priors based on training data\n",
    "\n",
    "# SVM with linear kernel.\n",
    "classifiers.append(LinearSVC(random_state=0)) \n",
    "\n",
    "# Logistic regression (sometimes called maxent).\n",
    "classifiers.append(SGDClassifier(loss='hinge', \n",
    "                                 penalty='l2', \n",
    "                                 alpha=1e-3, \n",
    "                                 n_iter=5, \n",
    "                                 random_state=0))\n",
    "\n",
    "# RandomForest.\n",
    "classifiers.append(RandomForestClassifier(n_estimators = 100))  # Number of decision stumps to use in the ensemble\n",
    "\n",
    "# AdaBoost with decision stumps.\n",
    "classifiers.append( AdaBoostClassifier(\n",
    "        #BernoulliNB(alpha=1.0, binarize=0, fit_prior=True),  # Use BernoulliNB as the weak estimators\n",
    "        DecisionTreeClassifier(max_depth=2),   # Use decision tree stumps as the weak estimators\n",
    "        n_estimators=600,    # The max number of estimators at which boosting is terminated\n",
    "        learning_rate=1) )   # By how much to shrink the contribution of each (successive?) estimator\n",
    "                             # By default, AdaBoost uses estimated class probabilities, not boolean class values\n",
    " \n",
    "#classifiers.append( AdaBoostClassifier( \n",
    "#            DecisionTreeClassifier(max_depth=2),\n",
    "#            n_estimators=600,\n",
    "#            learning_rate=1.5,\n",
    "#            algorithm=\"SAMME\") )  # Use boolean class values instead of estimated class probabilities\n",
    "\n",
    "#classifiers.append( AdaBoostClassifier( \n",
    "#            DecisionTreeClassifier(max_depth=2),\n",
    "#            n_estimators=600,\n",
    "#            learning_rate=1.5,\n",
    "#            algorithm=\"SAMME\") )  # Use boolean class values instead of estimated class probabilities\n",
    "\n",
    "\n",
    "cv = 5  # Number of crossvalidation folds to use.\n",
    "scores = []\n",
    "\n",
    "for classifier in classifiers:\n",
    "    scores.append( cross_validation.cross_val_score(classifier, X_featurized, y, cv=cv) )\n",
    "    \n",
    "for score in scores:\n",
    "    print score\n",
    "    print score.mean()\n",
    "    print\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into training & test sets.\n",
    "# The KFold function returns lists of indices to use for the splits.\n",
    "\n",
    "kf = KFold(len(X_selected), n_folds=10, shuffle=True, random_state=0)\n",
    "print type(kf)\n",
    "\n",
    "for train, test in kf:\n",
    "    #print(\"%s %s\" % (train.shape, test.shape))\n",
    "    print train\n",
    "    print test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create feature vectors.\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf=True,\n",
    "                             use_idf=True)\n",
    "train_vectors = vectorizer.fit_transform(train_data)\n",
    "test_vectors = vectorizer.transform(test_data)\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use basic linear regression.\n",
    "# Estimate error using 10-fold cross validation.\n",
    "\n",
    "clf = sklearn.linear_model.LinearRegression()\n",
    "scores = sklearn.cross_validation.cross_val_score(clf, X_selected, y, cv=10)\n",
    "print scores\n",
    "print scores.mean()\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Perform classification with SVM, kernel=rbf.\n",
    "# Get the time needed for training and for classification.\n",
    "\n",
    "classifier_rbf = svm.SVC()\n",
    "\n",
    "t0 = time.time()\n",
    "classifier_rbf.fit(train_vectors, train_labels)\n",
    "t1 = time.time()\n",
    "\n",
    "prediction_rbf = classifier_rbf.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_rbf_train = t1-t0\n",
    "time_rbf_predict = t2-t1\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at the confusion matrix.\n",
    "\n",
    "train_pred = clf.predict(X_train)\n",
    "print iris.target_names\n",
    "confusion_matrix(y_train, train_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Return df containing 'fraction' fraction of the original df,\n",
    "# with equal representation by the value in column 'col'.\n",
    "# Don't use this function.\n",
    "def get_equal_samples_dumb(df, col, fraction):\n",
    "    #vals = pd.unique(df[col].values.ravel())\n",
    "    #print type(vals)\n",
    "    #print \"vals=\", vals\n",
    "    #vals.sort()\n",
    "    \n",
    "    weight_col = 'my_temp_weight'\n",
    "    \n",
    "    denom = df.shape[0]\n",
    "    val_counts = df[col].value_counts()\n",
    "    val_weights_dict = {}\n",
    "    for val in val_counts.keys():\n",
    "        val_weights_dict[val] = (val_counts[val] / float(denom))\n",
    "    print val_weights_dict\n",
    "  \n",
    "    df[weight_col] = df[col]\n",
    "    #df[weight_col].replace({ 'pos':'Positive', 'neg':'Negative' }, inplace=True)\n",
    "    df[weight_col].replace(val_weights_dict, inplace=True)\n",
    "    \n",
    "    df_sampled = df.sample(frac=fraction, weight=df[weight_col])\n",
    "    \n",
    "    df_sampled.drop(weight_col, axis=1, inplace=True)\n",
    "    \n",
    "    return df_sampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13871, 23)\n"
     ]
    }
   ],
   "source": [
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
