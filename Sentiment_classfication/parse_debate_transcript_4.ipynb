{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:  Script for loading debate transcript.\n",
    "Author:  Carol Sniegoski\n",
    "Date:  April 12, 2016\n",
    "Course:  DSE MAS Capstone, Spring 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Return line with all misspelled instances of the correct_words replaced with the correct_word.\n",
    "# Here we define a misspelling as missing one letter other than the first or last letter in a word.\n",
    "# Case insensitive.\n",
    "def correct_spellings(line, correct_words):\n",
    "    \n",
    "    for correct_word in correct_words:\n",
    "        word_len = len(correct_word)\n",
    "        for i in range(1,word_len-1):\n",
    "            \n",
    "            # Create the misspelled version of the word to look for.\n",
    "            missp = correct_word[0:i]+correct_word[i+1:word_len]\n",
    "            \n",
    "            # Do a case-insensitive replacement.\n",
    "            #test_string.replace(missp, correct_word)\n",
    "            pattern = re.compile(missp, re.IGNORECASE)\n",
    "            line = pattern.sub(correct_word, line) \n",
    "            \n",
    "    # Fixing the \"O'Malley\" spelling variations.\n",
    "    line = line.replace(\"â€™\", \"'\")\n",
    "    line = line.replace(\"O' \", \"O'\")\n",
    "    \n",
    "    return line\n",
    "\n",
    "        \n",
    "# Return list of text chunks, each starting with either the beginning of the line\n",
    "# or a new speaker or audience event.\n",
    "def get_splits_by_speaker(line, candidates, moderators, audience):\n",
    "    return_list = []\n",
    "    \n",
    "    # Get splits for each speaker type. Unfortunately they are all handled slightly differently.\n",
    "    splits = get_candidate_splits(line, candidates) + get_moderator_splits(line, moderators) + get_audience_splits(line, audience)\n",
    "\n",
    "    # Sort list of tuples by 3rd element, which is the start index in the line.\n",
    "    splits.sort(key=lambda x: x[2])\n",
    "    \n",
    "    # Use indices to split line into text chunks.\n",
    "\n",
    "    # If there are no indices, just return the line, with speaker unknown.\n",
    "    if len(splits)==0:\n",
    "        return_list = [ ('', '', line) ]\n",
    "        return return_list\n",
    "    \n",
    "    # If the first entry does not start at index zero, add an initial text chunk with speaker unknown.\n",
    "    if splits[0][2]!=0:\n",
    "        return_list.append( ('', '', line[0:splits[0][2]]) )\n",
    "    \n",
    "    # Add the rest of the text chunks.\n",
    "    #ix_end = len(line)\n",
    "    for i in range(len(splits)):\n",
    "        ix_start = splits[i][2]\n",
    "        speaker_name = splits[i][0]\n",
    "        speaker_type = splits[i][1]\n",
    "        try:\n",
    "            ix_end = splits[i+1][2]\n",
    "        except:\n",
    "            ix_end = len(line)\n",
    "        return_list.append( ( speaker_name, speaker_type, line[ix_start:ix_end] )  )\n",
    "    \n",
    "    # Discard text chunks with no content but whitespace.\n",
    "    return_list = filter(lambda x: len(x[2].strip())>0, return_list)\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split before.\n",
    "def get_candidate_splits(line, candidates):\n",
    "    return_list = []\n",
    "    \n",
    "    pattern = '(' + '|'.join(candidates) + '):'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    matched = compiled_pattern.finditer(line)\n",
    "\n",
    "    for m in matched:\n",
    "        #print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "        return_list.append( (m.group(1), 'candidate', m.start()) )\n",
    "\n",
    "    #print 'get_candidate_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split before.\n",
    "def get_moderator_splits(line, moderators):\n",
    "    return_list = []\n",
    "    \n",
    "    #pattern = '(' + '|'.join(moderators) + '):'\n",
    "    pattern = '(' + '|'.join(moderators) + ')' + '(?: *\\[[a-z ]*\\])?:'\n",
    "    #compiled_pattern = re.compile(\"(ramos|salinas)(?:\\[[a-z ]*\\])?:\", re.IGNORECASE)\n",
    "    \n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "\n",
    "    for m in matched:\n",
    "        #print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "        return_list.append( (m.group(1), 'moderator', m.start()) )\n",
    "    \n",
    "    # Discard splits with no name or body.\n",
    "    return_list = filter(lambda x: len(x[0])>0, return_list)\n",
    "    \n",
    "    #print 'get_moderator_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split both before and after.\n",
    "def get_audience_splits(line, audience):\n",
    "    return_list = []\n",
    "    \n",
    "    # First split before.\n",
    "    pattern = '[\\(\\[](' + '|'.join(audience) + ')'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "    for m in matched:\n",
    "        return_list.append( (m.group(1), 'audience', m.start()) )\n",
    "        \n",
    "    # Then split after.\n",
    "    pattern = '(' + '|'.join(audience) + ')[\\)\\]]'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "    for m in matched:\n",
    "        if (m.end() != len(line)):\n",
    "            return_list.append( ('', '', m.end()) ) \n",
    "\n",
    "    #print 'get_audience_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Add line to dataframe.\n",
    "def add_line(speaker, speaker_type, speech, start_time, duration, rows_list):\n",
    "    #print '**add_line(): speaker=' + speaker + ', speaker_type=' + speaker_type + ', text=' + speech\n",
    "    dict = {'speaker':speaker, 'speaker_type':speaker_type, 'text':speech, 'start_time':start_time, 'duration':duration}\n",
    "    rows_list.append(dict)\n",
    "    \n",
    "# Return list of last names of candidates in this debate\n",
    "def get_candidates(cstr):\n",
    "    returnlist = [s.strip() for s in cstr.split(',')]\n",
    "    returnlist = [s.upper().split(' ')[1] for s in returnlist]\n",
    "    return returnlist\n",
    "\n",
    "# Return list of last names of moderators of this debate\n",
    "def get_moderators(mstr):\n",
    "    returnlist = [s.strip() for s in mstr.split(',')]\n",
    "    #returnlist = [s.upper().split(' ')[1] for s in returnlist]\n",
    "    returnlist = [s.upper().split(' ') for s in returnlist]\n",
    "    returnlist = [s[len(s)-1] for s in returnlist]\n",
    "    return returnlist\n",
    "\n",
    "# Return list of audience events\n",
    "def get_audience():\n",
    "    returnlist = ['APPLAUSE', 'BOOING', 'CHEERING', 'LAUGHTER']\n",
    "    return returnlist\n",
    "\n",
    "# Return map of strings for event name, date, party, location, start_time, end_time, duration\n",
    "def get_event_info():\n",
    "    returnmap = {}\n",
    "    return returnmap\n",
    "\n",
    "# Generate the conventional infile name for this debate.\n",
    "def get_infilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '.txt'\n",
    "    return returnstr\n",
    "\n",
    "# Generate the conentional outfile name for this debate.\n",
    "def get_outfilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '_proc.csv'\n",
    "    return returnstr\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BLITZER', 'moderator', \"BLITZER: We're live here at the University of Houston for the 10th Republican presidential debate. \"), ('applause', 'audience', '(applause)')]\n"
     ]
    }
   ],
   "source": [
    "testline = \"BLITZER: We're live here at the University of Houston for the 10th Republican presidential debate. (applause)\"\n",
    "\n",
    "get_audience_splits(testline, ['APPLAUSE', 'LAUGHTER'])\n",
    "result = get_splits_by_speaker(testline, ['TRUMP'],['BLITZER'],['APPLAUSE', 'LAUGHTER'])\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function def\n",
    "\n",
    "# Load and parse a text file representing a debate transcript. \n",
    "# Assume the debate candidates, moderators, and audience evets are as provided.\n",
    "# Write results to csv.\n",
    "\n",
    "def process_transcript(infilename, outfilename, candidates, moderators, audience):\n",
    "    rows_list = []\n",
    "    #with open('transcript_v2.txt') as infile:\n",
    "    with open(infilename) as infile:\n",
    "        speaker=\"\"\n",
    "        speaker_type=\"\"\n",
    "        speech=\"\"\n",
    "        time=0\n",
    "        #overlap_time=0\n",
    "        \n",
    "        #threshold = 20\n",
    "        #i = 0\n",
    "        for line in infile:\n",
    "            \n",
    "            #i+=1;\n",
    "            #if (i>threshold):\n",
    "            #    break\n",
    "            \n",
    "            line = line.strip()\n",
    "            line = correct_spellings(line, [x+':' for x in candidates+moderators+audience])\n",
    "            if len(line)==0:\n",
    "                continue\n",
    "            \n",
    "            # Split line into chunks, each from a single speaker, of format (speaker, speaker_type, speech).\n",
    "            splits = get_splits_by_speaker(line, candidates=candidates, moderators=moderators, audience=audience) \n",
    "            #print 'splits=', splits\n",
    "            \n",
    "            for split in splits:\n",
    "                #print 'split=', split\n",
    "                \n",
    "                new_speaker = split[0]\n",
    "                new_speaker_type = split[1]\n",
    "                new_speech = split[2]\n",
    "                \n",
    "                # Audience event, e.g. \"(laughter, applause)\".\n",
    "                # Do not change the speaker or end the current speech.\n",
    "                # Add one or more audience events with appropriate timing estimates.\n",
    "                if (new_speaker_type=='audience'):\n",
    "                    for event in audience:\n",
    "                        est_duration=50\n",
    "                        if event.lower() in new_speech.lower():\n",
    "                            add_line(event, \"audience\", new_speech, time+len(speech), est_duration, rows_list)  \n",
    "                \n",
    "                # No change of speaker.\n",
    "                # Just continue to accumulate the current speech text.\n",
    "                elif ( (new_speaker=='') | (new_speaker==speaker) ):\n",
    "                    speech+= (' ' + new_speech.strip())\n",
    "                \n",
    "                # Change of speaker, e.g. \"TRUMP: Blah.\"\n",
    "                # Cut off the current speech and add it to the results list.\n",
    "                # Change speaker and speaker type. Begin accumulating the next speech.\n",
    "                elif (new_speaker!=speaker):\n",
    "                   \n",
    "                    # Cut off the previous speech and add it to the df.\n",
    "                    add_line(speaker, speaker_type, speech, time, len(speech), rows_list)\n",
    "                   \n",
    "                    # Begin the next speech.\n",
    "                    time += len(speech)\n",
    "                    overlap_time = 0\n",
    "                    speech = new_speech\n",
    "                    speaker = new_speaker\n",
    "                    speaker_type = new_speaker_type\n",
    "                    \n",
    "                else:\n",
    "                    print \"ERROR! No line type recognized for split\", split\n",
    "                    \n",
    "        add_line(speaker, speaker_type, speech, time, len(speech), rows_list)\n",
    "       \n",
    "    # Now create the dataframe & write it to csv.\n",
    "    df = pd.DataFrame(rows_list[1:]) \n",
    "    df.to_csv(outfilename)\n",
    "    print 'done processing file ', infilename, '; shape=', df.shape, '; results written to file ', outfilename\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1.txt                    D8_proc.csv               R4_proc.csv\n",
      "D1_proc.csv               D9.txt                    R5.txt\n",
      "D2.txt                    R1.txt                    R5_proc.csv\n",
      "D2_proc.csv               R10.txt                   R6.txt\n",
      "D3.txt                    R10_proc.csv              R6_proc.csv\n",
      "D3_proc.csv               R11.txt                   R7.txt\n",
      "D4.txt                    R11_proc.csv              R7_proc.csv\n",
      "D4_proc.csv               R12.txt                   R8.txt\n",
      "D5.txt                    R12_proc.csv              R8_proc.csv\n",
      "D5_proc.csv               R1_proc.csv               R9.txt\n",
      "D6.txt                    R2.txt                    R9_proc.csv\n",
      "D6_proc.csv               R2_proc.csv               debateTranscripts.tar.gz\n",
      "D7.txt                    R3.txt                    \u001b[34mlabeled_transcripts\u001b[m\u001b[m/\n",
      "D7_proc.csv               R3_proc.csv               transcript_test.txt\n",
      "D8.txt                    R4.txt\n",
      "\n",
      "\u001b[34mKaggle_1stGOPDebateTweets\u001b[m\u001b[m/\n",
      "\u001b[34mKaggle_PrimaryResults2016\u001b[m\u001b[m/\n",
      "Transcript-R1_topTokensByTopic_04-08-16.csv\n",
      "bing-liu_opinion-lexicon-English_d04-13-16.rar\n",
      "\u001b[34mcyberbullying\u001b[m\u001b[m/\n",
      "debate08_sentiment_tweets.tsv\n",
      "debate08_sentiment_tweets.tsv.zip\n",
      "\u001b[34mdebateTranscripts\u001b[m\u001b[m/\n",
      "election-sample\n",
      "hashtags-Debbie.csv\n",
      "opinion-lexicon-English.rar\n",
      "sanders-twitter-0.2.zip\n",
      "\u001b[34mslices\u001b[m\u001b[m/\n",
      "transcript_forGantt_v3.csv\n",
      "\u001b[34munifiedCalendar_03-26-16\u001b[m\u001b[m/\n",
      "unifiedCalendar_03-26-16.csv\n",
      "unifiedCalendar_04-26-16.csv\n",
      "unifiedCalendar_DebatesAndPrimaries.csv\n"
     ]
    }
   ],
   "source": [
    "# Locate the data.\n",
    "%ls ../data/debateTranscripts/\n",
    "print\n",
    "%ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the schedule of debates and primaries.\n",
    "df_dp = pd.read_csv(\"../data/unifiedCalendar_04-26-16.csv\")\n",
    "#df_dp.head(2)\n",
    "#print type(df_dp[\"Candidates\"][0])\n",
    "\n",
    "# Get only entries for EventType 'debate'.\n",
    "df_dp = df_dp[df_dp['EventType']=='debate']\n",
    "df_dp.head(2)\n",
    "print df_dp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../data/debateTranscripts/R1.txt ../data/debateTranscripts/R1_proc.csv ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH'] ['BAIER', 'KELLY', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R1.txt ; shape= (417, 5) ; results written to file  ../data/debateTranscripts/R1_proc.csv\n",
      "\n",
      "1 ../data/debateTranscripts/D1.txt ../data/debateTranscripts/D1_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\", 'WEBB', 'CHAFEE'] ['COOPER', 'BASH', 'LOPEZ']\n",
      "done processing file  ../data/debateTranscripts/D1.txt ; shape= (530, 5) ; results written to file  ../data/debateTranscripts/D1_proc.csv\n",
      "\n",
      "2 ../data/debateTranscripts/R2.txt ../data/debateTranscripts/R2_proc.csv ['TRUMP', 'CARSON', 'BUSH', 'CRUZ', 'WALKER', 'RUBIO', 'FIORINA', 'HUCKABEE', 'PAUL', 'KASICH', 'CHRISTIE'] ['TAPPER', 'HEWITT', 'BASH']\n",
      "done processing file  ../data/debateTranscripts/R2.txt ; shape= (794, 5) ; results written to file  ../data/debateTranscripts/R2_proc.csv\n",
      "\n",
      "3 ../data/debateTranscripts/D2.txt ../data/debateTranscripts/D2_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['DICKERSON', 'CORDES', 'COONEY', 'OBRADOVICH']\n",
      "done processing file  ../data/debateTranscripts/D2.txt ; shape= (286, 5) ; results written to file  ../data/debateTranscripts/D2_proc.csv\n",
      "\n",
      "4 ../data/debateTranscripts/R3.txt ../data/debateTranscripts/R3_proc.csv ['TRUMP', 'CARSON', 'BUSH', 'RUBIO', 'CRUZ', 'HUCKABEE', 'PAUL', 'FIORINA', 'CHRISTIE', 'KASICH'] ['QUINTANILLA', 'QUICK', 'HARWOOD']\n",
      "done processing file  ../data/debateTranscripts/R3.txt ; shape= (485, 5) ; results written to file  ../data/debateTranscripts/R3_proc.csv\n",
      "\n",
      "5 ../data/debateTranscripts/D3.txt ../data/debateTranscripts/D3_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['MUIR', 'RADDATZ', 'LEVESQUE', 'MCELVEEN']\n",
      "done processing file  ../data/debateTranscripts/D3.txt ; shape= (357, 5) ; results written to file  ../data/debateTranscripts/D3_proc.csv\n",
      "\n",
      "6 ../data/debateTranscripts/R4.txt ../data/debateTranscripts/R4_proc.csv ['TRUMP', 'CARSON', 'RUBIO', 'CRUZ', 'BUSH', 'FIORINA', 'KASICH', 'PAUL'] ['BAKER', 'CAVUTO', 'BARTIROMO']\n",
      "done processing file  ../data/debateTranscripts/R4.txt ; shape= (398, 5) ; results written to file  ../data/debateTranscripts/R4_proc.csv\n",
      "\n",
      "7 ../data/debateTranscripts/D4.txt ../data/debateTranscripts/D4_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['HOLT', 'MITCHELL']\n",
      "done processing file  ../data/debateTranscripts/D4.txt ; shape= (359, 5) ; results written to file  ../data/debateTranscripts/D4_proc.csv\n",
      "\n",
      "8 ../data/debateTranscripts/R5.txt ../data/debateTranscripts/R5_proc.csv ['TRUMP', 'CARSON', 'CRUZ', 'RUBIO', 'BUSH', 'FIORINA', 'CHRISTIE', 'KASICH', 'PAUL'] ['BLITZER', 'BASH', 'HEWITT']\n",
      "done processing file  ../data/debateTranscripts/R5.txt ; shape= (450, 5) ; results written to file  ../data/debateTranscripts/R5_proc.csv\n",
      "\n",
      "9 ../data/debateTranscripts/D5.txt ../data/debateTranscripts/D5_proc.csv ['CLINTON', 'SANDERS'] ['TODD', 'MADDOW']\n",
      "done processing file  ../data/debateTranscripts/D5.txt ; shape= (309, 5) ; results written to file  ../data/debateTranscripts/D5_proc.csv\n",
      "\n",
      "10 ../data/debateTranscripts/R6.txt ../data/debateTranscripts/R6_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'CHRISTIE', 'BUSH', 'KASICH'] ['CAVUTO', 'BARTIROMO']\n",
      "done processing file  ../data/debateTranscripts/R6.txt ; shape= (400, 5) ; results written to file  ../data/debateTranscripts/R6_proc.csv\n",
      "\n",
      "11 ../data/debateTranscripts/D6.txt ../data/debateTranscripts/D6_proc.csv ['CLINTON', 'SANDERS'] ['IFILL', 'WOODRUFF']\n",
      "done processing file  ../data/debateTranscripts/D6.txt ; shape= (211, 5) ; results written to file  ../data/debateTranscripts/D6_proc.csv\n",
      "\n",
      "12 ../data/debateTranscripts/R7.txt ../data/debateTranscripts/R7_proc.csv ['CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH', 'PAUL'] ['BAIER', 'KELLY', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R7.txt ; shape= (401, 5) ; results written to file  ../data/debateTranscripts/R7_proc.csv\n",
      "\n",
      "13 ../data/debateTranscripts/D7.txt ../data/debateTranscripts/D7_proc.csv ['CLINTON', 'SANDERS'] ['COOPER', 'LEMON']\n",
      "done processing file  ../data/debateTranscripts/D7.txt ; shape= (356, 5) ; results written to file  ../data/debateTranscripts/D7_proc.csv\n",
      "\n",
      "14 ../data/debateTranscripts/R8.txt ../data/debateTranscripts/R8_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH'] ['MUIR', 'RADDATZ']\n",
      "done processing file  ../data/debateTranscripts/R8.txt ; shape= (464, 5) ; results written to file  ../data/debateTranscripts/R8_proc.csv\n",
      "\n",
      "15 ../data/debateTranscripts/D8.txt ../data/debateTranscripts/D8_proc.csv ['CLINTON', 'SANDERS'] ['SALINAS', 'RAMOS', 'TUMULTY']\n",
      "done processing file  ../data/debateTranscripts/D8.txt ; shape= (371, 5) ; results written to file  ../data/debateTranscripts/D8_proc.csv\n",
      "\n",
      "16 ../data/debateTranscripts/R9.txt ../data/debateTranscripts/R9_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'BUSH', 'CARSON', 'KASICH'] ['DICKERSON', 'GARRETT', 'STRASSEL']\n",
      "done processing file  ../data/debateTranscripts/R9.txt ; shape= (439, 5) ; results written to file  ../data/debateTranscripts/R9_proc.csv\n",
      "\n",
      "17 ../data/debateTranscripts/R10.txt ../data/debateTranscripts/R10_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH', 'CARSON'] ['BLITZER', 'ARRARAS', 'HEWITT', 'BASH']\n",
      "done processing file  ../data/debateTranscripts/R10.txt ; shape= (627, 5) ; results written to file  ../data/debateTranscripts/R10_proc.csv\n",
      "\n",
      "18 ../data/debateTranscripts/R11.txt ../data/debateTranscripts/R11_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH'] ['KELLY', 'BAIER', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R11.txt ; shape= (608, 5) ; results written to file  ../data/debateTranscripts/R11_proc.csv\n",
      "\n",
      "19 ../data/debateTranscripts/R12.txt ../data/debateTranscripts/R12_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH'] ['TAPPER', 'BASH', 'HEWITT', 'DINAN']\n",
      "done processing file  ../data/debateTranscripts/R12.txt ; shape= (315, 5) ; results written to file  ../data/debateTranscripts/R12_proc.csv\n",
      "\n",
      "21 ../data/debateTranscripts/D9.txt ../data/debateTranscripts/D9_proc.csv ['CLINTON', 'SANDERS'] ['BLITZER', 'BASH', 'LOUIS']\n",
      "done processing file  ../data/debateTranscripts/D9.txt ; shape= (595, 5) ; results written to file  ../data/debateTranscripts/D9_proc.csv\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Process the transcripts for all debates included in the schedule.\n",
    "\n",
    "#for row in df_dp.itertuples():\n",
    "#    print row.EventType\n",
    "\n",
    "#limit = 1\n",
    "#i = 0\n",
    "for ix, row in df_dp.iterrows():\n",
    "    #i+=1;\n",
    "    #if (i>limit):\n",
    "    #    break\n",
    "        \n",
    "    #print ix, row['EventType']\n",
    "    \n",
    "    prefix = '../data/debateTranscripts/'\n",
    "    if (row['Candidates']==\"CANCELLED\"):\n",
    "        continue\n",
    "    \n",
    "    candidates = get_candidates(row['Candidates'])\n",
    "    moderators = get_moderators(row['Moderators'])\n",
    "    audience = get_audience()\n",
    "    \n",
    "    infilename = prefix + get_infilename(row)\n",
    "    outfilename = prefix + get_outfilename(row)\n",
    "    \n",
    "    print ix, infilename, outfilename, candidates, moderators\n",
    "    #print\n",
    "    process_transcript(infilename, outfilename, candidates, moderators, audience)\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DO NOT USE BELOW THIS POINT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', '', 'blah '), ('TRUMP', 'candidate', 'TRUMP: blah. '), ('applause', 'audience', '(applause)'), ('CRUZ', 'candidate', 'CRUZ: blah '), ('applause', 'audience', '(applause, laughter)'), ('', '', ' blah')]\n"
     ]
    }
   ],
   "source": [
    "testline = \"blah TRUMP: blah. (applause) CRUZ: blah (applause, laughter) blah\"\n",
    "audience = ['APPLAUSE', 'BOOING', 'CHEERING', 'LAUGHTER']\n",
    "candidates = ['TRUMP', 'CRUZ', 'CARSON']\n",
    "#print get_candidate_splits(testline, candidates)\n",
    "print get_splits_by_speaker(testline, candidates, [], audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\n"
     ]
    }
   ],
   "source": [
    "teststring = ' '\n",
    "print '\"' + teststring.strip() + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TRUMP|CARSON|CRUZ):\n"
     ]
    }
   ],
   "source": [
    "testlist = ['TRUMP', 'CARSON', 'CRUZ']\n",
    "pattern = '(' + '|'.join(testlist) + '):'\n",
    "print pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['applause']\n",
      "<callable-iterator object at 0x1068e1190>\n",
      "group=\"applause\" 18 27\n",
      "[('applause', 'candidate', 18)]\n",
      "[('applause', 'candidate', 'Ramos [fsd]: blah '), '[applause] blah']\n"
     ]
    }
   ],
   "source": [
    "#testline = \"Trump: blah about Carson. [applause] Trump: blah. Carson: blah. (applause)\"\n",
    "#testline = \"blah (applause) talking. (applause) More text. (applause)\"\n",
    "testline = \"Ramos [fsd]: blah [applause] blah\"\n",
    "\n",
    "#pattern = r\"(?i)trump\"  # Also works (like cypher).\n",
    "#pattern = r\"(trump|carson)\"\n",
    "#matched = re.findall(pattern, testline, re.IGNORECASE)\n",
    "#print matched\n",
    "\n",
    "#compiled_pattern = re.compile(\"(?=(trump|carson):)\", re.IGNORECASE)\n",
    "#compiled_pattern = re.compile(\"(trump|carson):\", re.IGNORECASE)\n",
    "compiled_pattern = re.compile(\"[\\[\\(](applause|booing)\", re.IGNORECASE)\n",
    "#compiled_pattern = re.compile(\"(ramos|salinas)(?: *\\[[a-z ]*\\])?:\", re.IGNORECASE)\n",
    "\n",
    "matched = compiled_pattern.findall(testline)\n",
    "print matched  # findall returns a list of strings\n",
    "\n",
    "matched = compiled_pattern.finditer(testline)\n",
    "print matched  # finditer returns an iterator over match objects\n",
    "\n",
    "splits = []\n",
    "for m in matched:\n",
    "    print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "    splits.append( (m.group(1), 'candidate', m.start()) )\n",
    "print splits\n",
    "\n",
    "# Good for candidate, moderator\n",
    "chunks = []\n",
    "ix_end = 0\n",
    "for split in splits:\n",
    "    ix_start = ix_end\n",
    "    ix_end = split[2]\n",
    "    speaker_name = split[0]\n",
    "    speaker_type = split[1]\n",
    "    chunks.append( ( speaker_name, speaker_type, testline[ix_start:ix_end] )  )\n",
    "chunks.append( testline[ix_end:len(testline)] )\n",
    "    \n",
    "print chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Debate names.\n",
    "candidates = ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH', 'CROSSTALK', 'UNKNOWN']\n",
    "moderators = ['KELLY', 'BAIER', 'WALLACE']\n",
    "audience = ['APPLAUSE', 'BOOING', 'LAUGHTER', 'CHEERING']\n",
    "print 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits= [0]\n",
      "['', 'Trump: blah blah. Trump: blah.']\n"
     ]
    }
   ],
   "source": [
    "\"xxxxABCDyyyy\".find(\"ABC\")\n",
    "\n",
    "#testline = \"blah CARSON: blah. Trump: Blah blah (Laughter, booing, applause) More txt\"\n",
    "testline = \"Trump: blah blah. Trump: blah.\"\n",
    "#testline = \"blah (applause) talking. (applause) More text. (applause)\"\n",
    "splits = []\n",
    "#print filter(lambda x: x>=0, map(testline.lower().find, map(str.lower, candidates)))\n",
    "splits = filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: y.lower()+':', candidates+moderators)))\n",
    "#splits += filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: '('+y.lower(), audience)))\n",
    "#splits += filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: y.lower()+')', audience)))\n",
    "#splits += map(lambda x: len(testline)-len(x[0]), map(testline.lower().split, map(lambda y: y.lower()+')', audience)))\n",
    "#splits += filter(lambda x: x>0, map(lambda x: len(testline)-len(x[0]), map(testline.lower().split, map(lambda y: y.lower()+')', audience))))\n",
    "#splits += map(lambda z: len(testline)-len(z[1]), \n",
    "#              filter(lambda x: len(x)>1, \n",
    "#                     map(testline.lower().split, \n",
    "#                         map(lambda y: y.lower()+')', audience))))\n",
    "splits += filter(lambda z: len(z)>1, [testline.split(x) for x in [y.lower()+')' for y in audience]])\n",
    "\n",
    "#splits += map(testline.lower().split, map(lambda y: y.lower()+')', audience))\n",
    "#splits += filter(lambda z: len(z)>1, map(testline.lower().split, map(lambda y: y.lower()+')', audience)))\n",
    "\n",
    "splits.sort()\n",
    "print 'splits=', splits\n",
    "\n",
    "#c = [(m.start(), m.end()-1) for m in re.finditer(r'\\S+', a)]\n",
    "chunks = []\n",
    "ix_end = 0\n",
    "for ix in splits:\n",
    "    ix_start = ix_end\n",
    "    ix_end = ix\n",
    "    chunks.append( testline[ix_start:ix_end] )\n",
    "chunks.append( testline[ix_end:len(testline)] )\n",
    "    \n",
    "print chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRUMP']\n",
      "['BOOING', 'LAUGHTER', 'booing', 'laughter']\n",
      "['TRUMP', 'BOOING', 'LAUGHTER', 'booing', 'laughter']\n"
     ]
    }
   ],
   "source": [
    "testline = \"blah CARSON: blah. TRUMP: Blah blah (Laughter, booing)\"\n",
    "print filter(lambda x: x.lower()+':' in testline.lower(), candidates+moderators)\n",
    "print filter(lambda x: x.lower() in testline.lower(), audience)\n",
    "print ( filter(lambda x: x.lower()+':' in testline.lower(), candidates+moderators) + \n",
    "       filter(lambda x: x.lower() in testline.lower(), audience) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testline = \"TRUMP: Blah blah\"\n",
    "reduce(lambda x,y: x or y, map(testline.startswith, candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#testline = \"TRUMP: I will not make the pledge at this time.\"\n",
    "testline = \"(LAUGHTER, BOOING)\"\n",
    "print is_new_speaker(testline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, speaker, speaker_type, time, duration, topic]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for debate info.\n",
    "#cols = ['text', 'speaker', 'speaker_type', 'time', 'duration', 'topic']\n",
    "#df = pd.DataFrame(columns=cols)\n",
    "#df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.tail(10)\n",
    "df.to_csv(\"transcript_v2_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP: I will not make the pledge at this time. 47\n",
      "new_speaker!\n",
      "BAIER: OK. Alright. 19\n",
      "new_speaker!\n",
      "Enough. 7\n",
      "no new speaker\n",
      "KELLY: Gentlemen, our first round of questions is on the subject of electability in the general election. 105\n",
      "new_speaker!\n",
      "and we start tonight with you, Dr. Carson. 42\n",
      "no new speaker\n"
     ]
    }
   ],
   "source": [
    "with open('transcript_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if len(line)==0:\n",
    "            continue\n",
    "        print line, len(line)\n",
    "        if is_new_speaker(line):\n",
    "            print \"new_speaker!\"\n",
    "        else:\n",
    "            print \"no new speaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "test_list = [4,6,3]\n",
    "test_list.sort()\n",
    "print test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP 5\n",
      "TUMP\n",
      "TRMP\n",
      "TRUP\n",
      "CARSON 6\n",
      "CRSON\n",
      "CASON\n",
      "CARON\n",
      "CARSN\n",
      "WALLACE 7\n",
      "WLLACE\n",
      "WALACE\n",
      "WALACE\n",
      "WALLCE\n",
      "WALLAE\n",
      "TRUMP: blah. CARSON: blah. Trump: blah. WALLACE: blah\n"
     ]
    }
   ],
   "source": [
    "correct_words = ['TRUMP', 'CARSON', \"WALLACE\"]\n",
    "test_string = 'TUMP: blah. CRSON: blah. Trump: blah. WAlace: blah'\n",
    "for correct_word in correct_words:\n",
    "    word_len = len(correct_word)\n",
    "    print correct_word, word_len\n",
    "    for i in range(1,word_len-1):\n",
    "        #print i\n",
    "        missp = correct_word[0:i]+correct_word[i+1:word_len]\n",
    "        print missp\n",
    "        #test_string.replace(missp, correct_word)\n",
    "        pattern = re.compile(missp, re.IGNORECASE)\n",
    "        test_string = pattern.sub(correct_word, test_string)\n",
    "print test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP: blah\n"
     ]
    }
   ],
   "source": [
    "test_line = \"TUMP: blah\"\n",
    "import re\n",
    "pattern = re.compile(\"TUMP\", re.IGNORECASE)\n",
    "test_line = pattern.sub(\"TRUMP\", test_line)\n",
    "print test_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bye bye bye'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"hello\", re.IGNORECASE)\n",
    "pattern.sub(\"bye\", \"hello HeLLo HELLO\")\n",
    "## 'bye bye bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello python \n"
     ]
    }
   ],
   "source": [
    "my_string=\"hello python world , i'm a beginner \"\n",
    "print my_string.split(\"world\",1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['a', 'b']\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
