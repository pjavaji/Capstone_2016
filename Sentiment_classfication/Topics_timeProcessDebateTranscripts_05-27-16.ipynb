{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose:  For each debate, load the already-topic-labeled debate transcript, assign estimated time durations\n",
    "#           per statement, calculate total time durations by topic and candidate, and write results to csv.\n",
    "#           Or, write results to csv with time durations per statement, to support visualizing it as a Gantt chart.\n",
    "# Author:  Carol Sniegoski\n",
    "# Date:  May 27, 2016\n",
    "# Course:  DSE MAS Capstone, Spring 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function definitions.\n",
    "\n",
    "# Return list of last names of candidates in this debate\n",
    "def get_candidates(cstr):\n",
    "    returnlist = [s.strip() for s in cstr.split(',')]\n",
    "    returnlist = [s.upper().split(' ')[1] for s in returnlist]\n",
    "    return returnlist\n",
    "\n",
    "# Generate the conventional infile name for the manually-labeled, processed text of this debate.\n",
    "def get_labeled_infilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '_proc_labeled.csv'\n",
    "    return returnstr\n",
    "\n",
    "# Generate the event name (eg., D1, R2).\n",
    "def get_eventname(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal']))\n",
    "    return returnstr\n",
    "\n",
    "# Generate the conventional outfile name for manually-labeled, processed text of this debate.\n",
    "def get_labeled_outfilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '_timeDurations.csv'\n",
    "    return returnstr\n",
    "\n",
    "def time_process_transcript_forGantt( infilename, eventname, candidates ):\n",
    "    # Load infile.\n",
    "    try:\n",
    "        df_transcript = pd.read_csv(infilename)\n",
    "    except:\n",
    "        print \"ERROR: File {0} does not exist.\".format(infilename)\n",
    "        return\n",
    "    \n",
    "    # Remove audience speech acts, as they always overlap with speech acts from candidates or moderators.\n",
    "    df_transcript = df_transcript[ df_transcript['speaker_type']!='audience' ]\n",
    "    \n",
    "    # Get total debate length in characters.\n",
    "    totalChars = df_transcript['duration'].sum()\n",
    "    print totalChars\n",
    "    \n",
    "    # Normalize by total character length to get number of seconds. Assume each debate lasts 120 minutes.\n",
    "    df_transcript['timeDurationSec'] = (df_transcript['duration']*120*60)/totalChars\n",
    "    df_transcript['startTimeSec'] = (df_transcript['start_time']*120*60)/totalChars\n",
    "\n",
    "    # Add event field.\n",
    "    df_transcript['event'] = eventname\n",
    "    \n",
    "    return df_transcript\n",
    "    \n",
    "\n",
    "def time_process_transcript(infilename, outfilename, candidates):\n",
    "    # Load infile.\n",
    "    try:\n",
    "        df_transcript = pd.read_csv(infilename)\n",
    "    except:\n",
    "        print \"ERROR: File {0} does not exist.\".format(infilename)\n",
    "        return\n",
    "    \n",
    "    #print df_transcript.head(2)\n",
    "    \n",
    "    # Remove audience speech acts, as they always overlap with speech acts from candidates or moderators.\n",
    "    df_transcript = df_transcript[ df_transcript['speaker_type']!='audience' ]\n",
    "    #print df_transcript.head(2)\n",
    "    \n",
    "    # Get total debate length in characters.\n",
    "    totalChars = df_transcript['duration'].sum()\n",
    "    print totalChars\n",
    "        \n",
    "    # Do not include moderator speech.\n",
    "    df_transcript = df_transcript[df_transcript['speaker_type']=='candidate']\n",
    "    #df_transcript = df_transcript[df_transcript['speaker_type'].isin(['candidate', 'moderator'])]\n",
    "\n",
    "    # Drop unwanted topics.\n",
    "    unwanted_topics = ['intro', 'closing']\n",
    "    df_transcript = df_transcript[~df_transcript['topic'].isin(unwanted_topics)]\n",
    "\n",
    "    # Sum lengths of speeches (in characters) by candidate and topic. \n",
    "    df_transcript_summed = df_transcript.groupby(['speaker', 'topic'])['duration'].sum().reset_index()\n",
    "    df_transcript_summed.fillna(0, inplace=True)\n",
    "    #print df_transcript_summed.head(6)\n",
    "    \n",
    "    # Normalize by total character length to get number of minutes. Assume each debate lasts 120 minutes.\n",
    "    df_transcript_summed['timeDurationSec'] = (df_transcript_summed['duration']*120*60)/totalChars\n",
    "    \n",
    "    print df_transcript_summed.shape\n",
    "    #print df_transcript_summed.head(6)\n",
    "    #print df_transcript_summed['speaker'].value_counts()\n",
    "    #print df_transcript_summed['topic'].value_counts()\n",
    "    print df_transcript_summed.groupby(['speaker'])['timeDurationSec'].sum()/60\n",
    "    print df_transcript_summed['timeDurationSec'].sum()/60\n",
    "\n",
    "    # Write results to outfile.\n",
    "    df_transcript_summed.to_csv(outfilename)\n",
    "    print \"Wrote results to {}.\".format(outfilename)\n",
    "    \n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1_proc.csv            D4_timeDurations.csv   D8_proc.csv            R1_proc.csv            R4_proc_labeled.csv    R8_proc_labeled.csv\r\n",
      "D1_proc_labeled.csv    D5_proc.csv            D8_proc_labeled.csv    R1_proc_labeled.csv    R4_timeDurations.csv   R8_timeDurations.csv\r\n",
      "D1_timeDurations.csv   D5_proc_labeled.csv    D8_timeDurations.csv   R1_timeDurations.csv   R5_proc.csv            R9_proc.csv\r\n",
      "D2_proc labeled.csv    D5_timeDurations.csv   R10_proc.csv           R2_proc.csv            R6_proc.csv            R9_proc_labeled.csv\r\n",
      "D2_proc.csv            D6_proc.csv            R10_proc_labeled.csv   R2_proc_labeled.csv    R6_proc_labeled.csv    R9_timeDurations.csv\r\n",
      "D3_proc.csv            D6_proc_labeled.csv    R10_timeDurations.csv  R2_timeDurations.csv   R6_timeDurations.csv\r\n",
      "D3_proc_labeled.csv    D6_timeDurations.csv   R11_proc.csv           R3_proc.csv            R7_proc.csv\r\n",
      "D3_timeDurations.csv   D7_proc.csv            R11_proc_labeled.csv   R3_proc_labeled.csv    R7_proc_labeled.csv\r\n",
      "D4_proc.csv            D7_proc_labeled.csv    R11_timeDurations.csv  R3_timeDurations.csv   R7_timeDurations.csv\r\n",
      "D4_proc_labeled.csv    D7_timeDurations.csv   R12_proc.csv           R4_proc.csv            R8_proc.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Locate the labeled transcript data.\n",
    "labeledTranscripts_prefix = \"../data/debateTranscripts/labeled_transcripts/\"\n",
    "%ls ../data/debateTranscripts/labeled_transcripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34munifiedCalendar_03-26-16\u001b[m\u001b[m/                unifiedCalendar_04-26-16.csv\r\n",
      "unifiedCalendar_03-26-16.csv             unifiedCalendar_DebatesAndPrimaries.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Locate the debate calendar.\n",
    "%ls ../data/calendar/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the schedule of debates and primaries.\n",
    "df_dp = pd.read_csv(\"../data/calendar/unifiedCalendar_04-26-16.csv\")\n",
    "#df_dp.head(2)\n",
    "#print type(df_dp[\"Candidates\"][0])\n",
    "\n",
    "# Get only entries for EventType 'debate'.\n",
    "df_dp = df_dp[df_dp['EventType']=='debate']\n",
    "df_dp.head(2)\n",
    "print df_dp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 R1 ../data/debateTranscripts/labeled_transcripts/R1_proc_labeled.csv ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH']\n",
      "106812.0\n",
      "\n",
      "1 R2 ../data/debateTranscripts/labeled_transcripts/R2_proc_labeled.csv ['TRUMP', 'CARSON', 'BUSH', 'CRUZ', 'WALKER', 'RUBIO', 'FIORINA', 'HUCKABEE', 'PAUL', 'KASICH', 'CHRISTIE']\n",
      "187100.0\n",
      "\n",
      "2 D1 ../data/debateTranscripts/labeled_transcripts/D1_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\", 'WEBB', 'CHAFEE']\n",
      "129174\n",
      "\n",
      "3 R3 ../data/debateTranscripts/labeled_transcripts/R3_proc_labeled.csv ['TRUMP', 'CARSON', 'BUSH', 'RUBIO', 'CRUZ', 'HUCKABEE', 'PAUL', 'FIORINA', 'CHRISTIE', 'KASICH']\n",
      "121236.0\n",
      "\n",
      "4 R4 ../data/debateTranscripts/labeled_transcripts/R4_proc_labeled.csv ['TRUMP', 'CARSON', 'RUBIO', 'CRUZ', 'BUSH', 'FIORINA', 'KASICH', 'PAUL']\n",
      "114573.0\n",
      "\n",
      "5 D2 ../data/debateTranscripts/labeled_transcripts/D2_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/D2_proc_labeled.csv does not exist.\n",
      "\n",
      "6 R5 ../data/debateTranscripts/labeled_transcripts/R5_proc_labeled.csv ['TRUMP', 'CARSON', 'CRUZ', 'RUBIO', 'BUSH', 'FIORINA', 'CHRISTIE', 'KASICH', 'PAUL']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/R5_proc_labeled.csv does not exist.\n",
      "\n",
      "7 D3 ../data/debateTranscripts/labeled_transcripts/D3_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "117795\n",
      "\n",
      "8 R6 ../data/debateTranscripts/labeled_transcripts/R6_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'CHRISTIE', 'BUSH', 'KASICH']\n",
      "126885.0\n",
      "\n",
      "9 D4 ../data/debateTranscripts/labeled_transcripts/D4_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "86907\n",
      "\n",
      "10 R7 ../data/debateTranscripts/labeled_transcripts/R7_proc_labeled.csv ['CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH', 'PAUL']\n",
      "107775\n",
      "\n",
      "13 R10 ../data/debateTranscripts/labeled_transcripts/R10_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH', 'CARSON']\n",
      "138502.0\n",
      "\n",
      "14 D5 ../data/debateTranscripts/labeled_transcripts/D5_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "98475\n",
      "\n",
      "15 R8 ../data/debateTranscripts/labeled_transcripts/R8_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH']\n",
      "141334\n",
      "\n",
      "18 D6 ../data/debateTranscripts/labeled_transcripts/D6_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "89856\n",
      "\n",
      "19 R9 ../data/debateTranscripts/labeled_transcripts/R9_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'BUSH', 'CARSON', 'KASICH']\n",
      "103708\n",
      "\n",
      "51 R11 ../data/debateTranscripts/labeled_transcripts/R11_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH']\n",
      "130099\n",
      "\n",
      "60 D7 ../data/debateTranscripts/labeled_transcripts/D7_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "97842\n",
      "\n",
      "68 D8 ../data/debateTranscripts/labeled_transcripts/D8_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "84129\n",
      "\n",
      "70 R12 ../data/debateTranscripts/labeled_transcripts/R12_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/R12_proc_labeled.csv does not exist.\n",
      "\n",
      "99 D9 ../data/debateTranscripts/labeled_transcripts/D9_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/D9_proc_labeled.csv does not exist.\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Process the manually-labeled transcripts for all debates included in the schedule.\n",
    "# This version is for a Gantt chart.\n",
    "# It drops audience events and adds an estimated time duration to each remaining speech segment,\n",
    "# and returns the df.\n",
    "\n",
    "#for row in df_dp.itertuples():\n",
    "#    print row.EventType\n",
    "\n",
    "df_list = []\n",
    "limit = 100\n",
    "i = 0\n",
    "for ix, row in df_dp.iterrows():\n",
    "    i+=1;\n",
    "    if (i>limit):\n",
    "        break\n",
    "        \n",
    "    #print ix, row['EventType']\n",
    "    \n",
    "    if (row['Candidates']==\"CANCELLED\"):\n",
    "        continue\n",
    "    \n",
    "    candidates = get_candidates(row['Candidates'])\n",
    "    #moderators = get_moderators(row['Moderators'])\n",
    "    #audience = get_audience()\n",
    "    event = get_eventname(row)\n",
    "    \n",
    "    infilename = labeledTranscripts_prefix + get_labeled_infilename(row)\n",
    "    outfilename = labeledTranscripts_prefix + get_labeled_outfilename(row)\n",
    "    \n",
    "    print ix, event, infilename, candidates\n",
    "    #print\n",
    "    df_list.append( time_process_transcript_forGantt(infilename, event, candidates) )\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>duration</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>start_time</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>timeDurationSec</th>\n",
       "      <th>startTimeSec</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>427</td>\n",
       "      <td>KELLY</td>\n",
       "      <td>moderator</td>\n",
       "      <td>0</td>\n",
       "      <td>KELLY: Welcome to the first debate night of th...</td>\n",
       "      <td>intro</td>\n",
       "      <td>28.783283</td>\n",
       "      <td>0</td>\n",
       "      <td>R1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  duration speaker speaker_type  start_time  \\\n",
       "2           2       427   KELLY    moderator           0   \n",
       "\n",
       "                                                text  topic  timeDurationSec  \\\n",
       "2  KELLY: Welcome to the first debate night of th...  intro        28.783283   \n",
       "\n",
       "   startTimeSec event  \n",
       "2             0    R1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list[0].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5751, 10)\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat(df_list)\n",
    "print df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written to ../data/topic/All_durations_Gantt_06-09-16.csv\n"
     ]
    }
   ],
   "source": [
    "# Write to csv.\n",
    "out_prefix = \"../data/topic/\"\n",
    "out_fname = \"All_durations_Gantt_06-09-16.csv\"\n",
    "df_all.to_csv(out_prefix + out_fname)\n",
    "print \"Written to\", out_prefix + out_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../data/debateTranscripts/labeled_transcripts/R1_proc_labeled.csv ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH']\n",
      "106812.0\n",
      "(65, 4)\n",
      "speaker\n",
      "BUSH         8.347377\n",
      "CARSON       6.027413\n",
      "CHRISTIE     7.492417\n",
      "CRUZ         6.028536\n",
      "HUCKABEE     6.884620\n",
      "KASICH       7.302550\n",
      "PAUL         5.656668\n",
      "RUBIO        7.929446\n",
      "TRUMP       12.017751\n",
      "WALKER       6.950904\n",
      "Name: timeDurationSec, dtype: float64\n",
      "74.6376811594\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R1_timeDurations.csv.\n",
      "\n",
      "1 ../data/debateTranscripts/labeled_transcripts/D1_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\", 'WEBB', 'CHAFEE']\n",
      "129174\n",
      "(83, 4)\n",
      "speaker\n",
      "CHAFEE       5.858145\n",
      "CLINTON     24.365275\n",
      "O'MALLEY    13.576107\n",
      "SANDERS     21.410191\n",
      "WEBB        11.362348\n",
      "Name: timeDurationSec, dtype: float64\n",
      "76.572065586\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D1_timeDurations.csv.\n",
      "\n",
      "2 ../data/debateTranscripts/labeled_transcripts/R2_proc_labeled.csv ['TRUMP', 'CARSON', 'BUSH', 'CRUZ', 'WALKER', 'RUBIO', 'FIORINA', 'HUCKABEE', 'PAUL', 'KASICH', 'CHRISTIE']\n",
      "187100.0\n",
      "(133, 4)\n",
      "speaker\n",
      "BUSH        10.743560\n",
      "CARSON       6.484874\n",
      "CHRISTIE     7.820203\n",
      "CRUZ         5.447782\n",
      "FIORINA      8.243506\n",
      "HUCKABEE     5.448423\n",
      "KASICH       5.790273\n",
      "PAUL         7.290433\n",
      "RUBIO       10.168894\n",
      "TRUMP       13.926029\n",
      "WALKER       4.895564\n",
      "Name: timeDurationSec, dtype: float64\n",
      "86.2595403528\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R2_timeDurations.csv.\n",
      "\n",
      "3 ../data/debateTranscripts/labeled_transcripts/D2_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/D2_proc_labeled.csv does not exist.\n",
      "\n",
      "4 ../data/debateTranscripts/labeled_transcripts/R3_proc_labeled.csv ['TRUMP', 'CARSON', 'BUSH', 'RUBIO', 'CRUZ', 'HUCKABEE', 'PAUL', 'FIORINA', 'CHRISTIE', 'KASICH']\n",
      "121236.0\n",
      "(72, 4)\n",
      "speaker\n",
      "BUSH         7.767000\n",
      "CARSON       5.460754\n",
      "CHRISTIE     8.320301\n",
      "CRUZ         7.330496\n",
      "FIORINA     11.430268\n",
      "HUCKABEE     7.361180\n",
      "KASICH       8.125309\n",
      "PAUL         6.608928\n",
      "RUBIO       12.933782\n",
      "TRUMP        8.950807\n",
      "Name: timeDurationSec, dtype: float64\n",
      "84.2888251015\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R3_timeDurations.csv.\n",
      "\n",
      "5 ../data/debateTranscripts/labeled_transcripts/D3_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "117795\n",
      "(50, 4)\n",
      "speaker\n",
      "CLINTON     34.975678\n",
      "O'MALLEY    21.968674\n",
      "SANDERS     27.633771\n",
      "Name: timeDurationSec, dtype: float64\n",
      "84.5781230103\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D3_timeDurations.csv.\n",
      "\n",
      "6 ../data/debateTranscripts/labeled_transcripts/R4_proc_labeled.csv ['TRUMP', 'CARSON', 'RUBIO', 'CRUZ', 'BUSH', 'FIORINA', 'KASICH', 'PAUL']\n",
      "114573.0\n",
      "(56, 4)\n",
      "speaker\n",
      "BUSH       10.910424\n",
      "CARSON      8.223927\n",
      "CRUZ       11.996544\n",
      "FIORINA    10.965934\n",
      "KASICH     12.427012\n",
      "PAUL       10.297714\n",
      "RUBIO      12.086617\n",
      "TRUMP      11.194260\n",
      "Name: timeDurationSec, dtype: float64\n",
      "88.1024325103\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R4_timeDurations.csv.\n",
      "\n",
      "7 ../data/debateTranscripts/labeled_transcripts/D4_proc_labeled.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"]\n",
      "86907\n",
      "(49, 4)\n",
      "speaker\n",
      "CLINTON     30.174324\n",
      "O'MALLEY    19.489799\n",
      "SANDERS     34.280783\n",
      "Name: timeDurationSec, dtype: float64\n",
      "83.9449066243\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D4_timeDurations.csv.\n",
      "\n",
      "8 ../data/debateTranscripts/labeled_transcripts/R5_proc_labeled.csv ['TRUMP', 'CARSON', 'CRUZ', 'RUBIO', 'BUSH', 'FIORINA', 'CHRISTIE', 'KASICH', 'PAUL']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/R5_proc_labeled.csv does not exist.\n",
      "\n",
      "9 ../data/debateTranscripts/labeled_transcripts/D5_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "98475\n",
      "(45, 4)\n",
      "speaker\n",
      "CLINTON    44.212643\n",
      "SANDERS    41.911957\n",
      "Name: timeDurationSec, dtype: float64\n",
      "86.1246001523\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D5_timeDurations.csv.\n",
      "\n",
      "10 ../data/debateTranscripts/labeled_transcripts/R6_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'CHRISTIE', 'BUSH', 'KASICH']\n",
      "126885.0\n",
      "(56, 4)\n",
      "speaker\n",
      "BUSH        10.303818\n",
      "CARSON       7.105332\n",
      "CHRISTIE    14.396028\n",
      "CRUZ        14.400757\n",
      "KASICH      11.466131\n",
      "RUBIO       13.801159\n",
      "TRUMP       16.450171\n",
      "Name: timeDurationSec, dtype: float64\n",
      "87.9233952004\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R6_timeDurations.csv.\n",
      "\n",
      "11 ../data/debateTranscripts/labeled_transcripts/D6_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "89856\n",
      "(33, 4)\n",
      "speaker\n",
      "CLINTON    47.015224\n",
      "SANDERS    47.330395\n",
      "Name: timeDurationSec, dtype: float64\n",
      "94.3456196581\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D6_timeDurations.csv.\n",
      "\n",
      "12 ../data/debateTranscripts/labeled_transcripts/R7_proc_labeled.csv ['CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH', 'PAUL']\n",
      "107775\n",
      "(56, 4)\n",
      "speaker\n",
      "BUSH        10.449548\n",
      "CARSON       6.055950\n",
      "CHRISTIE    10.952818\n",
      "CRUZ        14.170633\n",
      "KASICH      11.060821\n",
      "PAUL         9.574391\n",
      "RUBIO       19.695477\n",
      "Name: timeDurationSec, dtype: float64\n",
      "81.959638135\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R7_timeDurations.csv.\n",
      "\n",
      "13 ../data/debateTranscripts/labeled_transcripts/D7_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "97842\n",
      "(37, 4)\n",
      "speaker\n",
      "CLINTON    41.533084\n",
      "SANDERS    41.381002\n",
      "Name: timeDurationSec, dtype: float64\n",
      "82.9140859753\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D7_timeDurations.csv.\n",
      "\n",
      "14 ../data/debateTranscripts/labeled_transcripts/R8_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH']\n",
      "141334\n",
      "(68, 4)\n",
      "speaker\n",
      "BUSH         8.943920\n",
      "CARSON       4.869317\n",
      "CHRISTIE    10.540139\n",
      "CRUZ        13.618804\n",
      "KASICH       8.843732\n",
      "RUBIO       16.754355\n",
      "TRUMP       13.160315\n",
      "Name: timeDurationSec, dtype: float64\n",
      "76.7305814595\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R8_timeDurations.csv.\n",
      "\n",
      "15 ../data/debateTranscripts/labeled_transcripts/D8_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "84129\n",
      "(38, 4)\n",
      "speaker\n",
      "CLINTON    44.848269\n",
      "SANDERS    35.171701\n",
      "Name: timeDurationSec, dtype: float64\n",
      "80.0199693328\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/D8_timeDurations.csv.\n",
      "\n",
      "16 ../data/debateTranscripts/labeled_transcripts/R9_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'BUSH', 'CARSON', 'KASICH']\n",
      "103708\n",
      "(42, 4)\n",
      "speaker\n",
      "BUSH      10.801481\n",
      "CARSON     6.125661\n",
      "CRUZ      13.267250\n",
      "KASICH    10.247233\n",
      "RUBIO     12.902765\n",
      "TRUMP     17.592471\n",
      "Name: timeDurationSec, dtype: float64\n",
      "70.9368611872\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R9_timeDurations.csv.\n",
      "\n",
      "17 ../data/debateTranscripts/labeled_transcripts/R10_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH', 'CARSON']\n",
      "138502.0\n",
      "(111, 4)\n",
      "speaker\n",
      "CARSON     8.993372\n",
      "CRUZ      20.768798\n",
      "KASICH    17.584728\n",
      "RUBIO     22.639384\n",
      "TRUMP     32.935842\n",
      "Name: timeDurationSec, dtype: float64\n",
      "102.922123868\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R10_timeDurations.csv.\n",
      "\n",
      "18 ../data/debateTranscripts/labeled_transcripts/R11_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH']\n",
      "130099\n",
      "(93, 4)\n",
      "speaker\n",
      "CRUZ      26.367920\n",
      "KASICH    18.132960\n",
      "RUBIO     17.281609\n",
      "TRUMP     31.753665\n",
      "Name: timeDurationSec, dtype: float64\n",
      "93.5361532372\n",
      "Wrote results to ../data/debateTranscripts/labeled_transcripts/R11_timeDurations.csv.\n",
      "\n",
      "19 ../data/debateTranscripts/labeled_transcripts/R12_proc_labeled.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/R12_proc_labeled.csv does not exist.\n",
      "\n",
      "21 ../data/debateTranscripts/labeled_transcripts/D9_proc_labeled.csv ['CLINTON', 'SANDERS']\n",
      "ERROR: File ../data/debateTranscripts/labeled_transcripts/D9_proc_labeled.csv does not exist.\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Process the manually-labeled transcripts for all debates included in the schedule.\n",
    "# This version rolls up each transcript by topic and speaker, sums the time in minutes, and writes\n",
    "# each result to csv file.\n",
    "\n",
    "#for row in df_dp.itertuples():\n",
    "#    print row.EventType\n",
    "\n",
    "limit = 400\n",
    "i = 0\n",
    "for ix, row in df_dp.iterrows():\n",
    "    i+=1;\n",
    "    if (i>limit):\n",
    "        break\n",
    "        \n",
    "    #print ix, row['EventType']\n",
    "    \n",
    "    if (row['Candidates']==\"CANCELLED\"):\n",
    "        continue\n",
    "    \n",
    "    candidates = get_candidates(row['Candidates'])\n",
    "    #moderators = get_moderators(row['Moderators'])\n",
    "    #audience = get_audience()\n",
    "    \n",
    "    infilename = labeledTranscripts_prefix + get_labeled_infilename(row)\n",
    "    outfilename = labeledTranscripts_prefix + get_labeled_outfilename(row)\n",
    "    \n",
    "    print ix, infilename, candidates\n",
    "    #print\n",
    "    time_process_transcript(infilename, outfilename, candidates)\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DO NOT USE BELOW THIS POINT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Define functions.\n",
    "\n",
    "# Return line with all misspelled instances of the correct_words replaced with the correct_word.\n",
    "# Here we define a misspelling as missing one letter other than the first or last letter in a word.\n",
    "# Case insensitive.\n",
    "def correct_spellings(line, correct_words):\n",
    "    \n",
    "    for correct_word in correct_words:\n",
    "        word_len = len(correct_word)\n",
    "        for i in range(1,word_len-1):\n",
    "            \n",
    "            # Create the misspelled version of the word to look for.\n",
    "            missp = correct_word[0:i]+correct_word[i+1:word_len]\n",
    "            \n",
    "            # Do a case-insensitive replacement.\n",
    "            #test_string.replace(missp, correct_word)\n",
    "            pattern = re.compile(missp, re.IGNORECASE)\n",
    "            line = pattern.sub(correct_word, line) \n",
    "            \n",
    "    # Fixing the \"O'Malley\" spelling variations.\n",
    "    line = line.replace(\"â€™\", \"'\")\n",
    "    line = line.replace(\"O' \", \"O'\")\n",
    "    \n",
    "    return line\n",
    "\n",
    "        \n",
    "# Return list of text chunks, each starting with either the beginning of the line\n",
    "# or a new speaker or audience event.\n",
    "def get_splits_by_speaker(line, candidates, moderators, audience):\n",
    "    return_list = []\n",
    "    \n",
    "    # Get splits for each speaker type. Unfortunately they are all handled slightly differently.\n",
    "    splits = get_candidate_splits(line, candidates) + get_moderator_splits(line, moderators) + get_audience_splits(line, audience)\n",
    "\n",
    "    # Sort list of tuples by 3rd element, which is the start index in the line.\n",
    "    splits.sort(key=lambda x: x[2])\n",
    "    \n",
    "    # Use indices to split line into text chunks.\n",
    "\n",
    "    # If there are no indices, just return the line, with speaker unknown.\n",
    "    if len(splits)==0:\n",
    "        return_list = [ ('', '', line) ]\n",
    "        return return_list\n",
    "    \n",
    "    # If the first entry does not start at index zero, add an initial text chunk with speaker unknown.\n",
    "    if splits[0][2]!=0:\n",
    "        return_list.append( ('', '', line[0:splits[0][2]]) )\n",
    "    \n",
    "    # Add the rest of the text chunks.\n",
    "    #ix_end = len(line)\n",
    "    for i in range(len(splits)):\n",
    "        ix_start = splits[i][2]\n",
    "        speaker_name = splits[i][0]\n",
    "        speaker_type = splits[i][1]\n",
    "        try:\n",
    "            ix_end = splits[i+1][2]\n",
    "        except:\n",
    "            ix_end = len(line)\n",
    "        return_list.append( ( speaker_name, speaker_type, line[ix_start:ix_end] )  )\n",
    "    \n",
    "    # Discard text chunks with no content but whitespace.\n",
    "    return_list = filter(lambda x: len(x[2].strip())>0, return_list)\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split before.\n",
    "def get_candidate_splits(line, candidates):\n",
    "    return_list = []\n",
    "    \n",
    "    pattern = '(' + '|'.join(candidates) + '):'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    \n",
    "    matched = compiled_pattern.finditer(line)\n",
    "\n",
    "    for m in matched:\n",
    "        #print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "        return_list.append( (m.group(1), 'candidate', m.start()) )\n",
    "\n",
    "    #print 'get_candidate_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split before.\n",
    "def get_moderator_splits(line, moderators):\n",
    "    return_list = []\n",
    "    \n",
    "    #pattern = '(' + '|'.join(moderators) + '):'\n",
    "    pattern = '(' + '|'.join(moderators) + ')' + '(?: *\\[[a-z ]*\\])?:'\n",
    "    #compiled_pattern = re.compile(\"(ramos|salinas)(?:\\[[a-z ]*\\])?:\", re.IGNORECASE)\n",
    "    \n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "\n",
    "    for m in matched:\n",
    "        #print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "        return_list.append( (m.group(1), 'moderator', m.start()) )\n",
    "    \n",
    "    # Discard splits with no name or body.\n",
    "    return_list = filter(lambda x: len(x[0])>0, return_list)\n",
    "    \n",
    "    #print 'get_moderator_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Split both before and after.\n",
    "def get_audience_splits(line, audience):\n",
    "    return_list = []\n",
    "    \n",
    "    # First split before.\n",
    "    pattern = '[\\(\\[](' + '|'.join(audience) + ')'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "    for m in matched:\n",
    "        return_list.append( (m.group(1), 'audience', m.start()) )\n",
    "        \n",
    "    # Then split after.\n",
    "    pattern = '(' + '|'.join(audience) + ')[\\)\\]]'\n",
    "    compiled_pattern = re.compile(pattern, re.IGNORECASE)\n",
    "    matched = compiled_pattern.finditer(line)\n",
    "    for m in matched:\n",
    "        if (m.end() != len(line)):\n",
    "            return_list.append( ('', '', m.end()) ) \n",
    "\n",
    "    #print 'get_audience_splits() returns: ', return_list\n",
    "    \n",
    "    return return_list\n",
    "\n",
    "# Add line to dataframe.\n",
    "def add_line(speaker, speaker_type, speech, start_time, duration, rows_list):\n",
    "    #print '**add_line(): speaker=' + speaker + ', speaker_type=' + speaker_type + ', text=' + speech\n",
    "    dict = {'speaker':speaker, 'speaker_type':speaker_type, 'text':speech, 'start_time':start_time, 'duration':duration}\n",
    "    rows_list.append(dict)\n",
    "    \n",
    "# Return list of last names of candidates in this debate\n",
    "def get_candidates(cstr):\n",
    "    returnlist = [s.strip() for s in cstr.split(',')]\n",
    "    returnlist = [s.upper().split(' ')[1] for s in returnlist]\n",
    "    return returnlist\n",
    "\n",
    "# Return list of last names of moderators of this debate\n",
    "def get_moderators(mstr):\n",
    "    returnlist = [s.strip() for s in mstr.split(',')]\n",
    "    #returnlist = [s.upper().split(' ')[1] for s in returnlist]\n",
    "    returnlist = [s.upper().split(' ') for s in returnlist]\n",
    "    returnlist = [s[len(s)-1] for s in returnlist]\n",
    "    return returnlist\n",
    "\n",
    "# Return list of audience events\n",
    "def get_audience():\n",
    "    returnlist = ['APPLAUSE', 'BOOING', 'CHEERING', 'LAUGHTER']\n",
    "    return returnlist\n",
    "\n",
    "# Return map of strings for event name, date, party, location, start_time, end_time, duration\n",
    "def get_event_info():\n",
    "    returnmap = {}\n",
    "    return returnmap\n",
    "\n",
    "# Generate the conventional infile name for this debate.\n",
    "def get_infilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '.txt'\n",
    "    return returnstr\n",
    "\n",
    "# Generate the conentional outfile name for this debate.\n",
    "def get_outfilename(row):\n",
    "    returnstr = \"\"\n",
    "    returnstr += row['Party'] + str(int(row['Ordinal'])) + '_proc.csv'\n",
    "    return returnstr\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BLITZER', 'moderator', \"BLITZER: We're live here at the University of Houston for the 10th Republican presidential debate. \"), ('applause', 'audience', '(applause)')]\n"
     ]
    }
   ],
   "source": [
    "testline = \"BLITZER: We're live here at the University of Houston for the 10th Republican presidential debate. (applause)\"\n",
    "\n",
    "get_audience_splits(testline, ['APPLAUSE', 'LAUGHTER'])\n",
    "result = get_splits_by_speaker(testline, ['TRUMP'],['BLITZER'],['APPLAUSE', 'LAUGHTER'])\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function def\n",
    "\n",
    "# Load and parse a text file representing a debate transcript. \n",
    "# Assume the debate candidates, moderators, and audience evets are as provided.\n",
    "# Write results to csv.\n",
    "\n",
    "def process_transcript(infilename, outfilename, candidates, moderators, audience):\n",
    "    rows_list = []\n",
    "    #with open('transcript_v2.txt') as infile:\n",
    "    with open(infilename) as infile:\n",
    "        speaker=\"\"\n",
    "        speaker_type=\"\"\n",
    "        speech=\"\"\n",
    "        time=0\n",
    "        #overlap_time=0\n",
    "        \n",
    "        #threshold = 20\n",
    "        #i = 0\n",
    "        for line in infile:\n",
    "            \n",
    "            #i+=1;\n",
    "            #if (i>threshold):\n",
    "            #    break\n",
    "            \n",
    "            line = line.strip()\n",
    "            line = correct_spellings(line, [x+':' for x in candidates+moderators+audience])\n",
    "            if len(line)==0:\n",
    "                continue\n",
    "            \n",
    "            # Split line into chunks, each from a single speaker, of format (speaker, speaker_type, speech).\n",
    "            splits = get_splits_by_speaker(line, candidates=candidates, moderators=moderators, audience=audience) \n",
    "            #print 'splits=', splits\n",
    "            \n",
    "            for split in splits:\n",
    "                #print 'split=', split\n",
    "                \n",
    "                new_speaker = split[0]\n",
    "                new_speaker_type = split[1]\n",
    "                new_speech = split[2]\n",
    "                \n",
    "                # Audience event, e.g. \"(laughter, applause)\".\n",
    "                # Do not change the speaker or end the current speech.\n",
    "                # Add one or more audience events with appropriate timing estimates.\n",
    "                if (new_speaker_type=='audience'):\n",
    "                    for event in audience:\n",
    "                        est_duration=50\n",
    "                        if event.lower() in new_speech.lower():\n",
    "                            add_line(event, \"audience\", new_speech, time+len(speech), est_duration, rows_list)  \n",
    "                \n",
    "                # No change of speaker.\n",
    "                # Just continue to accumulate the current speech text.\n",
    "                elif ( (new_speaker=='') | (new_speaker==speaker) ):\n",
    "                    speech+= (' ' + new_speech.strip())\n",
    "                \n",
    "                # Change of speaker, e.g. \"TRUMP: Blah.\"\n",
    "                # Cut off the current speech and add it to the results list.\n",
    "                # Change speaker and speaker type. Begin accumulating the next speech.\n",
    "                elif (new_speaker!=speaker):\n",
    "                   \n",
    "                    # Cut off the previous speech and add it to the df.\n",
    "                    add_line(speaker, speaker_type, speech, time, len(speech), rows_list)\n",
    "                   \n",
    "                    # Begin the next speech.\n",
    "                    time += len(speech)\n",
    "                    overlap_time = 0\n",
    "                    speech = new_speech\n",
    "                    speaker = new_speaker\n",
    "                    speaker_type = new_speaker_type\n",
    "                    \n",
    "                else:\n",
    "                    print \"ERROR! No line type recognized for split\", split\n",
    "                    \n",
    "        add_line(speaker, speaker_type, speech, time, len(speech), rows_list)\n",
    "       \n",
    "    # Now create the dataframe & write it to csv.\n",
    "    df = pd.DataFrame(rows_list[1:]) \n",
    "    df.to_csv(outfilename)\n",
    "    print 'done processing file ', infilename, '; shape=', df.shape, '; results written to file ', outfilename\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 17)\n"
     ]
    }
   ],
   "source": [
    "# Load the schedule of debates and primaries.\n",
    "df_dp = pd.read_csv(\"../data/unifiedCalendar_04-26-16.csv\")\n",
    "#df_dp.head(2)\n",
    "#print type(df_dp[\"Candidates\"][0])\n",
    "\n",
    "# Get only entries for EventType 'debate'.\n",
    "df_dp = df_dp[df_dp['EventType']=='debate']\n",
    "df_dp.head(2)\n",
    "print df_dp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ../data/debateTranscripts/R1.txt ../data/debateTranscripts/R1_proc.csv ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH'] ['BAIER', 'KELLY', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R1.txt ; shape= (417, 5) ; results written to file  ../data/debateTranscripts/R1_proc.csv\n",
      "\n",
      "1 ../data/debateTranscripts/D1.txt ../data/debateTranscripts/D1_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\", 'WEBB', 'CHAFEE'] ['COOPER', 'BASH', 'LOPEZ']\n",
      "done processing file  ../data/debateTranscripts/D1.txt ; shape= (530, 5) ; results written to file  ../data/debateTranscripts/D1_proc.csv\n",
      "\n",
      "2 ../data/debateTranscripts/R2.txt ../data/debateTranscripts/R2_proc.csv ['TRUMP', 'CARSON', 'BUSH', 'CRUZ', 'WALKER', 'RUBIO', 'FIORINA', 'HUCKABEE', 'PAUL', 'KASICH', 'CHRISTIE'] ['TAPPER', 'HEWITT', 'BASH']\n",
      "done processing file  ../data/debateTranscripts/R2.txt ; shape= (794, 5) ; results written to file  ../data/debateTranscripts/R2_proc.csv\n",
      "\n",
      "3 ../data/debateTranscripts/D2.txt ../data/debateTranscripts/D2_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['DICKERSON', 'CORDES', 'COONEY', 'OBRADOVICH']\n",
      "done processing file  ../data/debateTranscripts/D2.txt ; shape= (286, 5) ; results written to file  ../data/debateTranscripts/D2_proc.csv\n",
      "\n",
      "4 ../data/debateTranscripts/R3.txt ../data/debateTranscripts/R3_proc.csv ['TRUMP', 'CARSON', 'BUSH', 'RUBIO', 'CRUZ', 'HUCKABEE', 'PAUL', 'FIORINA', 'CHRISTIE', 'KASICH'] ['QUINTANILLA', 'QUICK', 'HARWOOD']\n",
      "done processing file  ../data/debateTranscripts/R3.txt ; shape= (485, 5) ; results written to file  ../data/debateTranscripts/R3_proc.csv\n",
      "\n",
      "5 ../data/debateTranscripts/D3.txt ../data/debateTranscripts/D3_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['MUIR', 'RADDATZ', 'LEVESQUE', 'MCELVEEN']\n",
      "done processing file  ../data/debateTranscripts/D3.txt ; shape= (357, 5) ; results written to file  ../data/debateTranscripts/D3_proc.csv\n",
      "\n",
      "6 ../data/debateTranscripts/R4.txt ../data/debateTranscripts/R4_proc.csv ['TRUMP', 'CARSON', 'RUBIO', 'CRUZ', 'BUSH', 'FIORINA', 'KASICH', 'PAUL'] ['BAKER', 'CAVUTO', 'BARTIROMO']\n",
      "done processing file  ../data/debateTranscripts/R4.txt ; shape= (398, 5) ; results written to file  ../data/debateTranscripts/R4_proc.csv\n",
      "\n",
      "7 ../data/debateTranscripts/D4.txt ../data/debateTranscripts/D4_proc.csv ['CLINTON', 'SANDERS', \"O'MALLEY\"] ['HOLT', 'MITCHELL']\n",
      "done processing file  ../data/debateTranscripts/D4.txt ; shape= (359, 5) ; results written to file  ../data/debateTranscripts/D4_proc.csv\n",
      "\n",
      "8 ../data/debateTranscripts/R5.txt ../data/debateTranscripts/R5_proc.csv ['TRUMP', 'CARSON', 'CRUZ', 'RUBIO', 'BUSH', 'FIORINA', 'CHRISTIE', 'KASICH', 'PAUL'] ['BLITZER', 'BASH', 'HEWITT']\n",
      "done processing file  ../data/debateTranscripts/R5.txt ; shape= (450, 5) ; results written to file  ../data/debateTranscripts/R5_proc.csv\n",
      "\n",
      "9 ../data/debateTranscripts/D5.txt ../data/debateTranscripts/D5_proc.csv ['CLINTON', 'SANDERS'] ['TODD', 'MADDOW']\n",
      "done processing file  ../data/debateTranscripts/D5.txt ; shape= (309, 5) ; results written to file  ../data/debateTranscripts/D5_proc.csv\n",
      "\n",
      "10 ../data/debateTranscripts/R6.txt ../data/debateTranscripts/R6_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'CHRISTIE', 'BUSH', 'KASICH'] ['CAVUTO', 'BARTIROMO']\n",
      "done processing file  ../data/debateTranscripts/R6.txt ; shape= (400, 5) ; results written to file  ../data/debateTranscripts/R6_proc.csv\n",
      "\n",
      "11 ../data/debateTranscripts/D6.txt ../data/debateTranscripts/D6_proc.csv ['CLINTON', 'SANDERS'] ['IFILL', 'WOODRUFF']\n",
      "done processing file  ../data/debateTranscripts/D6.txt ; shape= (211, 5) ; results written to file  ../data/debateTranscripts/D6_proc.csv\n",
      "\n",
      "12 ../data/debateTranscripts/R7.txt ../data/debateTranscripts/R7_proc.csv ['CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH', 'PAUL'] ['BAIER', 'KELLY', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R7.txt ; shape= (401, 5) ; results written to file  ../data/debateTranscripts/R7_proc.csv\n",
      "\n",
      "13 ../data/debateTranscripts/D7.txt ../data/debateTranscripts/D7_proc.csv ['CLINTON', 'SANDERS'] ['COOPER', 'LEMON']\n",
      "done processing file  ../data/debateTranscripts/D7.txt ; shape= (356, 5) ; results written to file  ../data/debateTranscripts/D7_proc.csv\n",
      "\n",
      "14 ../data/debateTranscripts/R8.txt ../data/debateTranscripts/R8_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'CARSON', 'BUSH', 'CHRISTIE', 'KASICH'] ['MUIR', 'RADDATZ']\n",
      "done processing file  ../data/debateTranscripts/R8.txt ; shape= (464, 5) ; results written to file  ../data/debateTranscripts/R8_proc.csv\n",
      "\n",
      "15 ../data/debateTranscripts/D8.txt ../data/debateTranscripts/D8_proc.csv ['CLINTON', 'SANDERS'] ['SALINAS', 'RAMOS', 'TUMULTY']\n",
      "done processing file  ../data/debateTranscripts/D8.txt ; shape= (371, 5) ; results written to file  ../data/debateTranscripts/D8_proc.csv\n",
      "\n",
      "16 ../data/debateTranscripts/R9.txt ../data/debateTranscripts/R9_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'BUSH', 'CARSON', 'KASICH'] ['DICKERSON', 'GARRETT', 'STRASSEL']\n",
      "done processing file  ../data/debateTranscripts/R9.txt ; shape= (439, 5) ; results written to file  ../data/debateTranscripts/R9_proc.csv\n",
      "\n",
      "17 ../data/debateTranscripts/R10.txt ../data/debateTranscripts/R10_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH', 'CARSON'] ['BLITZER', 'ARRARAS', 'HEWITT', 'BASH']\n",
      "done processing file  ../data/debateTranscripts/R10.txt ; shape= (627, 5) ; results written to file  ../data/debateTranscripts/R10_proc.csv\n",
      "\n",
      "18 ../data/debateTranscripts/R11.txt ../data/debateTranscripts/R11_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH'] ['KELLY', 'BAIER', 'WALLACE']\n",
      "done processing file  ../data/debateTranscripts/R11.txt ; shape= (608, 5) ; results written to file  ../data/debateTranscripts/R11_proc.csv\n",
      "\n",
      "19 ../data/debateTranscripts/R12.txt ../data/debateTranscripts/R12_proc.csv ['TRUMP', 'CRUZ', 'RUBIO', 'KASICH'] ['TAPPER', 'BASH', 'HEWITT', 'DINAN']\n",
      "done processing file  ../data/debateTranscripts/R12.txt ; shape= (315, 5) ; results written to file  ../data/debateTranscripts/R12_proc.csv\n",
      "\n",
      "21 ../data/debateTranscripts/D9.txt ../data/debateTranscripts/D9_proc.csv ['CLINTON', 'SANDERS'] ['BLITZER', 'BASH', 'LOUIS']\n",
      "done processing file  ../data/debateTranscripts/D9.txt ; shape= (595, 5) ; results written to file  ../data/debateTranscripts/D9_proc.csv\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Process the transcripts for all debates included in the schedule.\n",
    "\n",
    "#for row in df_dp.itertuples():\n",
    "#    print row.EventType\n",
    "\n",
    "#limit = 1\n",
    "#i = 0\n",
    "for ix, row in df_dp.iterrows():\n",
    "    #i+=1;\n",
    "    #if (i>limit):\n",
    "    #    break\n",
    "        \n",
    "    #print ix, row['EventType']\n",
    "    \n",
    "    prefix = '../data/debateTranscripts/'\n",
    "    if (row['Candidates']==\"CANCELLED\"):\n",
    "        continue\n",
    "    \n",
    "    candidates = get_candidates(row['Candidates'])\n",
    "    moderators = get_moderators(row['Moderators'])\n",
    "    audience = get_audience()\n",
    "    \n",
    "    infilename = prefix + get_infilename(row)\n",
    "    outfilename = prefix + get_outfilename(row)\n",
    "    \n",
    "    print ix, infilename, outfilename, candidates, moderators\n",
    "    #print\n",
    "    process_transcript(infilename, outfilename, candidates, moderators, audience)\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### DO NOT USE BELOW THIS POINT ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', '', 'blah '), ('TRUMP', 'candidate', 'TRUMP: blah. '), ('applause', 'audience', '(applause)'), ('CRUZ', 'candidate', 'CRUZ: blah '), ('applause', 'audience', '(applause, laughter)'), ('', '', ' blah')]\n"
     ]
    }
   ],
   "source": [
    "testline = \"blah TRUMP: blah. (applause) CRUZ: blah (applause, laughter) blah\"\n",
    "audience = ['APPLAUSE', 'BOOING', 'CHEERING', 'LAUGHTER']\n",
    "candidates = ['TRUMP', 'CRUZ', 'CARSON']\n",
    "#print get_candidate_splits(testline, candidates)\n",
    "print get_splits_by_speaker(testline, candidates, [], audience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\n"
     ]
    }
   ],
   "source": [
    "teststring = ' '\n",
    "print '\"' + teststring.strip() + '\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TRUMP|CARSON|CRUZ):\n"
     ]
    }
   ],
   "source": [
    "testlist = ['TRUMP', 'CARSON', 'CRUZ']\n",
    "pattern = '(' + '|'.join(testlist) + '):'\n",
    "print pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['applause']\n",
      "<callable-iterator object at 0x1068e1190>\n",
      "group=\"applause\" 18 27\n",
      "[('applause', 'candidate', 18)]\n",
      "[('applause', 'candidate', 'Ramos [fsd]: blah '), '[applause] blah']\n"
     ]
    }
   ],
   "source": [
    "#testline = \"Trump: blah about Carson. [applause] Trump: blah. Carson: blah. (applause)\"\n",
    "#testline = \"blah (applause) talking. (applause) More text. (applause)\"\n",
    "testline = \"Ramos [fsd]: blah [applause] blah\"\n",
    "\n",
    "#pattern = r\"(?i)trump\"  # Also works (like cypher).\n",
    "#pattern = r\"(trump|carson)\"\n",
    "#matched = re.findall(pattern, testline, re.IGNORECASE)\n",
    "#print matched\n",
    "\n",
    "#compiled_pattern = re.compile(\"(?=(trump|carson):)\", re.IGNORECASE)\n",
    "#compiled_pattern = re.compile(\"(trump|carson):\", re.IGNORECASE)\n",
    "compiled_pattern = re.compile(\"[\\[\\(](applause|booing)\", re.IGNORECASE)\n",
    "#compiled_pattern = re.compile(\"(ramos|salinas)(?: *\\[[a-z ]*\\])?:\", re.IGNORECASE)\n",
    "\n",
    "matched = compiled_pattern.findall(testline)\n",
    "print matched  # findall returns a list of strings\n",
    "\n",
    "matched = compiled_pattern.finditer(testline)\n",
    "print matched  # finditer returns an iterator over match objects\n",
    "\n",
    "splits = []\n",
    "for m in matched:\n",
    "    print 'group=\"'+m.group(1)+'\"', m.start(), m.end()\n",
    "    splits.append( (m.group(1), 'candidate', m.start()) )\n",
    "print splits\n",
    "\n",
    "# Good for candidate, moderator\n",
    "chunks = []\n",
    "ix_end = 0\n",
    "for split in splits:\n",
    "    ix_start = ix_end\n",
    "    ix_end = split[2]\n",
    "    speaker_name = split[0]\n",
    "    speaker_type = split[1]\n",
    "    chunks.append( ( speaker_name, speaker_type, testline[ix_start:ix_end] )  )\n",
    "chunks.append( testline[ix_end:len(testline)] )\n",
    "    \n",
    "print chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Debate names.\n",
    "candidates = ['TRUMP', 'BUSH', 'WALKER', 'HUCKABEE', 'CARSON', 'CRUZ', 'RUBIO', 'PAUL', 'CHRISTIE', 'KASICH', 'CROSSTALK', 'UNKNOWN']\n",
    "moderators = ['KELLY', 'BAIER', 'WALLACE']\n",
    "audience = ['APPLAUSE', 'BOOING', 'LAUGHTER', 'CHEERING']\n",
    "print 'done'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splits= [0]\n",
      "['', 'Trump: blah blah. Trump: blah.']\n"
     ]
    }
   ],
   "source": [
    "\"xxxxABCDyyyy\".find(\"ABC\")\n",
    "\n",
    "#testline = \"blah CARSON: blah. Trump: Blah blah (Laughter, booing, applause) More txt\"\n",
    "testline = \"Trump: blah blah. Trump: blah.\"\n",
    "#testline = \"blah (applause) talking. (applause) More text. (applause)\"\n",
    "splits = []\n",
    "#print filter(lambda x: x>=0, map(testline.lower().find, map(str.lower, candidates)))\n",
    "splits = filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: y.lower()+':', candidates+moderators)))\n",
    "#splits += filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: '('+y.lower(), audience)))\n",
    "#splits += filter(lambda x: x>=0, map(testline.lower().find, map(lambda y: y.lower()+')', audience)))\n",
    "#splits += map(lambda x: len(testline)-len(x[0]), map(testline.lower().split, map(lambda y: y.lower()+')', audience)))\n",
    "#splits += filter(lambda x: x>0, map(lambda x: len(testline)-len(x[0]), map(testline.lower().split, map(lambda y: y.lower()+')', audience))))\n",
    "#splits += map(lambda z: len(testline)-len(z[1]), \n",
    "#              filter(lambda x: len(x)>1, \n",
    "#                     map(testline.lower().split, \n",
    "#                         map(lambda y: y.lower()+')', audience))))\n",
    "splits += filter(lambda z: len(z)>1, [testline.split(x) for x in [y.lower()+')' for y in audience]])\n",
    "\n",
    "#splits += map(testline.lower().split, map(lambda y: y.lower()+')', audience))\n",
    "#splits += filter(lambda z: len(z)>1, map(testline.lower().split, map(lambda y: y.lower()+')', audience)))\n",
    "\n",
    "splits.sort()\n",
    "print 'splits=', splits\n",
    "\n",
    "#c = [(m.start(), m.end()-1) for m in re.finditer(r'\\S+', a)]\n",
    "chunks = []\n",
    "ix_end = 0\n",
    "for ix in splits:\n",
    "    ix_start = ix_end\n",
    "    ix_end = ix\n",
    "    chunks.append( testline[ix_start:ix_end] )\n",
    "chunks.append( testline[ix_end:len(testline)] )\n",
    "    \n",
    "print chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TRUMP']\n",
      "['BOOING', 'LAUGHTER', 'booing', 'laughter']\n",
      "['TRUMP', 'BOOING', 'LAUGHTER', 'booing', 'laughter']\n"
     ]
    }
   ],
   "source": [
    "testline = \"blah CARSON: blah. TRUMP: Blah blah (Laughter, booing)\"\n",
    "print filter(lambda x: x.lower()+':' in testline.lower(), candidates+moderators)\n",
    "print filter(lambda x: x.lower() in testline.lower(), audience)\n",
    "print ( filter(lambda x: x.lower()+':' in testline.lower(), candidates+moderators) + \n",
    "       filter(lambda x: x.lower() in testline.lower(), audience) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testline = \"TRUMP: Blah blah\"\n",
    "reduce(lambda x,y: x or y, map(testline.startswith, candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#testline = \"TRUMP: I will not make the pledge at this time.\"\n",
    "testline = \"(LAUGHTER, BOOING)\"\n",
    "print is_new_speaker(testline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>time</th>\n",
       "      <th>duration</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, speaker, speaker_type, time, duration, topic]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe for debate info.\n",
    "#cols = ['text', 'speaker', 'speaker_type', 'time', 'duration', 'topic']\n",
    "#df = pd.DataFrame(columns=cols)\n",
    "#df = df.append({'name': 'Zed', 'age': 9, 'height': 2}, ignore_index=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.shape\n",
    "df.tail(10)\n",
    "df.to_csv(\"transcript_v2_proc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP: I will not make the pledge at this time. 47\n",
      "new_speaker!\n",
      "BAIER: OK. Alright. 19\n",
      "new_speaker!\n",
      "Enough. 7\n",
      "no new speaker\n",
      "KELLY: Gentlemen, our first round of questions is on the subject of electability in the general election. 105\n",
      "new_speaker!\n",
      "and we start tonight with you, Dr. Carson. 42\n",
      "no new speaker\n"
     ]
    }
   ],
   "source": [
    "with open('transcript_test.txt') as infile:\n",
    "    for line in infile:\n",
    "        line = line.strip()\n",
    "        if len(line)==0:\n",
    "            continue\n",
    "        print line, len(line)\n",
    "        if is_new_speaker(line):\n",
    "            print \"new_speaker!\"\n",
    "        else:\n",
    "            print \"no new speaker\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "test_list = [4,6,3]\n",
    "test_list.sort()\n",
    "print test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP 5\n",
      "TUMP\n",
      "TRMP\n",
      "TRUP\n",
      "CARSON 6\n",
      "CRSON\n",
      "CASON\n",
      "CARON\n",
      "CARSN\n",
      "WALLACE 7\n",
      "WLLACE\n",
      "WALACE\n",
      "WALACE\n",
      "WALLCE\n",
      "WALLAE\n",
      "TRUMP: blah. CARSON: blah. Trump: blah. WALLACE: blah\n"
     ]
    }
   ],
   "source": [
    "correct_words = ['TRUMP', 'CARSON', \"WALLACE\"]\n",
    "test_string = 'TUMP: blah. CRSON: blah. Trump: blah. WAlace: blah'\n",
    "for correct_word in correct_words:\n",
    "    word_len = len(correct_word)\n",
    "    print correct_word, word_len\n",
    "    for i in range(1,word_len-1):\n",
    "        #print i\n",
    "        missp = correct_word[0:i]+correct_word[i+1:word_len]\n",
    "        print missp\n",
    "        #test_string.replace(missp, correct_word)\n",
    "        pattern = re.compile(missp, re.IGNORECASE)\n",
    "        test_string = pattern.sub(correct_word, test_string)\n",
    "print test_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUMP: blah\n"
     ]
    }
   ],
   "source": [
    "test_line = \"TUMP: blah\"\n",
    "import re\n",
    "pattern = re.compile(\"TUMP\", re.IGNORECASE)\n",
    "test_line = pattern.sub(\"TRUMP\", test_line)\n",
    "print test_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bye bye bye'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "pattern = re.compile(\"hello\", re.IGNORECASE)\n",
    "pattern.sub(\"bye\", \"hello HeLLo HELLO\")\n",
    "## 'bye bye bye'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello python \n"
     ]
    }
   ],
   "source": [
    "my_string=\"hello python world , i'm a beginner \"\n",
    "print my_string.split(\"world\",1)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['a', 'b']\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
