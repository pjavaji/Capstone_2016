{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Purpose:  Use supervised learning to train a classifier to predict candidate-sentiment for tweets.\n",
    "#           Evaluate multiple combinations of models and features.\n",
    "#           Use a 70/30 train/test split to estimate performance.\n",
    "#           Train final featurizer and model on full training set and save to file.\n",
    "# Author:  Carol Sniegoski\n",
    "# Date:  05/16/16\n",
    "# Course:  MAS DSE capstone, Spring 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # for featurizing using term frequencies\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # for featurizing using word n-grams\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "#from textblob import TextBlob\n",
    "#from textblob import Blobber\n",
    "#from textblob.taggers import NLTKTagger\n",
    "#from textblob.sentiments import NaiveBayesAnalyzer\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function defs.\n",
    "\n",
    "# return string with non-ascii chars removed\n",
    "def to_ascii(s):\n",
    "    returnstr = s.strip()\n",
    "    returnstr = \"\".join([ch for ch in returnstr if ord(ch)< 128])\n",
    "    return returnstr\n",
    "\n",
    "# Return df containing 'fraction' fraction of the original df,\n",
    "# with each value in column 'col' equally represented.\n",
    "def sample_equally( df, col, fraction ):\n",
    "    n = int(df.shape[0] * fraction)  # Get the total number of records to sample.\n",
    "    vals = pd.unique(df[col].values.ravel())  # Get the class labels.\n",
    "    n_to_sample = int(n/len(vals))   # Get the number of records to sample from each class.\n",
    "    \n",
    "    samples = []\n",
    "    for val in vals:\n",
    "        #samples.append( df[df[col]==val].sample(n=n_to_sample) )  # This should work in python 0.16.1\n",
    "        rows = np.random.choice(df[df[col]==val].index.values, n_to_sample)\n",
    "        sampled_df = df.ix[rows]\n",
    "        samples.append(sampled_df)\n",
    "    \n",
    "    result = pd.concat(samples)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Split dataframe into test/train set and validation set.\n",
    "# Return tuple of ( train/test df, validation df ).\n",
    "def get_validation_splits(df, label_field, validation_size=0.3):\n",
    "    sss = StratifiedShuffleSplit(df[label_field], 1, validation_size, random_state=0)\n",
    "    print len(sss)\n",
    "\n",
    "    for train_index, test_index in sss:\n",
    "        print len(train_index), len(test_index)\n",
    "        print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        #df_trainTest, df_validate = df.ix[train_index], df.ix[test_index]\n",
    "        #df_trainTest, df_validate = df.loc[train_index], df.loc[test_index]\n",
    "        df_trainTest, df_validate = df.iloc[train_index], df.iloc[test_index]\n",
    "\n",
    "        #print df_trainTest, df_validate\n",
    "\n",
    "    return df_trainTest, df_validate\n",
    "\n",
    "# From newer version of python.\n",
    "def cohen_kappa_score(y1, y2, labels=None, weights=None):\n",
    "    confusion = confusion_matrix(y1, y2, labels=labels)\n",
    "    n_classes = confusion.shape[0]\n",
    "    sum0 = np.sum(confusion, axis=0)\n",
    "    sum1 = np.sum(confusion, axis=1)\n",
    "    expected = np.outer(sum0, sum1) / np.sum(sum0)\n",
    "\n",
    "    if weights is None:\n",
    "        w_mat = np.ones([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat.flat[:: n_classes + 1] = 0\n",
    "    elif weights == \"linear\" or weights == \"quadratic\":\n",
    "        w_mat = np.zeros([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat += np.arange(n_classes)\n",
    "        if weights == \"linear\":\n",
    "            w_mat = np.abs(w_mat - w_mat.T)\n",
    "        else:\n",
    "            w_mat = (w_mat - w_mat.T) ** 2\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kappa weighting type.\")\n",
    "\n",
    "    k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
    "    return 1 - k\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20151013.csv\r\n",
      "2016211.csv\r\n",
      "\u001b[34mML_tagged\u001b[m\u001b[m/\r\n",
      "candidatesentiment_fromDebbie_05-14-16.csv\r\n",
      "candidatesentiment_fromDebbie_05-17-16.csv\r\n",
      "candidatesentiment_validationSet_random_05-19-16.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16.bak.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16_2.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16_2_LinearSVC_char3and4grams_predicted.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16_2_Logistic_huberLossL2_termFrequency_predicted.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-20-16_2_predicted.csv\r\n",
      "candidatesentiment_validationSet_random_caslabeled_05-21-16_2_predicted_termFrequency_MultinomialNB.csv\r\n",
      "sentimentsamples_random_05-18-16.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Locate the data.\n",
    "%ls ../data/candidatesentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Set the names of the cleaned text field and the class label field,\n",
    "# to be used in the sampling, featurizing, and classification steps.\n",
    "clean_text = 'ascii_clean'  # This is where the cleaned text will be put.\n",
    "label_field = 'label' # This is where the labels will be put.\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356344, 4)\n",
      "['candidate' 'sentiment' 'id_str' 'text']\n"
     ]
    }
   ],
   "source": [
    "# Load data file.\n",
    "\n",
    "prefix = \"../data/candidatesentiment/\"\n",
    "#filename = \"candidatesentiment_fromDebbie_05-14-16.csv\"\n",
    "#filename = \"candidatesentiment_fromDebbie_05-17-16.csv\"\n",
    "filename = \"sentimentsamples_random_05-18-16.csv\"\n",
    "\n",
    "columns = [\"candidate\", \"sentiment\", \"id_str\", \"text\"]\n",
    "df = pd.read_csv(prefix + filename, header=None, names=columns)\n",
    "print df.shape\n",
    "print df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ascii_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015_10_11</th>\n",
       "      <td>\"Latinos &amp;amp; immigrants support Donald Trump, \"Doing it Right\" http://t.co/ss8uq9w6Vh \"</td>\n",
       "      <td>latinos   immigrants support donald trump, doing it right url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015_10_11</th>\n",
       "      <td>\"#Trump2016 #Trump #TrumpTrain  OKAY CHERI KEEP UP THE LIES I KNOW YOU ARE FAR SUPERIOR TO ALL HUMAN LIFE.DISHONEST! https://t.co/GA6q1H1fge \"</td>\n",
       "      <td>#trump2016 #trump #trumptrain  okay cheri keep up the lies i know you are far superior to all human life dishonest! url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015_10_11</th>\n",
       "      <td>\"@bensonmya123 @LindaEpai457450 @TrumpNewsNetwrk That's a ridiculous statement. Trump supporters understand U.S. citizens being SCREWED. \"</td>\n",
       "      <td>@bensonmya123 @lindaepai457450 @trumpnewsnetwrk thats a ridiculous statement  trump supporters understand u s  citizens being screwed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      text  \\\n",
       "2015_10_11                                                       \"Latinos &amp; immigrants support Donald Trump, \"Doing it Right\" http://t.co/ss8uq9w6Vh \"   \n",
       "2015_10_11  \"#Trump2016 #Trump #TrumpTrain  OKAY CHERI KEEP UP THE LIES I KNOW YOU ARE FAR SUPERIOR TO ALL HUMAN LIFE.DISHONEST! https://t.co/GA6q1H1fge \"   \n",
       "2015_10_11      \"@bensonmya123 @LindaEpai457450 @TrumpNewsNetwrk That's a ridiculous statement. Trump supporters understand U.S. citizens being SCREWED. \"   \n",
       "\n",
       "                                                                                                                                        ascii_clean  \n",
       "2015_10_11                                                                           latinos   immigrants support donald trump, doing it right url   \n",
       "2015_10_11                 #trump2016 #trump #trumptrain  okay cheri keep up the lies i know you are far superior to all human life dishonest! url   \n",
       "2015_10_11  @bensonmya123 @lindaepai457450 @trumpnewsnetwrk thats a ridiculous statement  trump supporters understand u s  citizens being screwed    "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean the 'text' field.\n",
    "\n",
    "# Convert to ascii\n",
    "df['ascii'] = df['text'].apply(to_ascii)\n",
    "df[clean_text] = df['ascii']\n",
    "\n",
    "# Remove hashtags\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"#([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove handles\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"@([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove URLs\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \" \")\n",
    "# Replace URLs with \"URL\"\n",
    "df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \"URL\")\n",
    "\n",
    "# Remove punctuation symbols - but not @ or #\n",
    "df[clean_text] = df[clean_text].str.replace(r\"(['';:%()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"(['';:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"([;:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "df[clean_text] = df[clean_text].str.replace(r\"([.-])\", \" \")\n",
    "\n",
    "# Remove eol symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"\\n\", \" \")\n",
    "\n",
    "# Remove &x symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"&[a-z]+\", \" \")\n",
    "\n",
    "# Convert to lowercase\n",
    "df[clean_text] = df[clean_text].str.lower()\n",
    "\n",
    "#print df[df['ascii']!=df[clean_text]][['ascii', 'K_sentiment']].head(10)\n",
    "df[['text', clean_text]].head(3)\n",
    "#df[df['ascii'].str.contains(\"\\n\")][['text', 'ascii']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump_pos      (Count: 37962, Frequency: 0.11)\n",
      "Cruz_pos       (Count: 37668, Frequency: 0.11)\n",
      "Sanders_pos    (Count: 37544, Frequency: 0.11)\n",
      "Clinton_pos    (Count: 37254, Frequency: 0.10)\n",
      "Trump_neg      (Count: 36728, Frequency: 0.10)\n",
      "Clinton_neg    (Count: 36594, Frequency: 0.10)\n",
      "Rubio_pos      (Count: 33815, Frequency: 0.09)\n",
      "Cruz_neg       (Count: 33743, Frequency: 0.09)\n",
      "Sanders_neg    (Count: 33066, Frequency: 0.09)\n",
      "Rubio_neg      (Count: 31970, Frequency: 0.09)\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Populate the label_field.\n",
    "df[label_field] = df['candidate'] + '_' + df['sentiment']\n",
    "\n",
    "# Show the class frequencies.\n",
    "counts = df[label_field].value_counts()\n",
    "total = counts.sum()\n",
    "\n",
    "counts = counts.apply(lambda x: (\"Count: %d\" % x, \"Frequency: %.2f\" % (float(x)/total)) )\n",
    "\n",
    "#print(\"%.2f\" % a)\n",
    "#string = 'string%d' % (i,)\n",
    "\n",
    "print counts\n",
    "print type(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.cross_validation.StratifiedShuffleSplit'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "### \n",
    "# Set aside the validation set.\n",
    "\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(df[label_field], 1, test_size=0.3, random_state=0)\n",
    "print type(sss)\n",
    "\n",
    "X = df[clean_text]\n",
    "y = df[label_field]\n",
    "print type(X)\n",
    "\n",
    "for train_index, test_index in sss:\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "print type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump' 'Clinton' 'Sanders' 'Rubio' 'Cruz']\n",
      "Trump\n",
      "1\n",
      "52283 22407\n",
      "('TRAIN:', array([29003, 15337, 68002, ..., 25273,  6253, 37646]), 'TEST:', array([62288, 11032, 58251, ..., 62107, 57237, 68296]))\n",
      "Clinton\n",
      "1\n",
      "51693 22155\n",
      "('TRAIN:', array([10326, 40409, 63825, ..., 54243, 64399, 48349]), 'TEST:', array([20926, 72099, 29490, ..., 11564, 24082, 41166]))\n",
      "Sanders\n",
      "1\n",
      "49427 21183\n",
      "('TRAIN:', array([35163, 49675, 25215, ..., 24577, 54898, 68655]), 'TEST:', array([25835, 36616, 44740, ...,  9706, 63430, 50877]))\n",
      "Rubio\n",
      "1\n",
      "46049 19736\n",
      "('TRAIN:', array([24111, 18399, 52532, ..., 40835, 26667,   151]), 'TEST:', array([55855, 43903, 43681, ..., 56443, 12591, 13572]))\n",
      "Cruz\n",
      "1\n",
      "49987 21424\n",
      "('TRAIN:', array([57377,  1402, 46261, ...,  7322, 19662, 69484]), 'TEST:', array([20578, 57128, 61704, ..., 47184, 41211, 44732]))\n",
      "5 5\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Classes are balanced, so no need to under- or oversample. Just use the original unsampled data.\n",
    "\n",
    "# True if you want to set aside a validation set upfront.\n",
    "do_validation = True\n",
    "\n",
    "df_samples = []\n",
    "sample_names = []\n",
    "df_validation_splits = []\n",
    "    \n",
    "#df_samples = [ df ]\n",
    "#sample_names = [ 'original data' ]\n",
    "\n",
    "# Treat each candidate as a separate sample.\n",
    "candidates = df['candidate'].unique()\n",
    "print candidates\n",
    "\n",
    "for candidate in candidates:\n",
    "    sample_df = df[ df['candidate']==candidate]\n",
    "    #sample_df = df[ df['candidate']==candidate].copy(deep=True)\n",
    "    #print sample_df.shape\n",
    "    #print sample_df.head(3)\n",
    "\n",
    "    if do_validation:\n",
    "        print candidate\n",
    "        trainTest_df, validate_df = get_validation_splits( sample_df, label_field, 0.3 )\n",
    "        df_samples.append( trainTest_df )\n",
    "        df_validation_splits.append( validate_df )\n",
    "    else:\n",
    "        #df_samples.append( df[ df['candidate']==candidate] )\n",
    "        df_samples.append( sample_df )\n",
    "    sample_names.append( candidate )\n",
    "    #df_samples.append(sample_equally( df, label_field, data_fraction ))\n",
    "    #sample_names.append( str(data_fraction)+' random sample' )\n",
    "\n",
    "print len(df_samples), len(df_validation_splits)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "5\n",
      "5\n",
      "(52283,)\n",
      "5\n",
      "(22407,)\n"
     ]
    }
   ],
   "source": [
    "# Convert data & their class labels into ndarrays.\n",
    "X_samples = []\n",
    "y_samples = []\n",
    "\n",
    "for df_sample in df_samples:\n",
    "    X_samples.append(df_sample[clean_text].values)\n",
    "    y_samples.append(df_sample[label_field].values)\n",
    "    \n",
    "if do_validation:\n",
    "    X_validation_splits = []\n",
    "    y_validation_splits = []\n",
    "    for df_validation_split in df_validation_splits:\n",
    "        X_validation_splits.append(df_validation_split[clean_text].values)\n",
    "        y_validation_splits.append(df_validation_split[label_field].values)\n",
    "\n",
    "print type(X_samples[0])\n",
    "print len(X_samples)\n",
    "print len(y_samples)\n",
    "print X_samples[0].shape\n",
    "\n",
    "print len(X_validation_splits)\n",
    "print X_validation_splits[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of types of feature vectors to use.\n",
    "# Add feature vectors to this list by running one or more of the feature-generation cells below.\n",
    "\n",
    "feature_vector_lists = []\n",
    "feature_vector_validation_lists = []\n",
    "feature_names = []\n",
    "featurizers = []\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump (52283, 60677)\n",
      "Clinton (51693, 58368)\n",
      "Sanders (49427, 57571)\n",
      "Rubio (46049, 53090)\n",
      "Cruz (49987, 57003)\n",
      "['char3and4grams']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using character n-grams.\n",
    "\n",
    "this_feature_name = \"char3and4grams\"\n",
    "this_feature_vector_list = []\n",
    "this_feature_vector_validation_list = []\n",
    "\n",
    "ngram_min_size = 3\n",
    "ngram_max_size = 4\n",
    "\n",
    "#test_string = [\"I really like python, it's pretty awesome.\"]\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char'  # create character ngrams\n",
    "                             )\n",
    "\n",
    "for X_sample, X_validation_split, sample_name in zip(X_samples, X_validation_splits, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    this_feature_vector_validation_list.append( vectorizer.transform(X_validation_split) )\n",
    "    #feature_names.append( this_feature_name + ', ' + sample_name )\n",
    "\n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_vector_validation_lists.append(this_feature_vector_validation_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names\n",
    "    \n",
    "#print('{1}-grams: {0}'.format(vect.get_feature_names(), ngram_size))\n",
    "#print 'Number of char n-grams:', len(vectorizer.get_feature_names())\n",
    "#print vectorizer.get_feature_names()[1000:1025]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump (52283, 35509)\n",
      "Clinton (51693, 35765)\n",
      "Sanders (49427, 33618)\n",
      "Rubio (46049, 35306)\n",
      "Cruz (49987, 33953)\n",
      "['char 3grams', 'word 1- & 2grams']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using word n-grams.\n",
    "\n",
    "this_feature_name = 'word 1- & 2grams'\n",
    "this_feature_vector_list = []\n",
    "this_feature_vector_validation_list = []\n",
    "\n",
    "ngram_min_size = 1\n",
    "ngram_max_size = 2\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(ngram_min_size,ngram_max_size),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,      # min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,    # max percent of docs a token can appear in (if a float value)\n",
    "                             analyzer='word'  # create word ngrams; this is the default\n",
    "                             )\n",
    "\n",
    "for X_sample, X_validation_split, sample_name in zip(X_samples, X_validation_splits, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    this_feature_vector_validation_list.append( vectorizer.transform(X_validation_split) )\n",
    "    #feature_names.append( this_feature_name + ', ' + sample_name )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_vector_validation_lists.append(this_feature_vector_validation_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump (52283, 9732)\n",
      "Clinton (51693, 9696)\n",
      "Sanders (49427, 9261)\n",
      "Rubio (46049, 8310)\n",
      "Cruz (49987, 8784)\n",
      "['char3and4grams', 'term freq']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using term frequency (same as word 1-grams, presumably).\n",
    "\n",
    "this_feature_name = 'term freq'\n",
    "this_feature_vector_list = []\n",
    "this_feature_vector_validation_list = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5,     # Min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,   # Max percent of docs a token can appear in (if a float value)\n",
    "                             sublinear_tf = True,   # Need to look up what this is\n",
    "                             use_idf = False)  # Don't use inverse document frequency weighting\n",
    "\n",
    "for X_sample, X_validation_split, sample_name in zip(X_samples, X_validation_splits, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    this_feature_vector_validation_list.append( vectorizer.transform(X_validation_split) )\n",
    "    #feature_names.append( this_feature_name + ', ' + sample_name )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_vector_validation_lists.append(this_feature_vector_validation_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump (52283, 9732)\n",
      "Clinton (51693, 9696)\n",
      "Sanders (49427, 9261)\n",
      "Rubio (46049, 8310)\n",
      "Cruz (49987, 8784)\n",
      "['char 3grams', 'word 1- & 2grams', 'term freq', 'tfidf']\n"
     ]
    }
   ],
   "source": [
    "# Create feature vectors using tfidf.\n",
    "\n",
    "this_feature_name = 'tfidf'\n",
    "this_feature_vector_list = []\n",
    "this_feature_vector_validation_list = []\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df = 5,     # Min number of docs a token must appear in (if an integer value)\n",
    "                             max_df = 0.8,   # Max percent of docs a token can appear in (if a float value)\n",
    "                             sublinear_tf = True,   # Need to look up what this is\n",
    "                             use_idf = True)  # Use idf\n",
    "\n",
    "for X_sample, X_validation_split, sample_name in zip(X_samples, X_validation_splits, sample_names):\n",
    "    this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "    this_feature_vector_validation_list.append( vectorizer.transform(X_validation_split) )\n",
    "    #feature_names.append( this_feature_name + ', ' + sample_name )\n",
    "    \n",
    "feature_vector_lists.append(this_feature_vector_list)\n",
    "feature_vector_validation_lists.append(this_feature_vector_validation_list)\n",
    "feature_names.append(this_feature_name)\n",
    "\n",
    "for feature_vector, sample_name in zip(this_feature_vector_list, sample_names):\n",
    "    print sample_name, feature_vector.shape\n",
    "print feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize list of classifiers to use.\n",
    "# Add classifiers to this list by running one or more of the classifier-creation cells below.\n",
    "\n",
    "classifiers = []\n",
    "classifier_names = []\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['Multinomial NB']\n"
     ]
    }
   ],
   "source": [
    "# Create Naive Bayes classifiers.\n",
    "\n",
    "# Multinomial NaiveBayes. Commonly used for text classification.\n",
    "classifier_names.append(\"Multinomial NB\")\n",
    "classifiers.append(MultinomialNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "                                 fit_prior=True))  # Fit priors based on training data\n",
    "                  \n",
    "# Bernoulli NaiveBayes. Commonly used for text classification for short documents.\n",
    "# Expects boolean features (e.g., word occurence/nonoccurence instead of term frequency or tfidf).\n",
    "#classifier_names.append('Bernoulli NB')\n",
    "#classifiers.append(BernoulliNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "#                               binarize=0,       # Threshold for binarizing the input features\n",
    "#                               fit_prior=True))  # Fit priors based on training data\n",
    "print 'done'\n",
    "print classifier_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "['Multinomial NB', 'LinearSVC', 'Logistic']\n"
     ]
    }
   ],
   "source": [
    "# Create SVM / logistic regression classifiers.\n",
    "\n",
    "# SVM with linear kernel.\n",
    "classifier_names.append('LinearSVC')\n",
    "classifiers.append(LinearSVC(random_state=0)) \n",
    "\n",
    "# Logistic regression (sometimes called maxent).\n",
    "classifier_names.append('Logistic')\n",
    "classifiers.append(SGDClassifier(loss='hinge', \n",
    "                                 penalty='l2', \n",
    "                                 alpha=1e-3, \n",
    "                                 n_iter=100, \n",
    "                                 random_state=0))\n",
    "# Regular logistic regression.\n",
    "#classifier_names.append('Logistic_regular')\n",
    "#classifiers.append(LogisticRegression())\n",
    "\n",
    "\n",
    "print 'done'\n",
    "print classifier_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize scores.\n",
    "scores = {}\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Initialize labeled results.\n",
    "labeled_results = {}\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning classifier Multinomial NB\n",
      "(52283, 60677) (22407, 60677)\n",
      "(51693, 58368) (22155, 58368)\n",
      "(49427, 57571) (21183, 57571)\n",
      "(46049, 53090) (19736, 53090)\n",
      "(49987, 57003) (21424, 57003)\n",
      "   done with char3and4grams\n",
      "(52283, 9732) (22407, 9732)\n",
      "(51693, 9696) (22155, 9696)\n",
      "(49427, 9261) (21183, 9261)\n",
      "(46049, 8310) (19736, 8310)\n",
      "(49987, 8784) (21424, 8784)\n",
      "   done with term freq\n",
      "beginning classifier LinearSVC\n",
      "(52283, 60677) (22407, 60677)\n",
      "(51693, 58368) (22155, 58368)\n",
      "(49427, 57571) (21183, 57571)\n",
      "(46049, 53090) (19736, 53090)\n",
      "(49987, 57003) (21424, 57003)\n",
      "   done with char3and4grams\n",
      "(52283, 9732) (22407, 9732)\n",
      "(51693, 9696) (22155, 9696)\n",
      "(49427, 9261) (21183, 9261)\n",
      "(46049, 8310) (19736, 8310)\n",
      "(49987, 8784) (21424, 8784)\n",
      "   done with term freq\n",
      "beginning classifier Logistic\n",
      "(52283, 60677) (22407, 60677)\n",
      "(51693, 58368) (22155, 58368)\n",
      "(49427, 57571) (21183, 57571)\n",
      "(46049, 53090) (19736, 53090)\n",
      "(49987, 57003) (21424, 57003)\n",
      "   done with char3and4grams\n",
      "(52283, 9732) (22407, 9732)\n",
      "(51693, 9696) (22155, 9696)\n",
      "(49427, 9261) (21183, 9261)\n",
      "(46049, 8310) (19736, 8310)\n",
      "(49987, 8784) (21424, 8784)\n",
      "   done with term freq\n",
      "done training and validating classifiers\n"
     ]
    }
   ],
   "source": [
    "# Train classifiers on train/test set, test on the validation set.\n",
    "# Get scores every x iterations, for those classifiers for which one can control this in sklearn.\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    print 'beginning classifier ' + classifier_name\n",
    "    scores[classifier_name] = {}\n",
    "    labeled_results[classifier_name] = {}\n",
    "    for feature_vector_list, feature_vector_validation_list, feature_name \\\n",
    "    in zip(feature_vector_lists, feature_vector_validation_lists, feature_names):\n",
    "        scores[classifier_name][feature_name] = {}\n",
    "        labeled_results[classifier_name][feature_name] = {}\n",
    "\n",
    "        #for X, y_sample, sample_name in zip(feature_vector_list, y_samples, sample_names):\n",
    "        #    y_pred = cross_validation.cross_val_predict(classifier, X, y_sample, cv=cv)\n",
    "        #    scores[classifier_name][feature_name][sample_name] = ( y_sample, y_pred )\n",
    "\n",
    "        #for X, X_validation, y_sample, y_validation_split, sample_name in \\\n",
    "        #zip(feature_vector_list, feature_vector_validation_list, y_samples, y_validation_splits, sample_names):\n",
    "        for X, X_validation, y_sample, y_validation_split, df_validation_split, sample_name in \\\n",
    "        zip(feature_vector_list, feature_vector_validation_list, y_samples, y_validation_splits, df_validation_splits, sample_names):\n",
    "            \n",
    "            #y_pred = cross_validation.cross_val_predict(classifier, X, y_sample, cv=cv)\n",
    "            print X.shape, X_validation.shape\n",
    "            classifier.fit( X, y_sample )\n",
    "            y_pred = classifier.predict( X_validation )\n",
    "            scores[classifier_name][feature_name][sample_name] = ( y_validation_split, y_pred )\n",
    "            df_withNewLabel = df_validation_split.copy(deep=True)\n",
    "            df_withNewLabel['predicted'+ '_' + classifier_name + '_' + feature_name + '_' + sample_name] = y_pred\n",
    "            labeled_results[classifier_name][feature_name][sample_name] = ( df_withNewLabel )\n",
    "\n",
    "        print '   done with ' + feature_name\n",
    "    \n",
    "print 'done training and validating classifiers' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB, term freq, Trump\n",
      "(120, 9)\n",
      "Multinomial NB, term freq, Sanders\n",
      "(120, 9)\n",
      "Multinomial NB, term freq, Clinton\n",
      "(120, 9)\n",
      "Multinomial NB, term freq, Cruz\n",
      "(120, 9)\n",
      "Multinomial NB, term freq, Rubio\n",
      "(82, 9)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Write data with new labels to file.\n",
    "prefix = \"../data/candidatesentiment/output/\"\n",
    "filename = \"candidatesentiment_fromDebbie_05-14-16\"\n",
    "\n",
    "\n",
    "i = 0\n",
    "desired = [0, 1, 2, 3, 4, 5]\n",
    "for classifier_name in classifier_names:\n",
    "    for feature_name in feature_names:\n",
    "        for sample_name in sample_names:\n",
    "            if (i in desired):\n",
    "                print classifier_name + ', ' + feature_name + ', ' + sample_name\n",
    "                df = labeled_results[classifier_name][feature_name][sample_name]\n",
    "                print df.shape\n",
    "                new_label_field = 'predicted' + '_' + classifier_name + '_' + feature_name + '_' + sample_name\n",
    "                df.to_csv(prefix + filename + '_' + new_label_field + '.csv')\n",
    "            i+=1\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning classifier Multinomial NB\n",
      "   done with word 1- & 2grams\n",
      "   done with char 3grams\n",
      "   done with term freq\n",
      "   done with tfidf\n",
      "beginning classifier LinearSVC\n",
      "   done with word 1- & 2grams\n",
      "   done with char 3grams\n",
      "   done with term freq\n",
      "   done with tfidf\n",
      "beginning classifier Logistic\n",
      "   done with word 1- & 2grams\n",
      "   done with char 3grams\n",
      "   done with term freq\n",
      "   done with tfidf\n",
      "done training and testing classifiers\n"
     ]
    }
   ],
   "source": [
    "# Train and test classifiers using crossvalidation.\n",
    "# This will use all the types of sampling, features, and classifiers that were created.\n",
    "\n",
    "cv = 3  # Number of crossvalidation folds to use.\n",
    "#scores = {}\n",
    "#score_descriptions = []\n",
    "\n",
    "for classifier, classifier_name in zip(classifiers, classifier_names):\n",
    "    print 'beginning classifier ' + classifier_name\n",
    "    scores[classifier_name] = {}\n",
    "    for feature_vector_list, feature_name in zip(feature_vector_lists, feature_names):\n",
    "        scores[classifier_name][feature_name] = {}\n",
    "        for X, y_sample, sample_name in zip(feature_vector_list, y_samples, sample_names):\n",
    "            y_pred = cross_validation.cross_val_predict(classifier, X, y_sample, cv=cv)\n",
    "            scores[classifier_name][feature_name][sample_name] = ( y_sample, y_pred )\n",
    "            #scores[classifier_name][feature_name][sample_name] = cross_validation.cross_val_score(classifier, X, y_sample, cv=cv)\n",
    "            #scores.append( cross_validation.cross_val_score(classifier, X, y_sample, cv=cv) )\n",
    "            #score_descriptions.append( classifier_name + ', ' + feature_name + ', ' + sample_name )\n",
    "        print '   done with ' + feature_name\n",
    "    \n",
    "print 'done training and testing classifiers' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC\n",
      "\n",
      "term freq\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.83      0.82      0.83      9920\n",
      "Sanders_pos       0.85      0.85      0.85     11263\n",
      "\n",
      "avg / total       0.84      0.84      0.84     21183\n",
      "\n",
      "0.839116272483\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.86      0.86      0.86      9591\n",
      "  Rubio_pos       0.86      0.86      0.86     10145\n",
      "\n",
      "avg / total       0.86      0.86      0.86     19736\n",
      "\n",
      "0.860204702067\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.85      0.88      0.87     10978\n",
      "Clinton_pos       0.88      0.85      0.87     11177\n",
      "\n",
      "avg / total       0.87      0.87      0.87     22155\n",
      "\n",
      "0.865989618596\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.82      0.85      0.83     11018\n",
      "  Trump_pos       0.85      0.82      0.83     11389\n",
      "\n",
      "avg / total       0.83      0.83      0.83     22407\n",
      "\n",
      "0.833712679074\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.84      0.87      0.86     10123\n",
      "   Cruz_pos       0.88      0.85      0.87     11301\n",
      "\n",
      "avg / total       0.86      0.86      0.86     21424\n",
      "\n",
      "0.860997012696\n",
      "\n",
      "char3and4grams\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.79      0.79      0.79      9920\n",
      "Sanders_pos       0.82      0.81      0.82     11263\n",
      "\n",
      "avg / total       0.80      0.80      0.80     21183\n",
      "\n",
      "0.804040976255\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.85      0.82      0.83      9591\n",
      "  Rubio_pos       0.84      0.86      0.85     10145\n",
      "\n",
      "avg / total       0.84      0.84      0.84     19736\n",
      "\n",
      "0.840190514795\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.84      0.84      0.84     10978\n",
      "Clinton_pos       0.84      0.85      0.84     11177\n",
      "\n",
      "avg / total       0.84      0.84      0.84     22155\n",
      "\n",
      "0.842924847664\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.79      0.79      0.79     11018\n",
      "  Trump_pos       0.80      0.80      0.80     11389\n",
      "\n",
      "avg / total       0.80      0.80      0.80     22407\n",
      "\n",
      "0.795688847235\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.83      0.82      0.83     10123\n",
      "   Cruz_pos       0.84      0.85      0.85     11301\n",
      "\n",
      "avg / total       0.84      0.84      0.84     21424\n",
      "\n",
      "0.835978342046\n",
      "\n",
      "\n",
      "Multinomial NB\n",
      "\n",
      "term freq\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.83      0.79      0.81      9920\n",
      "Sanders_pos       0.83      0.86      0.84     11263\n",
      "\n",
      "avg / total       0.83      0.83      0.83     21183\n",
      "\n",
      "0.828116886182\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.84      0.80      0.82      9591\n",
      "  Rubio_pos       0.82      0.85      0.84     10145\n",
      "\n",
      "avg / total       0.83      0.83      0.83     19736\n",
      "\n",
      "0.828182002432\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.84      0.86      0.85     10978\n",
      "Clinton_pos       0.86      0.84      0.85     11177\n",
      "\n",
      "avg / total       0.85      0.85      0.85     22155\n",
      "\n",
      "0.851410516813\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.81      0.83      0.82     11018\n",
      "  Trump_pos       0.83      0.81      0.82     11389\n",
      "\n",
      "avg / total       0.82      0.82      0.82     22407\n",
      "\n",
      "0.818271076003\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.80      0.87      0.83     10123\n",
      "   Cruz_pos       0.87      0.80      0.83     11301\n",
      "\n",
      "avg / total       0.83      0.83      0.83     21424\n",
      "\n",
      "0.831637415982\n",
      "\n",
      "char3and4grams\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.79      0.84      0.82      9920\n",
      "Sanders_pos       0.85      0.80      0.83     11263\n",
      "\n",
      "avg / total       0.82      0.82      0.82     21183\n",
      "\n",
      "0.821366189869\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.83      0.83      0.83      9591\n",
      "  Rubio_pos       0.84      0.84      0.84     10145\n",
      "\n",
      "avg / total       0.84      0.84      0.84     19736\n",
      "\n",
      "0.837657073368\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.84      0.87      0.85     10978\n",
      "Clinton_pos       0.86      0.84      0.85     11177\n",
      "\n",
      "avg / total       0.85      0.85      0.85     22155\n",
      "\n",
      "0.850914014895\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.78      0.88      0.83     11018\n",
      "  Trump_pos       0.86      0.76      0.81     11389\n",
      "\n",
      "avg / total       0.82      0.82      0.82     22407\n",
      "\n",
      "0.817467755612\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.76      0.90      0.82     10123\n",
      "   Cruz_pos       0.90      0.74      0.81     11301\n",
      "\n",
      "avg / total       0.83      0.82      0.82     21424\n",
      "\n",
      "0.816560866318\n",
      "\n",
      "\n",
      "Logistic\n",
      "\n",
      "term freq\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.72      0.74      0.73      9920\n",
      "Sanders_pos       0.77      0.75      0.76     11263\n",
      "\n",
      "avg / total       0.75      0.75      0.75     21183\n",
      "\n",
      "0.747250153425\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.73      0.74      0.73      9591\n",
      "  Rubio_pos       0.75      0.74      0.75     10145\n",
      "\n",
      "avg / total       0.74      0.74      0.74     19736\n",
      "\n",
      "0.740119578435\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.70      0.84      0.76     10978\n",
      "Clinton_pos       0.81      0.64      0.72     11177\n",
      "\n",
      "avg / total       0.75      0.74      0.74     22155\n",
      "\n",
      "0.742902279395\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.67      0.87      0.76     11018\n",
      "  Trump_pos       0.83      0.58      0.68     11389\n",
      "\n",
      "avg / total       0.75      0.72      0.72     22407\n",
      "\n",
      "0.723122238586\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.70      0.83      0.76     10123\n",
      "   Cruz_pos       0.81      0.68      0.74     11301\n",
      "\n",
      "avg / total       0.76      0.75      0.75     21424\n",
      "\n",
      "0.747432785661\n",
      "\n",
      "char3and4grams\n",
      "\n",
      "  Sanders\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Sanders_neg       0.84      0.82      0.83      9920\n",
      "Sanders_pos       0.84      0.86      0.85     11263\n",
      "\n",
      "avg / total       0.84      0.84      0.84     21183\n",
      "\n",
      "0.841523863475\n",
      "  Rubio\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Rubio_neg       0.87      0.85      0.86      9591\n",
      "  Rubio_pos       0.86      0.88      0.87     10145\n",
      "\n",
      "avg / total       0.87      0.87      0.87     19736\n",
      "\n",
      "0.865474260235\n",
      "  Clinton\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Clinton_neg       0.86      0.89      0.87     10978\n",
      "Clinton_pos       0.88      0.85      0.87     11177\n",
      "\n",
      "avg / total       0.87      0.87      0.87     22155\n",
      "\n",
      "0.868833220492\n",
      "  Trump\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "  Trump_neg       0.83      0.85      0.84     11018\n",
      "  Trump_pos       0.85      0.83      0.84     11389\n",
      "\n",
      "avg / total       0.84      0.84      0.84     22407\n",
      "\n",
      "0.83714910519\n",
      "  Cruz\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Cruz_neg       0.85      0.87      0.86     10123\n",
      "   Cruz_pos       0.88      0.86      0.87     11301\n",
      "\n",
      "avg / total       0.87      0.87      0.87     21424\n",
      "\n",
      "0.865057879014\n",
      "\n",
      "\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Print results.\n",
    "\n",
    "for classifier_name, classifier_results in scores.items():\n",
    "    print classifier_name\n",
    "    print\n",
    "    for feature_name, feature_results in classifier_results.items():\n",
    "        print feature_name\n",
    "        print\n",
    "        #for sample_name, sample_scores in feature_results.items():\n",
    "        for sample_name, results in feature_results.items():\n",
    "            #print \"  \" + sample_name + \": mean=\" + str(sample_scores.mean()) + \", std=\" + str(sample_scores.std())\n",
    "            print \"  \" + sample_name\n",
    "            y, y_pred = results\n",
    "            #print type(results)\n",
    "            #print confusion_matrix( y, y_pred )\n",
    "            print classification_report( y, y_pred )\n",
    "            print metrics.accuracy_score( y, y_pred )\n",
    "            #print cohen_kappa_score( y, y_pred )\n",
    "            #print \n",
    "        print\n",
    "    print\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Define types final featurizer and classifier to use.\n",
    "\n",
    "final_featurizer_name = \"char3and4grams\"\n",
    "#final_featurizer = TfidfVectorizer(min_df = 5,   # Min number of docs a token must appear in (if an integer value)\n",
    "#                             max_df = 0.8,       # Max percent of docs a token can appear in (if a float value)\n",
    "#                             sublinear_tf = True,   # Need to look up what this is\n",
    "#                             use_idf = False)    # Don't use inverse document frequency weighting\n",
    "final_featurizer = CountVectorizer(ngram_range=(3,4),  # use n-gram sizes from min to max, inclusive\n",
    "                             min_df = 5,     # min number of docs a token must appear in\n",
    "                             max_df = .8,    # max percent of docs a token can appear in\n",
    "                             analyzer='char')  # create character ngrams\n",
    "                             \n",
    "\n",
    "final_classifier_name = \"LinearSVC\"\n",
    "#final_classifier = MultinomialNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "#                                 fit_prior=True)  # Fit priors based on training data\n",
    "# \n",
    "#classifiers.append(BernoulliNB(alpha=1.0,        # Use default Laplacian smoothing\n",
    "#                               binarize=0,       # Threshold for binarizing the input features\n",
    "#                               fit_prior=True))  # Fit priors based on training data\n",
    "final_classifier = LinearSVC(random_state=2016)\n",
    "#classifiers.append(SGDClassifier(loss='hinge', \n",
    "#                                 penalty='l2', \n",
    "#                                alpha=1e-3, \n",
    "#                                 n_iter=5, \n",
    "#                                 random_state=0))\n",
    "#final_classifier = LogisticRegression()\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump_pos      (Count: 37962, Frequency: 0.11)\n",
      "Cruz_pos       (Count: 37668, Frequency: 0.11)\n",
      "Sanders_pos    (Count: 37544, Frequency: 0.11)\n",
      "Clinton_pos    (Count: 37254, Frequency: 0.10)\n",
      "Trump_neg      (Count: 36728, Frequency: 0.10)\n",
      "Clinton_neg    (Count: 36594, Frequency: 0.10)\n",
      "Rubio_pos      (Count: 33815, Frequency: 0.09)\n",
      "Cruz_neg       (Count: 33743, Frequency: 0.09)\n",
      "Sanders_neg    (Count: 33066, Frequency: 0.09)\n",
      "Rubio_neg      (Count: 31970, Frequency: 0.09)\n",
      "dtype: object\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Check that the main df is still ok.\n",
    "# Show the class frequencies.\n",
    "counts = df[label_field].value_counts()\n",
    "total = counts.sum()\n",
    "\n",
    "counts = counts.apply(lambda x: (\"Count: %d\" % x, \"Frequency: %.2f\" % (float(x)/total)) )\n",
    "\n",
    "#print(\"%.2f\" % a)\n",
    "#string = 'string%d' % (i,)\n",
    "\n",
    "print counts\n",
    "print type(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl                   Logistic_regular_termFrequency_Cruz_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl_01.npy            Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl_02.npy            Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl                      Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl_02.npy               Logistic_regular_termFrequency_Rubio_05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl                     Logistic_regular_termFrequency_Rubio_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl_01.npy              Logistic_regular_termFrequency_Rubio_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl_02.npy              Logistic_regular_termFrequency_Rubio_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl                   Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl_01.npy            Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl_02.npy            Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl                     Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl_01.npy              Logistic_regular_termFrequency_Sanders_05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl_02.npy              Logistic_regular_termFrequency_Sanders_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl                    Logistic_regular_termFrequency_Sanders_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl_01.npy             Logistic_regular_termFrequency_Sanders_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl_02.npy             Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl                       Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl_01.npy                Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl_02.npy                Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl                      Logistic_regular_termFrequency_Trump_05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Trump_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl_02.npy               Logistic_regular_termFrequency_Trump_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl                    Logistic_regular_termFrequency_Trump_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl_01.npy             Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl_02.npy             Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl                      Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl_02.npy               MultinomialNB_termFrequency_Clinton_05-21-16.pkl\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl                        MultinomialNB_termFrequency_Clinton_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_01.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_02.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_03.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_04.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_05.npy                 MultinomialNB_termFrequency_Cruz_05-21-16.pkl\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl                           MultinomialNB_termFrequency_Cruz_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_01.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_02.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_03.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_04.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_05.npy                    MultinomialNB_termFrequency_Rubio_05-21-16.pkl\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl                          MultinomialNB_termFrequency_Rubio_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_01.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_02.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_03.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_04.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_05.npy                   MultinomialNB_termFrequency_Sanders_05-21-16.pkl\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl                        MultinomialNB_termFrequency_Sanders_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_01.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_02.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_03.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_04.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_05.npy                 MultinomialNB_termFrequency_Trump_05-21-16.pkl\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl                          MultinomialNB_termFrequency_Trump_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_01.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_02.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_03.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_04.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_05.npy                   \u001b[34mcandidateSentimentClassifier\u001b[m\u001b[m/\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl         \u001b[34mcandidateSentimentFeaturizer\u001b[m\u001b[m/\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_01.npy  char3and4grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_02.npy  char3and4grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_03.npy  char3and4grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_04.npy  char3and4grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl            char3and4grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_01.npy     char3grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_02.npy     char3grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_03.npy     char3grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_04.npy     char3grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl           char3grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_01.npy    char3to5grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_02.npy    char3to5grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_03.npy    char3to5grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_04.npy    char3to5grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl         char3to5grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_01.npy  termFrequency_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_02.npy  termFrequency_Clinton_05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_03.npy  termFrequency_Clinton_05-24-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_04.npy  termFrequency_Clinton_Deb-05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl           termFrequency_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_01.npy    termFrequency_Cruz_05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_02.npy    termFrequency_Cruz_05-24-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_03.npy    termFrequency_Cruz_Deb-05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_04.npy    termFrequency_Rubio_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl             termFrequency_Rubio_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_01.npy      termFrequency_Rubio_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_02.npy      termFrequency_Rubio_Deb-05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_03.npy      termFrequency_Sanders_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl         termFrequency_Sanders_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_01.npy  termFrequency_Sanders_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_02.npy  termFrequency_Sanders_Deb-05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_03.npy  termFrequency_Trump_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl                termFrequency_Trump_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl_01.npy         termFrequency_Trump_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl_02.npy         termFrequency_Trump_Deb-05-22-16.pkl\r\n"
     ]
    }
   ],
   "source": [
    "# Locate output directory.\n",
    "%ls ../classification/candidatesentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"../classification/candidatesentiment/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Trump' 'Clinton' 'Sanders' 'Cruz' 'Rubio']\n"
     ]
    }
   ],
   "source": [
    "print candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump\n",
      "Wrote featurizer to file: ../classification/candidatesentiment/char3and4grams_Trump_05-25-16.pkl\n",
      "Wrote classifier to file: ../classification/candidatesentiment/LinearSVC_char3and4grams_Trump_05-25-16.pkl\n",
      "Clinton\n",
      "Wrote featurizer to file: ../classification/candidatesentiment/char3and4grams_Clinton_05-25-16.pkl\n",
      "Wrote classifier to file: ../classification/candidatesentiment/LinearSVC_char3and4grams_Clinton_05-25-16.pkl\n",
      "Sanders\n",
      "Wrote featurizer to file: ../classification/candidatesentiment/char3and4grams_Sanders_05-25-16.pkl\n",
      "Wrote classifier to file: ../classification/candidatesentiment/LinearSVC_char3and4grams_Sanders_05-25-16.pkl\n",
      "Cruz\n",
      "Wrote featurizer to file: ../classification/candidatesentiment/char3and4grams_Cruz_05-25-16.pkl\n",
      "Wrote classifier to file: ../classification/candidatesentiment/LinearSVC_char3and4grams_Cruz_05-25-16.pkl\n",
      "Rubio\n",
      "Wrote featurizer to file: ../classification/candidatesentiment/char3and4grams_Rubio_05-25-16.pkl\n",
      "Wrote classifier to file: ../classification/candidatesentiment/LinearSVC_char3and4grams_Rubio_05-25-16.pkl\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# For each candidate, fit featurizer on each (entire) sample, train the classifier on it, \n",
    "# and write featurizer and classifier to file.\n",
    "\n",
    "date = \"05-25-16\"\n",
    "for candidate in candidates:\n",
    "    print candidate\n",
    "    \n",
    "    # Get data for this candidate.\n",
    "    candidate_df = df[ df['candidate']==candidate ]\n",
    "    \n",
    "    # Fit featurizer.\n",
    "    X = final_featurizer.fit_transform(candidate_df[clean_text])\n",
    "    \n",
    "    # Fit classifier.\n",
    "    y = candidate_df[label_field]\n",
    "    final_classifier.fit(X,y)\n",
    "    \n",
    "    # Write them to file.\n",
    "    \n",
    "    featurizer_filename = final_featurizer_name + \"_\" + candidate + \"_\" + date + \".pkl\"\n",
    "    #joblib.dump(final_featurizer, prefix + featurizer_filename) \n",
    "    with open(prefix+featurizer_filename, 'wb') as f:\n",
    "        pickle.dump(final_featurizer, f)\n",
    "    print \"Wrote featurizer to file: \" + prefix + featurizer_filename\n",
    "    \n",
    "    classifier_filename = final_classifier_name + \"_\" + final_featurizer_name + \"_\" + candidate + \"_\" + date + \".pkl\"\n",
    "    #joblib.dump(final_classifier, prefix + classifier_filename)\n",
    "    with open(prefix+classifier_filename, 'wb') as f:\n",
    "        pickle.dump(final_classifier, f)\n",
    "    print \"Wrote classifier to file: \" + prefix + classifier_filename\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl                   Logistic_regular_termFrequency_Cruz_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl_01.npy            Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Clinton_05-21-16.pkl_02.npy            Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl                      Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Cruz_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Cruz_05-21-16.pkl_02.npy               Logistic_regular_termFrequency_Rubio_05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl                     Logistic_regular_termFrequency_Rubio_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl_01.npy              Logistic_regular_termFrequency_Rubio_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Rubio_05-21-16.pkl_02.npy              Logistic_regular_termFrequency_Rubio_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl                   Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl_01.npy            Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3and4grams_Sanders_05-21-16.pkl_02.npy            Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl                     Logistic_regular_termFrequency_Rubio_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl_01.npy              Logistic_regular_termFrequency_Sanders_05-22-16.pkl\r\n",
      "LinearSVC_char3and4grams_Trump_05-21-16.pkl_02.npy              Logistic_regular_termFrequency_Sanders_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl                    Logistic_regular_termFrequency_Sanders_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl_01.npy             Logistic_regular_termFrequency_Sanders_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Clinton_05-21-16.pkl_02.npy             Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl                       Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl_01.npy                Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Cruz_05-21-16.pkl_02.npy                Logistic_regular_termFrequency_Sanders_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl                      Logistic_regular_termFrequency_Trump_05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Trump_05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Rubio_05-21-16.pkl_02.npy               Logistic_regular_termFrequency_Trump_05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl                    Logistic_regular_termFrequency_Trump_05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl_01.npy             Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl\r\n",
      "LinearSVC_char3to5grams_Sanders_05-21-16.pkl_02.npy             Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_01.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl                      Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_02.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl_01.npy               Logistic_regular_termFrequency_Trump_Deb-05-22-16.pkl_03.npy\r\n",
      "LinearSVC_char3to5grams_Trump_05-21-16.pkl_02.npy               MultinomialNB_termFrequency_Clinton_05-21-16.pkl\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl                        MultinomialNB_termFrequency_Clinton_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_01.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_02.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_03.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_04.npy                 MultinomialNB_termFrequency_Clinton_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Clinton_05-21-16.pkl_05.npy                 MultinomialNB_termFrequency_Cruz_05-21-16.pkl\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl                           MultinomialNB_termFrequency_Cruz_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_01.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_02.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_03.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_04.npy                    MultinomialNB_termFrequency_Cruz_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Cruz_05-21-16.pkl_05.npy                    MultinomialNB_termFrequency_Rubio_05-21-16.pkl\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl                          MultinomialNB_termFrequency_Rubio_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_01.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_02.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_03.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_04.npy                   MultinomialNB_termFrequency_Rubio_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Rubio_05-21-16.pkl_05.npy                   MultinomialNB_termFrequency_Sanders_05-21-16.pkl\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl                        MultinomialNB_termFrequency_Sanders_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_01.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_02.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_03.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_04.npy                 MultinomialNB_termFrequency_Sanders_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Sanders_05-21-16.pkl_05.npy                 MultinomialNB_termFrequency_Trump_05-21-16.pkl\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl                          MultinomialNB_termFrequency_Trump_05-21-16.pkl_01.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_01.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_02.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_02.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_03.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_03.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_04.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_04.npy                   MultinomialNB_termFrequency_Trump_05-21-16.pkl_05.npy\r\n",
      "Logistic_char3grams_Trump_05-21-16.pkl_05.npy                   \u001b[34mcandidateSentimentClassifier\u001b[m\u001b[m/\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl         \u001b[34mcandidateSentimentFeaturizer\u001b[m\u001b[m/\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_01.npy  char3and4grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_02.npy  char3and4grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_03.npy  char3and4grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Clinton_05-24-16.pkl_04.npy  char3and4grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl            char3and4grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_01.npy     char3grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_02.npy     char3grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_03.npy     char3grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Cruz_05-24-16.pkl_04.npy     char3grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl           char3grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_01.npy    char3to5grams_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_02.npy    char3to5grams_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_03.npy    char3to5grams_Rubio_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Rubio_05-24-16.pkl_04.npy    char3to5grams_Sanders_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl         char3to5grams_Trump_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_01.npy  termFrequency_Clinton_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_02.npy  termFrequency_Clinton_05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_03.npy  termFrequency_Clinton_05-24-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Sanders_05-24-16.pkl_04.npy  termFrequency_Clinton_Deb-05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl           termFrequency_Cruz_05-21-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_01.npy    termFrequency_Cruz_05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_02.npy    termFrequency_Cruz_05-24-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_03.npy    termFrequency_Cruz_Deb-05-22-16.pkl\r\n",
      "Logistic_huberLossL2_termFrequency_Trump_05-24-16.pkl_04.npy    termFrequency_Rubio_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl             termFrequency_Rubio_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_01.npy      termFrequency_Rubio_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_02.npy      termFrequency_Rubio_Deb-05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_05-22-16.pkl_03.npy      termFrequency_Sanders_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl         termFrequency_Sanders_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_01.npy  termFrequency_Sanders_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_02.npy  termFrequency_Sanders_Deb-05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Clinton_Deb-05-22-16.pkl_03.npy  termFrequency_Trump_05-21-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl                termFrequency_Trump_05-22-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl_01.npy         termFrequency_Trump_05-24-16.pkl\r\n",
      "Logistic_regular_termFrequency_Cruz_05-22-16.pkl_02.npy         termFrequency_Trump_Deb-05-22-16.pkl\r\n"
     ]
    }
   ],
   "source": [
    "# Verify that the files were written to the output directory.\n",
    "%ls ../classification/candidatesentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results on large dataset of 1000 pos & 1000 neg per candidate per partition. (40 partitions)\n",
    "05-21-16\n",
    "\n",
    "\n",
    "LinearSVC\n",
    "\n",
    "tfidf\n",
    "\n",
    "  Sanders\n",
    "[[8110 1810]\n",
    " [1662 9601]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.82      0.82      9920\n",
    "Sanders_pos       0.84      0.85      0.85     11263\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21183\n",
    "\n",
    "0.836094981825\n",
    "  Rubio\n",
    "[[8180 1411]\n",
    " [1344 8801]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.86      0.85      0.86      9591\n",
    "  Rubio_pos       0.86      0.87      0.86     10145\n",
    "\n",
    "avg / total       0.86      0.86      0.86     19736\n",
    "\n",
    "0.860407377381\n",
    "  Clinton\n",
    "[[9670 1308]\n",
    " [1635 9542]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.86      0.88      0.87     10978\n",
    "Clinton_pos       0.88      0.85      0.87     11177\n",
    "\n",
    "avg / total       0.87      0.87      0.87     22155\n",
    "\n",
    "0.867163168585\n",
    "  Trump\n",
    "[[9254 1764]\n",
    " [2013 9376]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.82      0.84      0.83     11018\n",
    "  Trump_pos       0.84      0.82      0.83     11389\n",
    "\n",
    "avg / total       0.83      0.83      0.83     22407\n",
    "\n",
    "0.831436604632\n",
    "  Cruz\n",
    "[[8729 1394]\n",
    " [1585 9716]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.85      0.86      0.85     10123\n",
    "   Cruz_pos       0.87      0.86      0.87     11301\n",
    "\n",
    "avg / total       0.86      0.86      0.86     21424\n",
    "\n",
    "0.860950336072\n",
    "\n",
    "term freq\n",
    "\n",
    "  Sanders\n",
    "[[8162 1758]\n",
    " [1650 9613]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.82      0.83      9920\n",
    "Sanders_pos       0.85      0.85      0.85     11263\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21183\n",
    "\n",
    "0.839116272483\n",
    "  Rubio\n",
    "[[8212 1379]\n",
    " [1380 8765]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.86      0.86      0.86      9591\n",
    "  Rubio_pos       0.86      0.86      0.86     10145\n",
    "\n",
    "avg / total       0.86      0.86      0.86     19736\n",
    "\n",
    "0.860204702067\n",
    "  Clinton\n",
    "[[9657 1321]\n",
    " [1648 9529]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.88      0.87     10978\n",
    "Clinton_pos       0.88      0.85      0.87     11177\n",
    "\n",
    "avg / total       0.87      0.87      0.87     22155\n",
    "\n",
    "0.865989618596\n",
    "  Trump\n",
    "[[9353 1665]\n",
    " [2061 9328]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.82      0.85      0.83     11018\n",
    "  Trump_pos       0.85      0.82      0.83     11389\n",
    "\n",
    "avg / total       0.83      0.83      0.83     22407\n",
    "\n",
    "0.833712679074\n",
    "  Cruz\n",
    "[[8810 1313]\n",
    " [1665 9636]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.84      0.87      0.86     10123\n",
    "   Cruz_pos       0.88      0.85      0.87     11301\n",
    "\n",
    "avg / total       0.86      0.86      0.86     21424\n",
    "\n",
    "0.860997012696\n",
    "\n",
    "word 1- & 2grams\n",
    "\n",
    "  Sanders\n",
    "[[7909 2011]\n",
    " [1917 9346]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.80      0.80      0.80      9920\n",
    "Sanders_pos       0.82      0.83      0.83     11263\n",
    "\n",
    "avg / total       0.81      0.81      0.81     21183\n",
    "\n",
    "0.81456828589\n",
    "  Rubio\n",
    "[[8108 1483]\n",
    " [1428 8717]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.85      0.85      0.85      9591\n",
    "  Rubio_pos       0.85      0.86      0.86     10145\n",
    "\n",
    "avg / total       0.85      0.85      0.85     19736\n",
    "\n",
    "0.85250304013\n",
    "  Clinton\n",
    "[[9417 1561]\n",
    " [1765 9412]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.84      0.86      0.85     10978\n",
    "Clinton_pos       0.86      0.84      0.85     11177\n",
    "\n",
    "avg / total       0.85      0.85      0.85     22155\n",
    "\n",
    "0.84987587452\n",
    "  Trump\n",
    "[[8868 2150]\n",
    " [2190 9199]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.80      0.80      0.80     11018\n",
    "  Trump_pos       0.81      0.81      0.81     11389\n",
    "\n",
    "avg / total       0.81      0.81      0.81     22407\n",
    "\n",
    "0.80631052796\n",
    "  Cruz\n",
    "[[8453 1670]\n",
    " [1600 9701]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.84      0.84      0.84     10123\n",
    "   Cruz_pos       0.85      0.86      0.86     11301\n",
    "\n",
    "avg / total       0.85      0.85      0.85     21424\n",
    "\n",
    "0.847367438387\n",
    "\n",
    "char 3grams\n",
    "\n",
    "  Sanders\n",
    "[[7893 2027]\n",
    " [1972 9291]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.80      0.80      0.80      9920\n",
    "Sanders_pos       0.82      0.82      0.82     11263\n",
    "\n",
    "avg / total       0.81      0.81      0.81     21183\n",
    "\n",
    "0.811216541566\n",
    "  Rubio\n",
    "[[7932 1659]\n",
    " [1480 8665]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.84      0.83      0.83      9591\n",
    "  Rubio_pos       0.84      0.85      0.85     10145\n",
    "\n",
    "avg / total       0.84      0.84      0.84     19736\n",
    "\n",
    "0.840950547223\n",
    "  Clinton\n",
    "[[9172 1806]\n",
    " [1754 9423]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.84      0.84      0.84     10978\n",
    "Clinton_pos       0.84      0.84      0.84     11177\n",
    "\n",
    "avg / total       0.84      0.84      0.84     22155\n",
    "\n",
    "0.839313924622\n",
    "  Trump\n",
    "[[8863 2155]\n",
    " [2218 9171]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.80      0.80      0.80     11018\n",
    "  Trump_pos       0.81      0.81      0.81     11389\n",
    "\n",
    "avg / total       0.80      0.80      0.80     22407\n",
    "\n",
    "0.80483777391\n",
    "  Cruz\n",
    "[[8309 1814]\n",
    " [1657 9644]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.83      0.82      0.83     10123\n",
    "   Cruz_pos       0.84      0.85      0.85     11301\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21424\n",
    "\n",
    "0.837985436893\n",
    "\n",
    "\n",
    "Multinomial NB\n",
    "\n",
    "tfidf\n",
    "\n",
    "  Sanders\n",
    "[[8007 1913]\n",
    " [1594 9669]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.81      0.82      9920\n",
    "Sanders_pos       0.83      0.86      0.85     11263\n",
    "\n",
    "avg / total       0.83      0.83      0.83     21183\n",
    "\n",
    "0.834442713497\n",
    "  Rubio\n",
    "[[7765 1826]\n",
    " [1385 8760]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.85      0.81      0.83      9591\n",
    "  Rubio_pos       0.83      0.86      0.85     10145\n",
    "\n",
    "avg / total       0.84      0.84      0.84     19736\n",
    "\n",
    "0.837302391569\n",
    "  Clinton\n",
    "[[9602 1376]\n",
    " [1711 9466]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.87      0.86     10978\n",
    "Clinton_pos       0.87      0.85      0.86     11177\n",
    "\n",
    "avg / total       0.86      0.86      0.86     22155\n",
    "\n",
    "0.860663507109\n",
    "  Trump\n",
    "[[9165 1853]\n",
    " [2147 9242]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.83      0.82     11018\n",
    "  Trump_pos       0.83      0.81      0.82     11389\n",
    "\n",
    "avg / total       0.82      0.82      0.82     22407\n",
    "\n",
    "0.821484357567\n",
    "  Cruz\n",
    "[[8794 1329]\n",
    " [2071 9230]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.81      0.87      0.84     10123\n",
    "   Cruz_pos       0.87      0.82      0.84     11301\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21424\n",
    "\n",
    "0.841299477222\n",
    "\n",
    "term freq\n",
    "\n",
    "  Sanders\n",
    "[[7877 2043]\n",
    " [1598 9665]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.79      0.81      9920\n",
    "Sanders_pos       0.83      0.86      0.84     11263\n",
    "\n",
    "avg / total       0.83      0.83      0.83     21183\n",
    "\n",
    "0.828116886182\n",
    "  Rubio\n",
    "[[7680 1911]\n",
    " [1480 8665]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.84      0.80      0.82      9591\n",
    "  Rubio_pos       0.82      0.85      0.84     10145\n",
    "\n",
    "avg / total       0.83      0.83      0.83     19736\n",
    "\n",
    "0.828182002432\n",
    "  Clinton\n",
    "[[9460 1518]\n",
    " [1774 9403]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.84      0.86      0.85     10978\n",
    "Clinton_pos       0.86      0.84      0.85     11177\n",
    "\n",
    "avg / total       0.85      0.85      0.85     22155\n",
    "\n",
    "0.851410516813\n",
    "  Trump\n",
    "[[9146 1872]\n",
    " [2200 9189]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.83      0.82     11018\n",
    "  Trump_pos       0.83      0.81      0.82     11389\n",
    "\n",
    "avg / total       0.82      0.82      0.82     22407\n",
    "\n",
    "0.818271076003\n",
    "  Cruz\n",
    "[[8777 1346]\n",
    " [2261 9040]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.80      0.87      0.83     10123\n",
    "   Cruz_pos       0.87      0.80      0.83     11301\n",
    "\n",
    "avg / total       0.83      0.83      0.83     21424\n",
    "\n",
    "0.831637415982\n",
    "\n",
    "word 1- & 2grams\n",
    "\n",
    "  Sanders\n",
    "[[8375 1545]\n",
    " [1764 9499]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.84      0.84      9920\n",
    "Sanders_pos       0.86      0.84      0.85     11263\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21183\n",
    "\n",
    "0.843789831469\n",
    "  Rubio\n",
    "[[8161 1430]\n",
    " [1389 8756]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.85      0.85      0.85      9591\n",
    "  Rubio_pos       0.86      0.86      0.86     10145\n",
    "\n",
    "avg / total       0.86      0.86      0.86     19736\n",
    "\n",
    "0.857164572355\n",
    "  Clinton\n",
    "[[9659 1319]\n",
    " [1643 9534]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.88      0.87     10978\n",
    "Clinton_pos       0.88      0.85      0.87     11177\n",
    "\n",
    "avg / total       0.87      0.87      0.87     22155\n",
    "\n",
    "0.866305574362\n",
    "  Trump\n",
    "[[9526 1492]\n",
    " [2207 9182]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.86      0.84     11018\n",
    "  Trump_pos       0.86      0.81      0.83     11389\n",
    "\n",
    "avg / total       0.84      0.83      0.83     22407\n",
    "\n",
    "0.83491765966\n",
    "  Cruz\n",
    "[[9166  957]\n",
    " [2259 9042]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.80      0.91      0.85     10123\n",
    "   Cruz_pos       0.90      0.80      0.85     11301\n",
    "\n",
    "avg / total       0.86      0.85      0.85     21424\n",
    "\n",
    "0.849887976102\n",
    "\n",
    "char 3grams\n",
    "\n",
    "  Sanders\n",
    "[[8190 1730]\n",
    " [2544 8719]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.76      0.83      0.79      9920\n",
    "Sanders_pos       0.83      0.77      0.80     11263\n",
    "\n",
    "avg / total       0.80      0.80      0.80     21183\n",
    "\n",
    "0.798234433272\n",
    "  Rubio\n",
    "[[7618 1973]\n",
    " [1870 8275]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.80      0.79      0.80      9591\n",
    "  Rubio_pos       0.81      0.82      0.81     10145\n",
    "\n",
    "avg / total       0.81      0.81      0.81     19736\n",
    "\n",
    "0.805279691934\n",
    "  Clinton\n",
    "[[9204 1774]\n",
    " [2085 9092]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.82      0.84      0.83     10978\n",
    "Clinton_pos       0.84      0.81      0.82     11177\n",
    "\n",
    "avg / total       0.83      0.83      0.83     22155\n",
    "\n",
    "0.825818099752\n",
    "  Trump\n",
    "[[9465 1553]\n",
    " [3125 8264]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.75      0.86      0.80     11018\n",
    "  Trump_pos       0.84      0.73      0.78     11389\n",
    "\n",
    "avg / total       0.80      0.79      0.79     22407\n",
    "\n",
    "0.791225956174\n",
    "  Cruz\n",
    "[[8935 1188]\n",
    " [3369 7932]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.73      0.88      0.80     10123\n",
    "   Cruz_pos       0.87      0.70      0.78     11301\n",
    "\n",
    "avg / total       0.80      0.79      0.79     21424\n",
    "\n",
    "0.787294622853\n",
    "\n",
    "\n",
    "Bernoulli NB\n",
    "\n",
    "tfidf\n",
    "\n",
    "  Sanders\n",
    "[[8182 1738]\n",
    " [1833 9430]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.82      0.82      0.82      9920\n",
    "Sanders_pos       0.84      0.84      0.84     11263\n",
    "\n",
    "avg / total       0.83      0.83      0.83     21183\n",
    "\n",
    "0.831421422839\n",
    "  Rubio\n",
    "[[7985 1606]\n",
    " [1568 8577]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.84      0.83      0.83      9591\n",
    "  Rubio_pos       0.84      0.85      0.84     10145\n",
    "\n",
    "avg / total       0.84      0.84      0.84     19736\n",
    "\n",
    "0.839177138225\n",
    "  Clinton\n",
    "[[9503 1475]\n",
    " [1695 9482]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.87      0.86     10978\n",
    "Clinton_pos       0.87      0.85      0.86     11177\n",
    "\n",
    "avg / total       0.86      0.86      0.86     22155\n",
    "\n",
    "0.856917174453\n",
    "  Trump\n",
    "[[9307 1711]\n",
    " [2211 9178]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.84      0.83     11018\n",
    "  Trump_pos       0.84      0.81      0.82     11389\n",
    "\n",
    "avg / total       0.83      0.82      0.82     22407\n",
    "\n",
    "0.824965412594\n",
    "  Cruz\n",
    "[[8889 1234]\n",
    " [2350 8951]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.79      0.88      0.83     10123\n",
    "   Cruz_pos       0.88      0.79      0.83     11301\n",
    "\n",
    "avg / total       0.84      0.83      0.83     21424\n",
    "\n",
    "0.832710978342\n",
    "\n",
    "term freq\n",
    "\n",
    "  Sanders\n",
    "[[8182 1738]\n",
    " [1833 9430]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.82      0.82      0.82      9920\n",
    "Sanders_pos       0.84      0.84      0.84     11263\n",
    "\n",
    "avg / total       0.83      0.83      0.83     21183\n",
    "\n",
    "0.831421422839\n",
    "  Rubio\n",
    "[[7985 1606]\n",
    " [1568 8577]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.84      0.83      0.83      9591\n",
    "  Rubio_pos       0.84      0.85      0.84     10145\n",
    "\n",
    "avg / total       0.84      0.84      0.84     19736\n",
    "\n",
    "0.839177138225\n",
    "  Clinton\n",
    "[[9503 1475]\n",
    " [1695 9482]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.87      0.86     10978\n",
    "Clinton_pos       0.87      0.85      0.86     11177\n",
    "\n",
    "avg / total       0.86      0.86      0.86     22155\n",
    "\n",
    "0.856917174453\n",
    "  Trump\n",
    "[[9307 1711]\n",
    " [2211 9178]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.84      0.83     11018\n",
    "  Trump_pos       0.84      0.81      0.82     11389\n",
    "\n",
    "avg / total       0.83      0.82      0.82     22407\n",
    "\n",
    "0.824965412594\n",
    "  Cruz\n",
    "[[8889 1234]\n",
    " [2350 8951]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.79      0.88      0.83     10123\n",
    "   Cruz_pos       0.88      0.79      0.83     11301\n",
    "\n",
    "avg / total       0.84      0.83      0.83     21424\n",
    "\n",
    "0.832710978342\n",
    "\n",
    "word 1- & 2grams\n",
    "\n",
    "  Sanders\n",
    "[[8341 1579]\n",
    " [1758 9505]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.84      0.83      9920\n",
    "Sanders_pos       0.86      0.84      0.85     11263\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21183\n",
    "\n",
    "0.842468016806\n",
    "  Rubio\n",
    "[[8270 1321]\n",
    " [1480 8665]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.85      0.86      0.86      9591\n",
    "  Rubio_pos       0.87      0.85      0.86     10145\n",
    "\n",
    "avg / total       0.86      0.86      0.86     19736\n",
    "\n",
    "0.858076611269\n",
    "  Clinton\n",
    "[[9638 1340]\n",
    " [1661 9516]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.85      0.88      0.87     10978\n",
    "Clinton_pos       0.88      0.85      0.86     11177\n",
    "\n",
    "avg / total       0.86      0.86      0.86     22155\n",
    "\n",
    "0.864545249379\n",
    "  Trump\n",
    "[[9591 1427]\n",
    " [2232 9157]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.81      0.87      0.84     11018\n",
    "  Trump_pos       0.87      0.80      0.83     11389\n",
    "\n",
    "avg / total       0.84      0.84      0.84     22407\n",
    "\n",
    "0.836702816084\n",
    "  Cruz\n",
    "[[9115 1008]\n",
    " [2264 9037]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.80      0.90      0.85     10123\n",
    "   Cruz_pos       0.90      0.80      0.85     11301\n",
    "\n",
    "avg / total       0.85      0.85      0.85     21424\n",
    "\n",
    "0.847274085138\n",
    "\n",
    "char 3grams\n",
    "\n",
    "  Sanders\n",
    "[[8170 1750]\n",
    " [2585 8678]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.76      0.82      0.79      9920\n",
    "Sanders_pos       0.83      0.77      0.80     11263\n",
    "\n",
    "avg / total       0.80      0.80      0.80     21183\n",
    "\n",
    "0.795354765614\n",
    "  Rubio\n",
    "[[7644 1947]\n",
    " [1939 8206]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.80      0.80      0.80      9591\n",
    "  Rubio_pos       0.81      0.81      0.81     10145\n",
    "\n",
    "avg / total       0.80      0.80      0.80     19736\n",
    "\n",
    "0.803100932306\n",
    "  Clinton\n",
    "[[9204 1774]\n",
    " [2250 8927]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.80      0.84      0.82     10978\n",
    "Clinton_pos       0.83      0.80      0.82     11177\n",
    "\n",
    "avg / total       0.82      0.82      0.82     22155\n",
    "\n",
    "0.818370570977\n",
    "  Trump\n",
    "[[9418 1600]\n",
    " [3104 8285]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.75      0.85      0.80     11018\n",
    "  Trump_pos       0.84      0.73      0.78     11389\n",
    "\n",
    "avg / total       0.80      0.79      0.79     22407\n",
    "\n",
    "0.790065604499\n",
    "  Cruz\n",
    "[[8890 1233]\n",
    " [3348 7953]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.73      0.88      0.80     10123\n",
    "   Cruz_pos       0.87      0.70      0.78     11301\n",
    "\n",
    "avg / total       0.80      0.79      0.79     21424\n",
    "\n",
    "0.786174383869\n",
    "\n",
    "\n",
    "Logistic\n",
    "\n",
    "tfidf\n",
    "\n",
    "  Sanders\n",
    "[[7465 2455]\n",
    " [2184 9079]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.77      0.75      0.76      9920\n",
    "Sanders_pos       0.79      0.81      0.80     11263\n",
    "\n",
    "avg / total       0.78      0.78      0.78     21183\n",
    "\n",
    "0.78100363499\n",
    "  Rubio\n",
    "[[7509 2082]\n",
    " [2277 7868]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.77      0.78      0.78      9591\n",
    "  Rubio_pos       0.79      0.78      0.78     10145\n",
    "\n",
    "avg / total       0.78      0.78      0.78     19736\n",
    "\n",
    "0.779134576409\n",
    "  Clinton\n",
    "[[9400 1578]\n",
    " [2996 8181]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.76      0.86      0.80     10978\n",
    "Clinton_pos       0.84      0.73      0.78     11177\n",
    "\n",
    "avg / total       0.80      0.79      0.79     22155\n",
    "\n",
    "0.793545475062\n",
    "  Trump\n",
    "[[9719 1299]\n",
    " [4103 7286]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.70      0.88      0.78     11018\n",
    "  Trump_pos       0.85      0.64      0.73     11389\n",
    "\n",
    "avg / total       0.78      0.76      0.76     22407\n",
    "\n",
    "0.758914624894\n",
    "  Cruz\n",
    "[[9083 1040]\n",
    " [3686 7615]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.71      0.90      0.79     10123\n",
    "   Cruz_pos       0.88      0.67      0.76     11301\n",
    "\n",
    "avg / total       0.80      0.78      0.78     21424\n",
    "\n",
    "0.779406273338\n",
    "\n",
    "term freq\n",
    "\n",
    "  Sanders\n",
    "[[7491 2429]\n",
    " [2928 8335]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.72      0.76      0.74      9920\n",
    "Sanders_pos       0.77      0.74      0.76     11263\n",
    "\n",
    "avg / total       0.75      0.75      0.75     21183\n",
    "\n",
    "0.747108530425\n",
    "  Rubio\n",
    "[[6993 2598]\n",
    " [2560 7585]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.73      0.73      0.73      9591\n",
    "  Rubio_pos       0.74      0.75      0.75     10145\n",
    "\n",
    "avg / total       0.74      0.74      0.74     19736\n",
    "\n",
    "0.738650182408\n",
    "  Clinton\n",
    "[[9182 1796]\n",
    " [3824 7353]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.71      0.84      0.77     10978\n",
    "Clinton_pos       0.80      0.66      0.72     11177\n",
    "\n",
    "avg / total       0.76      0.75      0.74     22155\n",
    "\n",
    "0.746332656285\n",
    "  Trump\n",
    "[[9496 1522]\n",
    " [4563 6826]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.68      0.86      0.76     11018\n",
    "  Trump_pos       0.82      0.60      0.69     11389\n",
    "\n",
    "avg / total       0.75      0.73      0.72     22407\n",
    "\n",
    "0.728433078949\n",
    "  Cruz\n",
    "[[8331 1792]\n",
    " [3622 7679]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.70      0.82      0.75     10123\n",
    "   Cruz_pos       0.81      0.68      0.74     11301\n",
    "\n",
    "avg / total       0.76      0.75      0.75     21424\n",
    "\n",
    "0.747292755788\n",
    "\n",
    "word 1- & 2grams\n",
    "\n",
    "  Sanders\n",
    "[[8174 1746]\n",
    " [1732 9531]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.83      0.82      0.82      9920\n",
    "Sanders_pos       0.85      0.85      0.85     11263\n",
    "\n",
    "avg / total       0.84      0.84      0.84     21183\n",
    "\n",
    "0.835811735826\n",
    "  Rubio\n",
    "[[8417 1174]\n",
    " [1659 8486]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.84      0.88      0.86      9591\n",
    "  Rubio_pos       0.88      0.84      0.86     10145\n",
    "\n",
    "avg / total       0.86      0.86      0.86     19736\n",
    "\n",
    "0.856455208756\n",
    "  Clinton\n",
    "[[9793 1185]\n",
    " [1920 9257]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.84      0.89      0.86     10978\n",
    "Clinton_pos       0.89      0.83      0.86     11177\n",
    "\n",
    "avg / total       0.86      0.86      0.86     22155\n",
    "\n",
    "0.859851049425\n",
    "  Trump\n",
    "[[9620 1398]\n",
    " [2429 8960]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.80      0.87      0.83     11018\n",
    "  Trump_pos       0.87      0.79      0.82     11389\n",
    "\n",
    "avg / total       0.83      0.83      0.83     22407\n",
    "\n",
    "0.829205159102\n",
    "  Cruz\n",
    "[[8927 1196]\n",
    " [1850 9451]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.83      0.88      0.85     10123\n",
    "   Cruz_pos       0.89      0.84      0.86     11301\n",
    "\n",
    "avg / total       0.86      0.86      0.86     21424\n",
    "\n",
    "0.85782300224\n",
    "\n",
    "char 3grams\n",
    "\n",
    "  Sanders\n",
    "[[8113 1807]\n",
    " [2142 9121]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Sanders_neg       0.79      0.82      0.80      9920\n",
    "Sanders_pos       0.83      0.81      0.82     11263\n",
    "\n",
    "avg / total       0.81      0.81      0.81     21183\n",
    "\n",
    "0.813576924893\n",
    "  Rubio\n",
    "[[8030 1561]\n",
    " [1713 8432]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Rubio_neg       0.82      0.84      0.83      9591\n",
    "  Rubio_pos       0.84      0.83      0.84     10145\n",
    "\n",
    "avg / total       0.83      0.83      0.83     19736\n",
    "\n",
    "0.834110255371\n",
    "  Clinton\n",
    "[[9313 1665]\n",
    " [1826 9351]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "Clinton_neg       0.84      0.85      0.84     10978\n",
    "Clinton_pos       0.85      0.84      0.84     11177\n",
    "\n",
    "avg / total       0.84      0.84      0.84     22155\n",
    "\n",
    "0.842428345746\n",
    "  Trump\n",
    "[[9032 1986]\n",
    " [2269 9120]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "  Trump_neg       0.80      0.82      0.81     11018\n",
    "  Trump_pos       0.82      0.80      0.81     11389\n",
    "\n",
    "avg / total       0.81      0.81      0.81     22407\n",
    "\n",
    "0.810103985362\n",
    "  Cruz\n",
    "[[8973 1150]\n",
    " [2432 8869]]\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "   Cruz_neg       0.79      0.89      0.83     10123\n",
    "   Cruz_pos       0.89      0.78      0.83     11301\n",
    "\n",
    "avg / total       0.84      0.83      0.83     21424\n",
    "\n",
    "0.832804331591\n",
    "\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
