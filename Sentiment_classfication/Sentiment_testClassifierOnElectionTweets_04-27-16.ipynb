{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: Use curl to send cypher quries to the Neo4j server on sauce5. \n",
    "         Use jq to parse the json-formatted results and store them in a csv file.\n",
    "Author:  Debbie Hofmann, adapted by Carol Sniegoski\n",
    "Date:  April 27, 2016\n",
    "Course: MAS DSE Capstone, Spring 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 240)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification\n",
    "\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Function defs.\n",
    "\n",
    "# Return string with non-ascii chars removed.\n",
    "def to_ascii(s):\n",
    "    returnstr = s.strip()\n",
    "    returnstr = \"\".join([ch for ch in returnstr if ord(ch)< 128])\n",
    "    return returnstr\n",
    "\n",
    "# Get class frequencies. Input is a series.\n",
    "def get_class_frequencies(s):\n",
    "    counts = s.value_counts()\n",
    "    total = counts.sum()\n",
    "    counts = counts.apply(lambda x: (\"Count: %d\" % x, \"Frequency: %.2f\" % (float(x)/total)) )\n",
    "    return counts.sort_index()\n",
    "\n",
    "# From newer version of python.\n",
    "def cohen_kappa_score(y1, y2, labels=None, weights=None):\n",
    "    confusion = confusion_matrix(y1, y2, labels=labels)\n",
    "    n_classes = confusion.shape[0]\n",
    "    sum0 = np.sum(confusion, axis=0)\n",
    "    sum1 = np.sum(confusion, axis=1)\n",
    "    expected = np.outer(sum0, sum1) / np.sum(sum0)\n",
    "\n",
    "    if weights is None:\n",
    "        w_mat = np.ones([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat.flat[:: n_classes + 1] = 0\n",
    "    elif weights == \"linear\" or weights == \"quadratic\":\n",
    "        w_mat = np.zeros([n_classes, n_classes], dtype=np.int)\n",
    "        w_mat += np.arange(n_classes)\n",
    "        if weights == \"linear\":\n",
    "            w_mat = np.abs(w_mat - w_mat.T)\n",
    "        else:\n",
    "            w_mat = (w_mat - w_mat.T) ** 2\n",
    "    else:\n",
    "        raise ValueError(\"Unknown kappa weighting type.\")\n",
    "\n",
    "    k = np.sum(w_mat * confusion) / np.sum(w_mat * expected)\n",
    "    return 1 - k\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"statements\":[{\"statement\":\"MATCH (hashtag:Hashtag_172)-[:TAGS]->(tweet:Tweet_172)<-[:TAGS]-(hashtag2:Hashtag_172)     WHERE hashtag.text = \\\"feelthebern\\\"      RETURN hashtag2.text, COUNT(hashtag2.text) as frequency ORDER BY frequency desc\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   322  100    77  100   245    809   2576 --:--:-- --:--:-- --:--:--  2578\n"
     ]
    }
   ],
   "source": [
    "for partition in range(172,173):\n",
    "    cyphercmd = \\\n",
    "    \"\"\"MATCH (hashtag:Hashtag_{0})-[:TAGS]->(tweet:Tweet_{0})<-[:TAGS]-(hashtag2:Hashtag_{0}) \\\n",
    "    WHERE hashtag.text = \\\\\"feelthebern\\\\\"  \\\n",
    "    RETURN hashtag2.text, COUNT(hashtag2.text) as frequency ORDER BY frequency desc\"\"\".format(partition)\n",
    "\n",
    "    statementstr = \"\"\"'{{\"statements\":[{{\"statement\":\"{0}\"}}]}}'\"\"\".format(cyphercmd)\n",
    "    print statementstr\n",
    "    \n",
    "    !curl -H accept:application/json -H content-type:application/json \\\n",
    "        -d $statementstr \\\n",
    "        http://neo4j:lajolla@sauce5.sdsc.edu:7474/db/data/transaction/commit | \\\n",
    "        jq -r '(.results[0]) | .columns, .data[].row | @csv' >> hashtags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mKaggle\u001b[m\u001b[m/                  \u001b[34mcyberbullying\u001b[m\u001b[m/           election-sample          hashtags-Debbie.csv      \u001b[34mschedule\u001b[m\u001b[m/                \u001b[34mslices\u001b[m\u001b[m/\r\n",
      "\u001b[34mcalendar\u001b[m\u001b[m/                \u001b[34mdebateTranscripts\u001b[m\u001b[m/       \u001b[34melectionSampleData\u001b[m\u001b[m/      sanders-twitter-0.2.zip  \u001b[34msentiment\u001b[m\u001b[m/               \u001b[34mtopic\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "# Find output diretory.\n",
    "#%pwd\n",
    "%ls ../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/electionSampleData/electionTweets_randomSample_allPartitions_04-26-16.csv\n"
     ]
    }
   ],
   "source": [
    "# Define variables.\n",
    "\n",
    "url = \"http://neo4j:lajolla@sauce5.sdsc.edu:7474/db/data/transaction/commit\"\n",
    "\n",
    "# Partitions are 172 to 193.\n",
    "min_partition = 172\n",
    "max_partition = 194\n",
    "\n",
    "# .0001 retrieves about 100 tweets per partition.\n",
    "query = \"MATCH (t:Tweet_{0}) WHERE rand()<.0001 RETURN t.text AS text\"\n",
    "\n",
    "out_dir = \"../data/electionSampleData/\"\n",
    "outfile_name = \"electionTweets_randomSample_allPartitions_04-26-16.csv\"\n",
    "outfile = out_dir + outfile_name\n",
    "print outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_172) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  2897  100  2812  100    85   2339     70  0:00:01  0:00:01 --:--:--  2341\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_173) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9577  100  9492  100    85   2802     25  0:00:03  0:00:03 --:--:--  2802\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_174) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9992  100  9907  100    85   3048     26  0:00:03  0:00:03 --:--:--  3049\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_175) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10457  100 10372  100    85   3201     26  0:00:03  0:00:03 --:--:--  3202\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_176) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13499  100 13414  100    85   3467     21  0:00:04  0:00:03  0:00:01  3467\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_177) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9575  100  9490  100    85   3225     28  0:00:03  0:00:02  0:00:01  3224\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_178) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  8925  100  8840  100    85   3223     30  0:00:02  0:00:02 --:--:--  3225\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_179) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 13860  100 13775  100    85   3221     19  0:00:04  0:00:04 --:--:--  4229\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_180) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10887  100 10802  100    85   3127     24  0:00:03  0:00:03 --:--:--  3128\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_181) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10466  100 10381  100    85   3156     25  0:00:03  0:00:03 --:--:--  3156\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_182) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10853  100 10768  100    85   3152     24  0:00:03  0:00:03 --:--:--  3152\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_183) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10640  100 10555  100    85   3247     26  0:00:03  0:00:03 --:--:--  3246\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_184) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12504  100 12419  100    85   3391     23  0:00:03  0:00:03 --:--:--  3392\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_185) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11480  100 11395  100    85   3398     25  0:00:03  0:00:03 --:--:--  3397\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_186) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12649  100 12564  100    85   3636     24  0:00:03  0:00:03 --:--:--  3637\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_187) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  9676  100  9591  100    85   3375     29  0:00:02  0:00:02 --:--:--  3375\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_188) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12383  100 12298  100    85   3782     26  0:00:03  0:00:03 --:--:--  3784\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_189) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 11038  100 10953  100    85   3366     26  0:00:03  0:00:03 --:--:--  3367\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_190) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12836  100 12751  100    85  18412    122 --:--:-- --:--:-- --:--:-- 18399\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_191) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12415  100 12330  100    85   6427     44  0:00:01  0:00:01 --:--:--  6425\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_192) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12938  100 12853  100    85   5688     37  0:00:02  0:00:02 --:--:--  5689\n",
      "'{\"statements\":[{\"statement\":\"MATCH (t:Tweet_193) WHERE rand()<.0001 RETURN t.text\"}]}'\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10763  100 10678  100    85   5664     45  0:00:01  0:00:01 --:--:--  5667\n"
     ]
    }
   ],
   "source": [
    "# Send query to Neo4j server and get response.\n",
    "\n",
    "for partition in range(min_partition, max_partition):\n",
    "    \n",
    "    cyphercmd = query.format(partition)\n",
    "\n",
    "    statementstr = \"\"\"'{{\"statements\":[{{\"statement\":\"{0}\"}}]}}'\"\"\".format(cyphercmd)\n",
    "    print statementstr\n",
    "    \n",
    "    !curl -H accept:application/json -H content-type:application/json \\\n",
    "        -d $statementstr \\\n",
    "        $url | \\\n",
    "        jq -r '(.results[0]) | .columns, .data[].row | @csv'  >>  $outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1859, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/…\n",
       "1                                             Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the csv file you just created.\n",
    "df = pd.read_csv(outfile)\n",
    "#df=df.rename(columns = {'t.text':'text'})\n",
    "print df.shape\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text field.\n",
    "\n",
    "# Set the names of the cleaned text field and the class label field,\n",
    "# to be used in the sampling, featurizing, and classification steps.\n",
    "clean_text = 'ascii_clean'  # This is where the cleaned text will be put.\n",
    "label_field = 'K_sentiment' # This is where the labels will be put.\n",
    "\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ascii_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/…</td>\n",
       "      <td>rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "      <td>father ted cruzs success depends on people of faith url url</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trump Caught Red-Handed Funneling Donations For Veterans To His Own “Foundation” | Occupy Democrats https://t.co/Mzobk7mydD</td>\n",
       "      <td>trump caught red-handed funneling donations for veterans to his own foundation | occupy democrats url</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/…   \n",
       "1                                             Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK   \n",
       "2                       Trump Caught Red-Handed Funneling Donations For Veterans To His Own “Foundation” | Occupy Democrats https://t.co/Mzobk7mydD   \n",
       "\n",
       "                                                                                                                            ascii_clean  \n",
       "0  rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url  \n",
       "1                                                                           father ted cruzs success depends on people of faith url url  \n",
       "2                                 trump caught red-handed funneling donations for veterans to his own foundation | occupy democrats url  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Populate the clean_text field.\n",
    "# Load data file & clean the 'text' column.\n",
    "\n",
    "# Convert to ascii\n",
    "df['ascii'] = df['text'].apply(to_ascii)\n",
    "df[clean_text] = df['ascii']\n",
    "\n",
    "# Remove hashtags\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"#([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove handles\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"@([A-Za-z0-9_]+)\", \" \")\n",
    "\n",
    "# Remove URLs\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \" \")\n",
    "# Replace URLs with \"URL\"\n",
    "df[clean_text] = df[clean_text].str.replace(r\"http([A-Za-z0-9_:.\\/]+)\", \"URL\")\n",
    "\n",
    "# Remove punctuation symbols - but not @ or #\n",
    "df[clean_text] = df[clean_text].str.replace(r\"(['';:%()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"(['';:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "#df[clean_text] = df[clean_text].str.replace(r\"([;:@%#()\\+\\*\\\"\\…\\“\\”])\", \"\")\n",
    "\n",
    "# Remove eol symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"\\n\", \" \")\n",
    "\n",
    "# Remove &x symbols\n",
    "df[clean_text] = df[clean_text].str.replace(r\"&[a-z]+\", \" \")\n",
    "\n",
    "# Convert to lowercase\n",
    "df[clean_text] = df[clean_text].str.lower()\n",
    "\n",
    "#print df[df['ascii']!=df[clean_text]][['ascii', 'K_sentiment']].head(10)\n",
    "df[['text', clean_text]].head(3)\n",
    "#df[df['ascii'].str.contains(\"\\n\")][['text', 'ascii']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl         LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_02.npy\r\n",
      "LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_01.npy  LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_03.npy\r\n"
     ]
    }
   ],
   "source": [
    "# Find the pickle file containing the trained classifier.\n",
    "%ls ../classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.svm.classes.LinearSVC'>\n"
     ]
    }
   ],
   "source": [
    "# Load the trained classifier.\n",
    "dir = \"../classification/\"\n",
    "filename = \"LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl\"\n",
    "file = dir + filename\n",
    "\n",
    "classifier = joblib.load(file)\n",
    "print type(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl         LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_03.npy\r\n",
      "LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_01.npy  featurizer_char3grams_0.75randomsample_2016-04-27.pkl\r\n",
      "LinearSVC_char3grams_0.75randomsample_2016-04-27.pkl_02.npy\r\n"
     ]
    }
   ],
   "source": [
    "# Find the pickle file contaning the fitted featurizer.\n",
    "%ls ../classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n"
     ]
    }
   ],
   "source": [
    "# Load the fitted featurizer.\n",
    "dir = \"../classification/\"\n",
    "filename = \"featurizer_char3grams_0.75randomsample_2016-04-27.pkl\"\n",
    "file = dir + filename\n",
    "\n",
    "featurizer = joblib.load(file)\n",
    "print type(featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "(1859, 4)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "(1859, 6749)\n"
     ]
    }
   ],
   "source": [
    "# Featurize the cleaned text data.\n",
    "\n",
    "# Convert to ndarray.\n",
    "#X_samples.append(df_sample[clean_text].values)\n",
    "#this_feature_vector_list.append( vectorizer.fit_transform(X_sample) )\n",
    "\n",
    "# Don't do this - it puts the entire feature matrix into each X_feauturized value.\n",
    "#df['X_featurized'] = featurizer.transform( df[clean_text].values )\n",
    "df.drop('X_featurized', axis=1, inplace=True)\n",
    "\n",
    "X_featurized = featurizer.transform( df[clean_text].values )\n",
    "print 'done'\n",
    "\n",
    "print df.shape\n",
    "print type(X_featurized)\n",
    "print X_featurized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "<type 'numpy.ndarray'>\n",
      "(1859,)\n"
     ]
    }
   ],
   "source": [
    "# Classify.\n",
    "\n",
    "y_preds = classifier.predict(X_featurized)\n",
    "print 'done'\n",
    "print type( y_preds )\n",
    "print y_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral     783\n",
      "Negative    671\n",
      "Positive    405\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ascii</th>\n",
       "      <th>ascii_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/…</td>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/</td>\n",
       "      <td>rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "      <td>Father: Ted Cruzs success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "      <td>father ted cruzs success depends on people of faith url url</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/…   \n",
       "1                                             Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK   \n",
       "\n",
       "                                                                                                                                             ascii  \\\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/   \n",
       "1                                             Father: Ted Cruzs success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK   \n",
       "\n",
       "                                                                                                                            ascii_clean  \\\n",
       "0  rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url   \n",
       "1                                                                           father ted cruzs success depends on people of faith url url   \n",
       "\n",
       "      label  \n",
       "0  Negative  \n",
       "1  Negative  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at results.\n",
    "\n",
    "df['label'] = y_preds\n",
    "print df['label'].value_counts()\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>ascii</th>\n",
       "      <th>ascii_clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bernie Sanders And Big Business Find Something They Can Actually Agree On - Huffington Post: Huffington PostBe... https://t.co/mXetlBjtJB</td>\n",
       "      <td>Bernie Sanders And Big Business Find Something They Can Actually Agree On - Huffington Post: Huffington PostBe... https://t.co/mXetlBjtJB</td>\n",
       "      <td>bernie sanders and big business find something they can actually agree on - huffington post huffington postbe... url</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @slone: Tucker Carlson: @realDonaldTrump is the ONLY Republican who can meaningfully expand the pie https://t.co/hzhTP8iNGw https://t.co…</td>\n",
       "      <td>RT @slone: Tucker Carlson: @realDonaldTrump is the ONLY Republican who can meaningfully expand the pie https://t.co/hzhTP8iNGw https://t.co</td>\n",
       "      <td>rt @slone tucker carlson @realdonaldtrump is the only republican who can meaningfully expand the pie url url</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @RealTimers: \"Donald Trump skipped the #GOPDebate  - it was like a #Seinfeld episode without Kramer.\" - @billmaher #RealTime</td>\n",
       "      <td>RT @RealTimers: \"Donald Trump skipped the #GOPDebate  - it was like a #Seinfeld episode without Kramer.\" - @billmaher #RealTime</td>\n",
       "      <td>rt @realtimers donald trump skipped the #gopdebate  - it was like a #seinfeld episode without kramer. - @billmaher #realtime</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @Donnydinker: @NonSerf @BoSnerdley @NRO don't look to Rush for any analysis on Trump unless it is praise.  I blame Rush for the debacle …</td>\n",
       "      <td>RT @Donnydinker: @NonSerf @BoSnerdley @NRO don't look to Rush for any analysis on Trump unless it is praise.  I blame Rush for the debacle</td>\n",
       "      <td>rt @donnydinker @nonserf @bosnerdley @nro dont look to rush for any analysis on trump unless it is praise.  i blame rush for the debacle</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @TheNewDeal: Bernie Sanders is Only 'Un-Electable' If You Don't Vote\\r\\rHis Ideas are Only 'Unrealistic' If You Don't Fight\\r\\r#FeelTheBern\\r…</td>\n",
       "      <td>RT @TheNewDeal: Bernie Sanders is Only 'Un-Electable' If You Don't Vote\\r\\rHis Ideas are Only 'Unrealistic' If You Don't Fight\\r\\r#FeelTheBern\\r</td>\n",
       "      <td>rt @thenewdeal bernie sanders is only un-electable if you dont vote\\r\\rhis ideas are only unrealistic if you dont fight\\r\\r#feelthebern\\r</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@rhc_gop  @steph93065 @GrannyMarried  @atticsonline @sliderblaze So did Obama, Carter, Clinton. He's in good company.</td>\n",
       "      <td>@rhc_gop  @steph93065 @GrannyMarried  @atticsonline @sliderblaze So did Obama, Carter, Clinton. He's in good company.</td>\n",
       "      <td>@rhc_gop  @steph93065 @grannymarried  @atticsonline @sliderblaze so did obama, carter, clinton. hes in good company.</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @MyDriver88: Cruz wins America wins https://t.co/feEVXi1Vgm</td>\n",
       "      <td>RT @MyDriver88: Cruz wins America wins https://t.co/feEVXi1Vgm</td>\n",
       "      <td>rt @mydriver88 cruz wins america wins url</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RT @BeeFeelings: A student tells Sanders that the case for climate change seems fake to her. \"Thank you for the question,\" he says. \"You're…</td>\n",
       "      <td>RT @BeeFeelings: A student tells Sanders that the case for climate change seems fake to her. \"Thank you for the question,\" he says. \"You're</td>\n",
       "      <td>rt @beefeelings a student tells sanders that the case for climate change seems fake to her. thank you for the question, he says. youre</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RT @Iowa4Bernie: Don't believe the cynics who say our goals are too lofty, together we can do ANYTHING!\\n#NotMeUs\\n#WeAreBernie\\n#Bernie https…</td>\n",
       "      <td>RT @Iowa4Bernie: Don't believe the cynics who say our goals are too lofty, together we can do ANYTHING!\\n#NotMeUs\\n#WeAreBernie\\n#Bernie https</td>\n",
       "      <td>rt @iowa4bernie dont believe the cynics who say our goals are too lofty, together we can do anything! #notmeus #wearebernie #bernie url</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RT @PaulSasso: Let us be bold, together! #NotMeUs https://t.co/HLUiJUxZ7F</td>\n",
       "      <td>RT @PaulSasso: Let us be bold, together! #NotMeUs https://t.co/HLUiJUxZ7F</td>\n",
       "      <td>rt @paulsasso let us be bold, together! #notmeus url</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                 text  \\\n",
       "11          Bernie Sanders And Big Business Find Something They Can Actually Agree On - Huffington Post: Huffington PostBe... https://t.co/mXetlBjtJB   \n",
       "13       RT @slone: Tucker Carlson: @realDonaldTrump is the ONLY Republican who can meaningfully expand the pie https://t.co/hzhTP8iNGw https://t.co…   \n",
       "15                    RT @RealTimers: \"Donald Trump skipped the #GOPDebate  - it was like a #Seinfeld episode without Kramer.\" - @billmaher #RealTime   \n",
       "19       RT @Donnydinker: @NonSerf @BoSnerdley @NRO don't look to Rush for any analysis on Trump unless it is praise.  I blame Rush for the debacle …   \n",
       "22  RT @TheNewDeal: Bernie Sanders is Only 'Un-Electable' If You Don't Vote\\r\\rHis Ideas are Only 'Unrealistic' If You Don't Fight\\r\\r#FeelTheBern\\r…   \n",
       "24                              @rhc_gop  @steph93065 @GrannyMarried  @atticsonline @sliderblaze So did Obama, Carter, Clinton. He's in good company.   \n",
       "29                                                                                     RT @MyDriver88: Cruz wins America wins https://t.co/feEVXi1Vgm   \n",
       "31       RT @BeeFeelings: A student tells Sanders that the case for climate change seems fake to her. \"Thank you for the question,\" he says. \"You're…   \n",
       "37    RT @Iowa4Bernie: Don't believe the cynics who say our goals are too lofty, together we can do ANYTHING!\\n#NotMeUs\\n#WeAreBernie\\n#Bernie https…   \n",
       "40                                                                          RT @PaulSasso: Let us be bold, together! #NotMeUs https://t.co/HLUiJUxZ7F   \n",
       "\n",
       "                                                                                                                                               ascii  \\\n",
       "11         Bernie Sanders And Big Business Find Something They Can Actually Agree On - Huffington Post: Huffington PostBe... https://t.co/mXetlBjtJB   \n",
       "13       RT @slone: Tucker Carlson: @realDonaldTrump is the ONLY Republican who can meaningfully expand the pie https://t.co/hzhTP8iNGw https://t.co   \n",
       "15                   RT @RealTimers: \"Donald Trump skipped the #GOPDebate  - it was like a #Seinfeld episode without Kramer.\" - @billmaher #RealTime   \n",
       "19       RT @Donnydinker: @NonSerf @BoSnerdley @NRO don't look to Rush for any analysis on Trump unless it is praise.  I blame Rush for the debacle    \n",
       "22  RT @TheNewDeal: Bernie Sanders is Only 'Un-Electable' If You Don't Vote\\r\\rHis Ideas are Only 'Unrealistic' If You Don't Fight\\r\\r#FeelTheBern\\r   \n",
       "24                             @rhc_gop  @steph93065 @GrannyMarried  @atticsonline @sliderblaze So did Obama, Carter, Clinton. He's in good company.   \n",
       "29                                                                                    RT @MyDriver88: Cruz wins America wins https://t.co/feEVXi1Vgm   \n",
       "31       RT @BeeFeelings: A student tells Sanders that the case for climate change seems fake to her. \"Thank you for the question,\" he says. \"You're   \n",
       "37    RT @Iowa4Bernie: Don't believe the cynics who say our goals are too lofty, together we can do ANYTHING!\\n#NotMeUs\\n#WeAreBernie\\n#Bernie https   \n",
       "40                                                                         RT @PaulSasso: Let us be bold, together! #NotMeUs https://t.co/HLUiJUxZ7F   \n",
       "\n",
       "                                                                                                                                  ascii_clean  \\\n",
       "11                       bernie sanders and big business find something they can actually agree on - huffington post huffington postbe... url   \n",
       "13                               rt @slone tucker carlson @realdonaldtrump is the only republican who can meaningfully expand the pie url url   \n",
       "15               rt @realtimers donald trump skipped the #gopdebate  - it was like a #seinfeld episode without kramer. - @billmaher #realtime   \n",
       "19  rt @donnydinker @nonserf @bosnerdley @nro dont look to rush for any analysis on trump unless it is praise.  i blame rush for the debacle    \n",
       "22  rt @thenewdeal bernie sanders is only un-electable if you dont vote\\r\\rhis ideas are only unrealistic if you dont fight\\r\\r#feelthebern\\r   \n",
       "24                       @rhc_gop  @steph93065 @grannymarried  @atticsonline @sliderblaze so did obama, carter, clinton. hes in good company.   \n",
       "29                                                                                                  rt @mydriver88 cruz wins america wins url   \n",
       "31     rt @beefeelings a student tells sanders that the case for climate change seems fake to her. thank you for the question, he says. youre   \n",
       "37    rt @iowa4bernie dont believe the cynics who say our goals are too lofty, together we can do anything! #notmeus #wearebernie #bernie url   \n",
       "40                                                                                       rt @paulsasso let us be bold, together! #notmeus url   \n",
       "\n",
       "       label  \n",
       "11  Positive  \n",
       "13  Positive  \n",
       "15  Positive  \n",
       "19  Positive  \n",
       "22  Positive  \n",
       "24  Positive  \n",
       "29  Positive  \n",
       "31  Positive  \n",
       "37  Positive  \n",
       "40  Positive  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get 10 from each class.\n",
    "df[df['label']=='Positive'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bing-liu_opinion-lexicon-English_d04-13-16.rar  debate08_sentiment_tweets.tsv.zip\r\n",
      "debate08_sentiment_tweets.tsv                   opinion-lexicon-English.rar\r\n"
     ]
    }
   ],
   "source": [
    "# Locate output dir.\n",
    "%ls ../data/sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sentiment/Labeled_electionTweets_randomSample_allPartitions_04-26-16.csv\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Write to csv.\n",
    "\n",
    "out_dir = \"../data/sentiment/\"\n",
    "outfile = out_dir + \"Labeled_\" + outfile_name\n",
    "print outfile\n",
    "df.to_csv(outfile)\n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assume manual labels have been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1859, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>ascii</th>\n",
       "      <th>ascii_clean</th>\n",
       "      <th>label</th>\n",
       "      <th>label_cas_04-27-16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/…</td>\n",
       "      <td>RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp;amp; sources were prosecuted... https:/</td>\n",
       "      <td>rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "      <td>Father: Ted Cruzs success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK</td>\n",
       "      <td>father ted cruzs success depends on people of faith url url</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  \\\n",
       "0           0   \n",
       "1           1   \n",
       "\n",
       "                                                                                                                                               text  \\\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/…   \n",
       "1                                             Father: Ted Cruz’s success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK   \n",
       "\n",
       "                                                                                                                                             ascii  \\\n",
       "0  RT @ggreenwald: Clinton sadly never complained about \"overclassification run amok\" when whistleblowers &amp; sources were prosecuted... https:/   \n",
       "1                                             Father: Ted Cruzs success depends on people of faith https://t.co/sXviGD11Xw https://t.co/T0cdqrNowK   \n",
       "\n",
       "                                                                                                                            ascii_clean  \\\n",
       "0  rt @ggreenwald clinton sadly never complained about overclassification run amok when whistleblowers   sources were prosecuted... url   \n",
       "1                                                                           father ted cruzs success depends on people of faith url url   \n",
       "\n",
       "      label label_cas_04-27-16  \n",
       "0  Negative           Negative  \n",
       "1  Negative            Neutral  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload csv.\n",
    "df = pd.read_csv(outfile)\n",
    "print df.shape\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative    (Count: 98, Frequency: 0.52)\n",
      "Neutral     (Count: 55, Frequency: 0.29)\n",
      "Positive    (Count: 37, Frequency: 0.19)\n",
      "dtype: object\n",
      "Negative    (Count: 671, Frequency: 0.36)\n",
      "Neutral     (Count: 783, Frequency: 0.42)\n",
      "Positive    (Count: 405, Frequency: 0.22)\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Look at class proportions.\n",
    "\n",
    "f1 = get_class_frequencies(df['label_cas_04-27-16'])\n",
    "f2 = get_class_frequencies(df['label'])\n",
    "print f1\n",
    "print f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190,)\n",
      "(190,)\n",
      "accuracy = 0.331578947368\n",
      "cohen's kappa = 0\n",
      " Neg  Neu  Pos\n",
      "[[41 33 24]\n",
      " [22 19 14]\n",
      " [11 23  3]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.55      0.42      0.48        98\n",
      "    Neutral       0.25      0.35      0.29        55\n",
      "   Positive       0.07      0.08      0.08        37\n",
      "\n",
      "avg / total       0.37      0.33      0.35       190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Look at metrics for those rows that have >1 label.\n",
    "y = df[df['label_cas_04-27-16'].notnull()]['label_cas_04-27-16'].values\n",
    "y_pred = df[df['label_cas_04-27-16'].notnull()]['label'].values\n",
    "\n",
    "print(y.shape)\n",
    "print(y_pred.shape)\n",
    "# Reverse y to make sure it hurts the scores!\n",
    "y = y[::-1]\n",
    "\n",
    "print(\"accuracy =\", metrics.accuracy_score(y, y_pred))\n",
    "print(\"cohen's kappa =\", cohen_kappa_score(y, y_pred))\n",
    "print(' Neg', ' Neu', ' Pos')\n",
    "print(metrics.confusion_matrix(y, y_pred))\n",
    "print(metrics.classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "### From SKLL -- DO NOT USE ###\n",
    "\n",
    "# License: BSD 3 clause\n",
    "#\"\"\"\n",
    "#This module contains a bunch of evaluation metrics that can be used to\n",
    "#evaluate the performance of learners.\n",
    "#\n",
    "#:author: Michael Heilman (mheilman@ets.org)\n",
    "#:author: Nitin Madnani (nmadnani@ets.org)\n",
    "#:author: Dan Blanchard (dblanchard@ets.org)\n",
    "#:organization: ETS\n",
    "#\"\"\"\n",
    "\n",
    "from __future__ import print_function, unicode_literals\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import kendalltau, spearmanr, pearsonr\n",
    "from six import string_types\n",
    "from six.moves import xrange as range\n",
    "from sklearn.metrics import confusion_matrix, f1_score, SCORERS\n",
    "\n",
    "\n",
    "# Constants\n",
    "_CORRELATION_METRICS = frozenset(['kendall_tau', 'spearman', 'pearson'])\n",
    "\n",
    "\n",
    "def kappa(y_true, y_pred, weights=None, allow_off_by_one=False):\n",
    "#    \"\"\"\n",
    "#    Calculates the kappa inter-rater agreement between two the gold standard\n",
    "#    and the predicted ratings. Potential values range from -1 (representing\n",
    "#    complete disagreement) to 1 (representing complete agreement).  A kappa\n",
    "#    value of 0 is expected if all agreement is due to chance.\n",
    "#\n",
    "#    In the course of calculating kappa, all items in `y_true` and `y_pred` will\n",
    "#    first be converted to floats and then rounded to integers.\n",
    "#\n",
    "#    It is assumed that y_true and y_pred contain the complete range of possible\n",
    "#    ratings.\n",
    "#\n",
    "#    This function contains a combination of code from yorchopolis's kappa-stats\n",
    "#    and Ben Hamner's Metrics projects on Github.\n",
    "#\n",
    "#    :param y_true: The true/actual/gold labels for the data.\n",
    "#    :type y_true: array-like of float\n",
    "#    :param y_pred: The predicted/observed labels for the data.\n",
    "#    :type y_pred: array-like of float\n",
    "#    :param weights: Specifies the weight matrix for the calculation.\n",
    "#                    Options are:\n",
    "#\n",
    "#                        -  None = unweighted-kappa\n",
    "#                        -  'quadratic' = quadratic-weighted kappa\n",
    "#                        -  'linear' = linear-weighted kappa\n",
    "#                        -  two-dimensional numpy array = a custom matrix of\n",
    "#                           weights. Each weight corresponds to the\n",
    "#                           :math:`w_{ij}` values in the wikipedia description\n",
    "#                           of how to calculate weighted Cohen's kappa.\n",
    "#\n",
    "#    :type weights: str or numpy array\n",
    "#    :param allow_off_by_one: If true, ratings that are off by one are counted as\n",
    "#                             equal, and all other differences are reduced by\n",
    "#                             one. For example, 1 and 2 will be considered to be\n",
    "#                             equal, whereas 1 and 3 will have a difference of 1\n",
    "#                             for when building the weights matrix.\n",
    "#    :type allow_off_by_one: bool\n",
    "#    \"\"\"\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    # Ensure that the lists are both the same length\n",
    "    assert(len(y_true) == len(y_pred))\n",
    "\n",
    "    # This rather crazy looking typecast is intended to work as follows:\n",
    "    # If an input is an int, the operations will have no effect.\n",
    "    # If it is a float, it will be rounded and then converted to an int\n",
    "    # because the ml_metrics package requires ints.\n",
    "    # If it is a str like \"1\", then it will be converted to a (rounded) int.\n",
    "    # If it is a str that can't be typecast, then the user is\n",
    "    # given a hopefully useful error message.\n",
    "    # Note: numpy and python 3.3 use bankers' rounding.\n",
    "    try:\n",
    "        y_true = [int(np.round(float(y))) for y in y_true]\n",
    "        y_pred = [int(np.round(float(y))) for y in y_pred]\n",
    "    except ValueError as e:\n",
    "        logger.error(\"For kappa, the labels should be integers or strings \"\n",
    "                     \"that can be converted to ints (E.g., '4.0' or '3').\")\n",
    "        raise e\n",
    "\n",
    "    # Figure out normalized expected values\n",
    "    min_rating = min(min(y_true), min(y_pred))\n",
    "    max_rating = max(max(y_true), max(y_pred))\n",
    "\n",
    "    # shift the values so that the lowest value is 0\n",
    "    # (to support scales that include negative values)\n",
    "    y_true = [y - min_rating for y in y_true]\n",
    "    y_pred = [y - min_rating for y in y_pred]\n",
    "\n",
    "    # Build the observed/confusion matrix\n",
    "    num_ratings = max_rating - min_rating + 1\n",
    "    observed = confusion_matrix(y_true, y_pred,\n",
    "                                labels=list(range(num_ratings)))\n",
    "    num_scored_items = float(len(y_true))\n",
    "\n",
    "    # Build weight array if weren't passed one\n",
    "    if isinstance(weights, string_types):\n",
    "        wt_scheme = weights\n",
    "        weights = None\n",
    "    else:\n",
    "        wt_scheme = ''\n",
    "    if weights is None:\n",
    "        weights = np.empty((num_ratings, num_ratings))\n",
    "        for i in range(num_ratings):\n",
    "            for j in range(num_ratings):\n",
    "                diff = abs(i - j)\n",
    "                if allow_off_by_one and diff:\n",
    "                    diff -= 1\n",
    "                if wt_scheme == 'linear':\n",
    "                    weights[i, j] = diff\n",
    "                elif wt_scheme == 'quadratic':\n",
    "                    weights[i, j] = diff ** 2\n",
    "                elif not wt_scheme:  # unweighted\n",
    "                    weights[i, j] = bool(diff)\n",
    "                else:\n",
    "                    raise ValueError('Invalid weight scheme specified for '\n",
    "                                     'kappa: {}'.format(wt_scheme))\n",
    "\n",
    "    hist_true = np.bincount(y_true, minlength=num_ratings)\n",
    "    hist_true = hist_true[: num_ratings] / num_scored_items\n",
    "    hist_pred = np.bincount(y_pred, minlength=num_ratings)\n",
    "    hist_pred = hist_pred[: num_ratings] / num_scored_items\n",
    "    expected = np.outer(hist_true, hist_pred)\n",
    "\n",
    "    # Normalize observed array\n",
    "    observed = observed / num_scored_items\n",
    "\n",
    "    # If all weights are zero, that means no disagreements matter.\n",
    "    k = 1.0\n",
    "    if np.count_nonzero(weights):\n",
    "        k -= (sum(sum(weights * observed)) / sum(sum(weights * expected)))\n",
    "\n",
    "    return k\n",
    "\n",
    "\n",
    "\n",
    "def kendall_tau(y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Calculate Kendall's tau between ``y_true`` and ``y_pred``.\n",
    "#\n",
    "#    :param y_true: The true/actual/gold labels for the data.\n",
    "#    :type y_true: array-like of float\n",
    "#    :param y_pred: The predicted/observed labels for the data.\n",
    "#    :type y_pred: array-like of float\n",
    "#\n",
    "#    :returns: Kendall's tau if well-defined, else 0\n",
    "#    \"\"\"\n",
    "    ret_score = kendalltau(y_true, y_pred)[0]\n",
    "    return ret_score if not np.isnan(ret_score) else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def spearman(y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Calculate Spearman's rank correlation coefficient between ``y_true`` and\n",
    "#    ``y_pred``.\n",
    "\n",
    "#    :param y_true: The true/actual/gold labels for the data.\n",
    "#    :type y_true: array-like of float\n",
    "#    :param y_pred: The predicted/observed labels for the data.\n",
    "#    :type y_pred: array-like of float\n",
    "\n",
    "#    :returns: Spearman's rank correlation coefficient if well-defined, else 0\n",
    "#    \"\"\"\n",
    "    ret_score = spearmanr(y_true, y_pred)[0]\n",
    "    return ret_score if not np.isnan(ret_score) else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def pearson(y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Calculate Pearson product-moment correlation coefficient between ``y_true``\n",
    "#    and ``y_pred``.\n",
    "#\n",
    "#    :param y_true: The true/actual/gold labels for the data.\n",
    "#    :type y_true: array-like of float\n",
    "#    :param y_pred: The predicted/observed labels for the data.\n",
    "#    :type y_pred: array-like of float\n",
    "#\n",
    "#    :returns: Pearson product-moment correlation coefficient if well-defined,\n",
    "#              else 0\n",
    "#    \"\"\"\n",
    "    ret_score = pearsonr(y_true, y_pred)[0]\n",
    "    return ret_score if not np.isnan(ret_score) else 0.0\n",
    "\n",
    "\n",
    "\n",
    "def f1_score_least_frequent(y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Calculate the F1 score of the least frequent label/class in ``y_true`` for\n",
    "#    ``y_pred``.\n",
    "#\n",
    "#    :param y_true: The true/actual/gold labels for the data.\n",
    "#    :type y_true: array-like of float\n",
    "#    :param y_pred: The predicted/observed labels for the data.\n",
    "#    :type y_pred: array-like of float\n",
    "#\n",
    "#    :returns: F1 score of the least frequent label\n",
    "#    \"\"\"\n",
    "    least_frequent = np.bincount(y_true).argmin()\n",
    "    return f1_score(y_true, y_pred, average=None)[least_frequent]\n",
    "\n",
    "\n",
    "\n",
    "def use_score_func(func_name, y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Call the scoring function in `sklearn.metrics.SCORERS` with the given name.\n",
    "#    This takes care of handling keyword arguments that were pre-specified when\n",
    "#    creating the scorer. This applies any sign-flipping that was specified by\n",
    "#    `make_scorer` when the scorer was created.\n",
    "#    \"\"\"\n",
    "    scorer = SCORERS[func_name]\n",
    "    return scorer._sign * scorer._score_func(y_true, y_pred, **scorer._kwargs)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
